[{"title":"git-hooks","subtitle":"git hooks","date":"2019-05-15","updated":"2019-05-16","path":"git-hooks/","link":"","text":"git hooks现在代码一般都会使用git来进行管理, 其中git hooks(git钩子)是git提供的在代码管理的生命周期中会被触发的一个阶段, 如同react里面组件的生命周期一样, 随着组件的状态的改变, 一些生命周期函数会被触发, 然后可以在触发的时候进行自定义的操作, git 也是如此, 例如我们可以在代码被提交(git commit)前进行代码的自动检查, 通过了检查才允许提交, 否则提交失败, 然后还有常见的自动化部署也是利用了 git hooks, 当新代码被提交到服务端(git push)的时候触发git hooks, 然后服务器自动进行重新部署.我目前的使用来说用到了上面提供的两个钩子pre-commit(git commit时触发)和post-update(git push时触发)一个是在本地提交js代码的时候使用eslint先对代码进行lint, lint通过后才允许提交, 否则提交失败, 修正不合约的语法之后再次进行提交, 这样强制性的代码lint可以一定程度保证团队协作时代码的风格和质量.另一个是我博客的搜索服务是部署在阿里云ECS的docker里面的, 每次我对搜索相关的代码改动的时候, 就会推送到我的服务器里, 然后服务器上通过post-update钩子接收到新的提交时就会执行我写好的脚本, 自动使用最新代码进行docker的重新构建和运行, 很是方便每一个git仓库在初始化的时候都会在项目的.git/hooks目录下初始化默认的钩子脚本# 进入项目根目录后查看默认的钩子脚本cd .git/hooks &amp;&amp; ls# 有如下默认的钩子脚本applypatch-msg.sample pre-applypatch.sample pre-receive.samplecommit-msg.sample pre-commit.sample prepare-commit-msg.samplefsmonitor-watchman.sample pre-push.sample update.samplepost-update.sample pre-rebase.sample每个脚本后都带有.sample后缀, 这是因为这些钩子脚本默认都是不执行的, 如果需要使用哪个钩子, 那么就把后缀去掉, 然后就可以执行了关于各个钩子的调用时机可以查看HOOKS不过需要注意的是.git目录下的内容是不在git的版本管理里面的, 所以你如果更改了本地的钩子脚本, 那么默认情况下是不会被提交的, 如果需要这些内容也能够像其他代码一样在团队之间保持一致的话, 可以把这些钩子文件移出.git目录, 这样提交代码的时候就会提交这部分内容, 然后每一次代码更新以后再把这些脚本复制回.git/hooks目录中(复制的过程也可以通过钩子来自动完成, 不用手动复制, 钩子脚本里面加上拷贝文件的命令就可以了)pre-commitpre-commit是客户端钩子, 在键入提交信息前在本地运行, 它用于检查即将提交的快照, 如果该钩子以非零值退出，Git 将放弃此次提交，不过你可以用git commit --no-verify来绕过这个环节例如对本次提交的js和jsx文件进行eslint检查, 如果有文件无法通过检查, 那么将会退出此次提交#!/bin/shSTAGED_FILES=$(git diff --cached --name-only --diff-filter=ACM | grep \".jsx\\&#123;0,1\\&#125;$\")if [[ \"$STAGED_FILES\" = \"\" ]]; thenexit 0fiPASS=trueecho \"\\nValidating Javascript:\\n\"# Check for eslintwhich eslint &amp;&gt; /dev/nullif [[ \"$?\" == 1 ]]; thenecho \"\\t\\033[41mPlease install ESlint\\033[0m\"exit 1fifor FILE in $STAGED_FILESdoeslint \"$FILE\"if [[ \"$?\" == 0 ]]; thenecho \"\\t\\033[32mESLint Passed: $FILE\\033[0m\"elseecho \"\\t\\033[41mESLint Failed: $FILE\\033[0m\"PASS=falsefidoneecho \"\\nJavascript validation completed!\\n\"if ! $PASS; thenecho \"\\033[41mCOMMIT FAILED:\\033[0m Your commit contains files that should pass ESLint but do not. Please fix the ESLint errors and try again.\\n\"exit 1elseecho \"\\033[42mCOMMIT SUCCEEDED\\033[0m\\n\"fiexit $?post-updatepost-update是服务端钩子, 在服务器收到新的代码推送(git push)的时候运行, 自动化部署就利用这个钩子, 每次向服务器推送代码, 就触发该钩子然后服务器开始部署新代码例如我的博客的搜索目前就是采用这种方式, 搜索使用的是koa框架来做服务端, 代码其实很简单, 只有一个文件, 就是连接我的es, 然后依据查询参数到es中查询文章数据, 然后返回去, 不过中间复杂一点的是使用了nginx来代理(后期还打算通过nginx把被墙的Disqus接进来作为博客的评论系统, 这是后话了), 我的node端是运行在docker里面的, 所以还写了一个Dockerfile来每次拉新代码以后就重新构建docker镜像, 然后使用新的镜像来生成一个搜索容器, 这一套流程还是比较麻烦的, 不过使用自动化的话就能省不少事服务端配置钩子也还是很方便的, 主要就是新建一个git裸仓, git裸仓一般也被作为远程的中心仓库, 这个仓库无法直接作为工作区, 也就是说在这个仓库里是不能进行git commit等操作的, 里面也没有项目源文件而是包含着文件版本历史, 一般是作为共享区来使用, 命名一般为xxx.git的形式, 例如你经常clone的git仓库就是这样的. 我们可以使用git push来向裸仓中提交版本记录, 也可以使用git pull从裸仓中拉取最新的版本新建一个本地仓库的命令是git init, 而新建一个裸仓的命令是git init --bare例如我在服务器上新建一个裸仓用来接受我本地向它提交代码# 新建一个目录用来存放裸仓mkdir ks.git &amp;&amp; cd ks.git# 初始化裸仓git init --bare一个裸仓就建好了我的目的是之后向这个裸仓中提交代码时就触发自动部署流程, 所以我要编辑裸仓中的post-update钩子cd hooks# 使用cp来拷贝并重命名钩子文件cp post-update.sample post-updatevi post-update然后开始写脚本了# 环境变量GIT_DIR会被设置为服务端当前目录, 我们需要更新另一个git里面的文件, 所以要先重置环境变量unset GIT_DIR# 指定一个目录用来作为代码文件夹, 这里面存放的是要运行的代码WORK_DIR=/workspace/ks/servercd $WORK_DIR# 初始化该目录为git工作仓库git init# 指定该仓库的远程仓库地址就是我们之前建立的那个裸仓, 因为我们提交代码是提交到裸仓中的, 所以这个仓库可以从裸仓中拉取最新代码, git remote add origin /workspace/ks/ks.git# 清除未在版本控制里面的冗余文件, 比如编译后的一些文件等等, 保证工作目录的干净git clean -df# 拉取最新代码到工作目录中git pull origin master# 现在最新的代码已经到工作目录中了, 之后可已使用 pm2 restart xxx 来重启我们的node服务# 对于我来说现在可以按照新代码来重新构建镜像了, 当然了, 建新的之前先把旧的都清除掉# 停止正在运行的搜索服务容器docker stop ks# 删除这个已停止的搜索服务容器docker container rm ks# 删除旧的搜索服务镜像docker image rm ks# 根据项目根目录的 Dockerfile 来构建新镜像docker build -t ks .# 然后使用新镜像来生成并运行新的搜索服务容器docker run -d --name ks -p 3000:3000 ks注意: 如果post-update执行权限不足的话可以使用chmod +x post-update来赋予执行权限以上服务器端就配置完成了, 那么本地代码如何提交到服务器呢, 按照如下步骤# 如果本地已经是一个 git 仓库了, 就不用 git init 初始化了git init# 添加刚刚配置的服务器的裸仓为本地仓库的其中一个 remote 主机# 我这里给远程主机配置的名字是 server , 因为我已经把 github 上的仓库配置成 origin 了# user_name 和 server_ip 是你使用 ssh 方式连接服务器时的用户名和服务器地址, : 后面的是裸仓的路径git remote add server user_name:server_ip:/worksapce/ks/ks.git# 之后如果有新的代码需要推送到服务器上, 然后命令可以看到 服务器返回的一些日志信息, 表明 post-update 已被成功调用, 开始自动部署了git push server master以上脚本内容实现了如下自动化过程:本地git push代码到服务器 =&gt; 服务器部署新代码 =&gt; 服务器停止并删除旧的docker里面的搜索服务 =&gt; 根据新代码生成新的docker镜像并运行新的搜索服务参考文章用 Git 钩子进行简单自动部署"},{"title":"elasticsearch","subtitle":"elasticsearch 笔记","date":"2019-05-08","updated":"2019-05-10","path":"elasticsearch/","link":"","text":"elasticsearch我的博客之前的搜索都是使用的hexo-generator-json-content这个插件来生成的静态json文件, 在搜索的时候会去请求这个json文件, 里面是整个博客站点的文章数据, 随着博客的数量变多, 这个文件也越来越大, 导致第一次搜索的时候下载这个文件就会出现很长时间的等待, 所以也一直想要优化博客的搜索.之前做爬虫的时候使用过elasticsearch这个全文检索库, 感觉检索非常方便和快速, 所以这次有时间了就把博客的搜索完全迁移到了es上, 另外还顺带写了一个自动同步 hexo 博客数据到 es 里面的插件hexo-elasticsearch我有一个阿里云的ECS服务器, 不过内存很小只有1G, 我把node端和es都使用docker的方式部署在了这个服务器上, 然后给es分配了300多M的内存, 虽然官方建议分配内存是2G, 但是我这小水管服务器实在是没那么多, 内存给的太多了服务器直接就会挂掉, 好在目前我的博客数据也没那么多, 分配的内存暂时够用. 部署过程可以看我这篇博客docker学习笔记.关于elasticsearch有部分想法借鉴了屈屈的博客使用 Elasticsearch 实现博客站内搜索elasticsearch是一个基于lucene的全文检索库, 向外提供了简洁易用的restful api, 同时在Python, java 和 js 等语言中都有对应的实现, 使用起来很方便. 我现在主要做前端开发, 所以服务端使用的是轻量的 nodejs, 然后引用的elasticsearch这个npm包来实现对 es 的操作.我使用到的也只是es比较简单的一部分功能, 已经完全可以满足我博客的搜索需求.Elasticsearch 集群可以包含多个索引（Index），每个索引可以包含多个类型（Type），每个类型可以包含多个文档（Document），每个文档可以包含多个字段（Field）。以下是 MySQL 和 Elasticsearch 的术语类比图，帮助理解：MySQLElasticsearchDatabaseIndexTableTypeRowDocumentColumnFieldSchemaMappingIndexEverything Indexed by defaultSQLQuery DSL–使用 Elasticsearch 实现博客站内搜索相关apiAPI ReferenceHow to Integrate Elasticsearch into Your Node.js ApplicationElasticsearch 6.x Mapping设置new elasticsearch.Client()第一步是新建一个es连接const es = require('elasticsearch');const client = new es.Client(&#123; // es 的连接地址及ip host: 'your_es_host:port', // 日志, 如果配置了的话每次操作es都会在控制输出相关信息 log: 'trace'&#125;);client.info()连接之后可以通过infoapi查看es的相关信息, 检查是否连接成功, 也可使用client.ping()来测试连接client.info(&#123;&#125;) .then(info =&gt; console.log(info)) .catch(error =&gt; console.error(error))// 或者使用 ping 来查看连接是否正常client.ping(&#123; requestTimeout: 30000&#125;).then(success =&gt; &#123; if(success) &#123; console.log('es connected!'); &#125; else &#123; console.error('es connect error!'); &#125;&#125;)client.indices.create([params] [, options] [, callback])创建索引, 存储数据之前一般都要先创建一个索引, 之后所有的数据都会存储在这个索引中client.indices.create(&#123; // index_name 就是索引的名字 index: 'index_name'&#125;).then(res =&gt; console.log('index success', res)) .catch(err =&gt; console.warn('index fail', err))client.indices.putMapping([params] [, options] [, callback])在有了索引之后, 我们可以创建一个Type, 然后定义Type里面的各自字段的结构和索引信息, 也就是创建Mapping, 和MySQL不同的是在M有SQL里面要先定义好表结构(scheme)然后才能往表里插入数据, 但是在es中我们可以不用先定义Mapping直接就插入数据, es会自动根据数据的类型建立索引, 并且数据字段也可以动态增长, 这是es非常灵活的一点, 但是我仍然先定义Mapping再插入数据, 主要是因为这一步可以定义好各个字段的索引规则对于一个字段首先指定该字段的type(数据类型), 可以查看Mapping里面的可用字段类型, 比较常用的有text: text 类型数据会被分词器拆分开来检索, 例如我的名字会被拆分成我, 我的, 名字和我的名字一般用于一段文字内容的检索, 如果不需要分词可以配置index项为false, 但是如果不需要分词的话就推荐使用keyword类型, keyword类型默认就是不进行分词的keyword: keyword 类型数据不会被拆分, 只能作为整体进行匹配, 例如我的名字就只能搜索我的名字才能搜索到, 一般用于关键词之类的检索date: 日期类型long: 长整型数据double: 浮点数数据boolean: 布尔值ip: ip地址然后是term_vector(词条向量), 这个配置项代表对该字段的各个term的统计信息, 如果某个词出现的位置和频率等, 具体可以查看这里ElasticSearch之termvector介绍analyzer配置指定该字段使用的分词器, 如果不指定, 那么使用的就是默认分词器(standard analyzer), 我这里安装了对中文分词友好elasticsearch-analysis-ik插件, 使用的是该插件提供的分词器, ik 提供了ik_max_word和ik_smart两个分词器, 前者会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合，适合 Term Query; 后者会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”，适合 Phrase 查询.search_analyzer配置搜索时使用的分词器, 默认和analyzer保持一致我的博客的Mapping如下client.indices.putMapping(&#123; index: 'blog', type: 'article', body: &#123; properties: &#123; title: &#123; type: 'text', term_vector: 'with_positions_offsets', analyzer: 'ik_max_word', search_analyzer: 'ik_max_word' &#125;, subtitle: &#123; type: 'text', term_vector: 'with_positions_offsets', analyzer: 'ik_max_word', search_analyzer: 'ik_max_word' &#125;, content: &#123; type: 'text', term_vector: 'with_positions_offsets', analyzer: 'ik_max_word', search_analyzer: 'ik_max_word' &#125;, link: &#123; type: 'keyword' &#125;, author: &#123; type: 'keyword', &#125;, categories: &#123; type: 'keyword', &#125;, tags: &#123; type: 'keyword', &#125;, create_date: &#123; type: 'date', &#125;, update_date: &#123; type: 'date', &#125; &#125; &#125;&#125;);client.index([params] [, options] [, callback])像某个Type中插入数据, 这个接口只能一次插入一条数据client.index(&#123; // 要插入到哪个 index 中 index: 'blog', // 要插入到哪个 Type 中 type: 'article', // 本次插入的数据的id, 可以不配置, 默认也会生成一个id id: 'input-event/', // body 内容就是本次插入的数据的各自字段内容 body: &#123; title: 'input event', subtitle: 'input 元素的事件顺序', author: 'kricsleo', tags: ['js', 'h5'], categories: ['front-end'], content: '如果是组合输入(比如中文日文等)输入的话就会出现括号中组合输入事件, 详细来说是当开始输入中文的时候就会触发`compositionstart`事件, 此时`input`事件和`keyup`事件拿到的输入框的值是不完整的(一般包含你输入的拼音和拼音之间的分号), 当中文输入结束的时候会触发`compositionend`事件, 此时可以取到该输入框的完整的输入中文后的值(一般而言这个值是我们所需要的)', create_date: '2015-12-15T13:05:55Z', update_date: '2015-12-15T13:05:55Z', &#125;&#125;)client.bulk([params] [, options] [, callback])如果需要批量操作的话就需要使用bulk接口, 给bulk可以一次传入多种多样的操作, 比如index(新增), update(更新)和delete删除等等比如我博客生成的json数据里面的一个数组, 每一项都是一篇文章数据, 我需要一次性插入所有文章到es中. 我的做法是每次插入前先清除之前的文章数据, 因为文章里面的内容可能会被更新, 但是博客和es本身是相互独立的, 博客里面是没有记录该文章数据在es中的对应的数据id的, 所以没法去更新es里面的文章数据, 只能先全部清除, 然后再将最新的文章数据全部写入const es = require('elasticsearch');const fs = require('fs');const path = require('path');const client = new es.Client(&#123; host: 'your_es_host:port', // log: 'trace'&#125;);// json file pathconst JSON_PATH = '../../public/content.json';// generate docs by post datafunction convertPosts2Docs(posts) &#123; return posts.map(post =&gt; (&#123; index: 'blog', type: 'article', id: post.title, body: &#123; title: post.title, subtitle: post.subtitle || post.title, link: `/$&#123;post.path&#125;`, content: post.text, create_date: post.date, update_date: post.updated &#125; &#125;));&#125;// generate bulk body by postfunction buildBody(post) &#123; return &#123; body: &#123; title: post.title, subtitle: post.subtitle || post.title, link: `/$&#123;post.path&#125;`, content: post.text, create_date: post.date, update_date: post.updated &#125; &#125;&#125;// generate bulk by index, type, postsfunction buildBulk(index, type, posts) &#123; const bulk = []; posts.forEach(post =&gt; &#123; bulk.push(&#123; index: &#123; _index: index, _type: type, _id: post.title, &#125; &#125;); bulk.push(buildBody(post)); &#125;); return bulk;&#125;// write json into esfunction writeJson(jsonPath) &#123; const filePath = path.resolve(__dirname, jsonPath); fs.readFile(filePath, 'utf8', (err, data) =&gt; &#123; if (err) &#123; console.error(`read file: $&#123;filePath&#125; failed!`); return; &#125; const posts = JSON.parse(data); const bulk = buildBulk('blog', 'article', posts); client.bulk(&#123; body: bulk &#125;).then(res =&gt; &#123; let errorCount = 0; res.items.forEach(item =&gt; &#123; if (item.index &amp;&amp; item.index.error) &#123; console.error(`$&#123;errorCount++&#125; write failed: `, item.index.error); &#125; &#125;); const total = res.items.length; console.log(`write done: $&#123;total - errorCount&#125;/$&#123;total&#125; write successfully!`); &#125;) &#125;);&#125;// clear all previous docsfunction clearDocs(index, type) &#123; return client.deleteByQuery(&#123; index, type, body: &#123; query: &#123; match_all: &#123;&#125; &#125; &#125; &#125;).then(res =&gt; &#123; console.log(`delete done: $&#123;res.deleted&#125;/$&#123;res.total&#125; delete successfully!`); return Promise.resolve(res); &#125;)&#125;clearDocs('blog', 'article') .then(() =&gt; writeJson(JSON_PATH)) .catch(err =&gt; console.error(error))client.search([params] [, options] [, callback])根据 Query DSL 语句查询符合条件的数据一个最简单的搜索, 搜索后匹配的数据返回在hits字段中client.search(&#123; index: 'blog', type: 'article', q: '中文'&#125;).then(res =&gt; console.log(res)) .catch(err =&gt; console.error(err))目前我的博客使用的搜索语句参考了屈屈的博客里面的搜索语句const generateDSL = (q = '', from = 0, to = 10) =&gt; (&#123; index: 'blog', type: 'article', // 搜索关键词 q, // 搜索条目起始位置 from, // 搜索条目终止位置 to, body: &#123; query: &#123; // 使用 dis_max 会在最后计算文档的相关性算分的时候, 只会取queries中的相关性的最大值 // 关于 dis_max 可以查看这里 [Elasticsearch的入门使用](https://juejin.im/post/5b9dbe645188255c865e0d0e#heading-84) dis_max: &#123; queries: [ &#123; match: &#123; // 在哪个字段中进行搜索, 这里是 title 字段 title: &#123; // 要搜索的关键词 query: q, // 最小匹配数 minimum_should_match: '50%', // 设置查询语句的权重, 大于1权重增大, 0到1之间权重逐渐降低。匹配到权重越高的查询语句, 相关性算分越高 boost: 4, &#125; &#125; &#125;, &#123; match: &#123; subtitle: &#123; query: q, minimum_should_match: '50%', boost: 4, &#125; &#125; &#125;, &#123; match: &#123; content: &#123; query: q, minimum_should_match: '75%', boost: 4, &#125; &#125; &#125;, &#123; match: &#123; tags: &#123; query: q, minimum_should_match: '100%', boost: 2, &#125; &#125; &#125;, &#123; match: &#123; categories: &#123; query: q, minimum_should_match: '100%', boost: 2, &#125; &#125; &#125; ], // 将其他匹配语句的评分也计算在内。将其他匹配语句的评分结果与tie_breaker相乘, 最后与最佳字段的评分求和得出文档的算分。 tie_breaker: 0.3 &#125; &#125;, // 会对检索的匹配的结果中，匹配的部分做出高亮的展示, 默认使用标签em包裹 highlight: &#123; // 指定高亮标签前标签 pre_tags: ['&lt;b&gt;'], // 指定高亮标签后标签 post_tags: ['&lt;/b&gt;'], fields: &#123; // 返回的匹配结果中会列出title字段(数组) title: &#123;&#125;, // 返回的匹配结果中会列出content字段(数组) content: &#123;&#125;, &#125; &#125; &#125;&#125;);client.delete([params] [, options] [, callback])删除指定的某条数据, 使用此api删除时必须至少指定index, type和id三个参数, 否则就会删除失败, 也就是说此api只能删除单条数据client.delete(&#123; index: 'blog', type: 'article', id: 'data_id'&#125;)client.deleteByQuery([params] [, options] [, callback])删除符合条件的数据, 使用此api可以删除多条数据, 只要数据符合 query 的条件即可比如我每次同步博客数据的时候都会先删除之前的所有历史博客数据使用的就是这个apiclient.deleteByQuery(&#123; index: 'blog', type: 'article', body: &#123; query: &#123; // 匹配所有文档 match_all: &#123;&#125; &#125; &#125;&#125;elaticsearch与hexo配合折腾着写了个hexo的插件hexo-elasticsearch, 在每次重新生成文章的时候都会自动把文章信息同步到自己的es库中, 不过如果真的要做到博客中使用es来进行搜索, 那么你还要做部署es和部署nodejs后端提供查询服务两个部分, 目前来说我就是这样实现的, 关于 es 的部署你可以查看我这篇博客: docker学习笔记"},{"title":"toLocaleString","subtitle":"冷门的toLocaleString","date":"2019-04-25","updated":"2019-05-16","path":"toLocalString/","link":"","text":"冷门的toLocaleSringjs 里面除了我们日常使用的api以外, 其实还是有不少大多数人都不知道的很好用的api的, toLocaleString算一个, 也许你在面试题中看到过用正则来实现数字千位用逗号分隔的做法, 但是如果你能直接说出toLocaleString, 应该是出乎面试官的意料的, 而它的用法可不止于此.toLocaleString方法在Numnber和Date类型上都有部署, 实现的作用都是格式化数字或者日期, 返回格式化后的字符串.Number.prototype.toLocaleStringapi: toLocaleString([locales [, options]])locales指定地区, 默认是按照当前电脑环境的语言, 也可以指定不同的语言, 中文是zh, 英文是en, 其它可选项请查看MDN, 不区分大小写.例如:const a = -2345679.56789;const b = new Date();// 单纯的数字的格式化在 zh 和 en 是相同的a.toLocalString(); // =&gt; \"-2,345,679.568\"a.toLocaleString('zh'); // =&gt; \"-2,345,679.568\"a.toLocaleString('en'); // =&gt; \"-2,345,679.568\"// 日期的格式化就能看出语言差异了b.toLocalString(); // =&gt; \"2019/4/25 上午10:27:15\"b.toLocaleString('zh'); // =&gt; \"2019/4/25 上午10:27:15\"b.toLocaleString('en'); // =&gt; \"4/25/2019, 10:27:15 AM\"options参数才是重头戏, 它可以定义更多的配置项, 但是一定要先指定locales参数, 才能使用options参数.options对象中的style表示格式化时使用的格式, 默认是decimal即纯数字, 另外还有percent百分比和currency货币形式, 需要注意的是如果指定style为currency, 那么必须接着指定currency属性才行, 因为currency没有默认值, 可选值有CNY人民币, USD美元, EUR欧元等, 更多请参考MDN指定了style为currency之后, 除了currency属性之外, 还有一个currencyDisplay属性可用, 默认值是symbol即货币符号, 另外两个可选值为code代码(如CNY)和name名称(如人民币)const c = 80909.89;c.toLocaleString('zh', &#123;style: 'percent'&#125;); // =&gt; \"8,090,989%\" c.toLocaleString('zh', &#123;style: 'currency', currency: 'CNY'&#125;); // =&gt; \"￥80,909.89\"c.toLocaleString('zh', &#123;style: 'currency', currency: 'CNY', currencyDisplay: 'name'&#125;); // =&gt; \"80,909.89 人民币\"接下来是options里面的两组不能同时使用的参数, 一组是minimumIntegerDigits, minimumFractionDigits和maximumFractionDigits, 另一组是minimumSignificantDigits和maximumSignificantDigits前一组是用来指定数字的最少整数位数, 最少小数位数和最多小数位数, 后一组用来指定最少数字位数和最多数字位数(包括整数和小数一起). 如果指定了后一组参数, 那么前一组参数就会被忽略掉. 指定位数的规则都是按照四舍五入, 是真正的数学上的四舍五入, 而不是像toFixed那样的按照银行家算法的伪四舍五入, 如果位数不足的话就会自动用0补齐. 四舍五入, 自动补齐, 想想就知道有多大潜力!另外style里面还有一个useGrouping参数, 表示是否使用分组分隔符，如千位分隔符或千/万/亿分隔符, 默认为trueconst d = 892839.855;d.toLocaleString('zh', &#123; style: 'currency', currency: 'CNY' ,minimumFractionDigits: 2, maximumFractionDigits:2 &#125;); // =&gt; \"￥892,839.86\"d.toLocaleString('zh', &#123; style: 'currency', currency: 'CNY' ,minimumFractionDigits: 2, maximumFractionDigits:2, useGrouping: false &#125;); // =&gt; \"￥892839.86\"看看上面的金额格式化的示例, 只需要一行语句多简洁啊, 我之前还专门写了个函数来做金额的格式化显示, 跟这个一比差远了…/** * @description: format money to standard string including prefix, separator and two decimal places * @param &#123;number | string&#125; currency * @param &#123;string&#125; prefix prefix the output with the specified string * @return: &#123;string&#125; formated currency */function formatCurrency(currency = '', prefix = '') &#123; const split = currency.toString().split('.'); let integer = split[0] || '0'; if (integer.startsWith('¥')) &#123; integer = integer.slice(1, integer.length); &#125; let isNegative = false; if(integer.startsWith('-')) &#123; isNegative = true; integer = integer.slice(1, integer.length); &#125; let decimal = split[1] || '00'; let output = ''; while (integer.length &gt; 3) &#123; output = `,$&#123;integer.slice(-3)&#125;$&#123;output&#125;`; integer = integer.slice(0, integer.length - 3); &#125; if (integer) &#123; output = integer + output; &#125; if (decimal.length &lt; 2) &#123; decimal = decimal + '0'; &#125; output = `$&#123;isNegative ? '-' : ''&#125;$&#123;prefix&#125;$&#123;output&#125;.$&#123;decimal&#125;`; return output;&#125;Date.prototype.toLocaleStringapi: toLocaleString([locales [, options]])locales参数与之前的一致, 也是指定语言, 默认是当前电脑环境语言options参数就不一样了, 里面的hour12表示使用十二小时制还是二十四小时制, 默认值根据当前环境变化而变化const e = new Date();e.toLocaleString('zh', &#123;hour12: true&#125;); // =&gt; \"2019/4/25 下午11:07:32\"e.toLocaleString('zh', &#123;hour12: false&#125;); // =&gt; \"2019/4/25 23:07:32\"然后是对年月日星期时分秒时区等的显示格式设置, 参数分别是year, month, day, weekday, hour, minute, second, timeZoneName.weekday可选值为narrow, short和long, 就是缩写的长度不同, 例如 Wednesday 依次显示为 W , Wed 和 WednesdaytimeZoneName可选值为short和long, 例如 GMT+8 和 中国标准时间其余的参数可选值为numeric和2-digit, 区别是numeric直接显示, 2-digit会固定显示两位数, 例如 7 和 07month除了numeric和2-digit外还有narrow, short和long, 额外的这三个其实也是控制缩写的长度(设置locales为en能看出差别)参考文章Number​.prototype​.toLocale​String()toLocaleString 了解一下"},{"title":"input-event","subtitle":"input 元素的事件顺序","date":"2019-04-22","updated":"2019-04-22","path":"input-event/","link":"","text":"input 元素的事件顺序h5 的&lt;input /&gt;组件上有很多的事件, 这次来详细的探究一下它们的触发顺序和使用场景我的测试是在 chrome 版本 73.0.3683.75（正式版本）（64 位）环境, 其它的浏览器可能有不同, 有时间再补充其它浏览器吧.目前来说比较常用的有focus/keydown/input/keyup/compositionstart/compositionupdate/compositionend/change点击一个输入框开始输入触发的事件顺序依次是:focus=&gt;keydown(=&gt;compositionstart=&gt;compositionupdate)=&gt;input(=&gt;compositionend)=&gt;keyup如果是组合输入(比如中文日文等)输入的话就会出现括号中组合输入事件, 详细来说是当开始输入中文的时候就会触发compositionstart事件, 此时input事件和keyup事件拿到的输入框的值是不完整的(一般包含你输入的拼音和拼音之间的分号), 当中文输入结束的时候会触发compositionend事件, 此时可以取到该输入框的完整的输入中文后的值(一般而言这个值是我们所需要的)(额外的一点是从input事件开始可以拿到最新输入的值, 前面的事件拿到的值都要落后一次, 少了最后一次输入的字符)change事件的触发需要两个条件, 一是input元素即将失焦, 事件顺序是change=&gt;blur, 二是本次失焦后的内容与前一次失焦后的内容不同(如果相同是不会触发该事件的),最常用的场景之一是input用来搜索的时候, 我们的需求是输入变化的时候就去查询(当然有节流), 但是在中文输入的时候就不要查询, 直到中文输入结束之后再查询, 这样可以避免用一些明显无效的关键词如文章n&#39;r去查询, 等到完整中文输入后变成文章内容再去查询function throttle(fn, minDelay, maxDelay) &#123; let timer; let startTime = new Date(); return function () &#123; const context = this; const args = arguments; let curTime = new Date(); clearTimeout(timer); if (curTime - startTime &gt;= maxDelay) &#123; fn.apply(context, args); startTime = curTime; &#125; else &#123; timer = setTimeout(() =&gt; &#123; fn.apply(context, args); &#125;, minDelay); &#125; &#125;&#125;function listenInput(selector, cb, delay = 150, maxDelay = 1000) &#123; const el = document.querySelector(selector); if(!el || !cb || typeof cb !== 'function') &#123; return false; &#125; const throttleCB = throttle(cb, delay, maxDelay); let isComposition = false; const compositionstart = () =&gt; isComposition = true; const compositionend = () =&gt; &#123; isComposition = false; throttleCB(el.value); &#125;; const input = () =&gt; &#123; if(isComposition) &#123; return false; &#125; throttleCB(el.value); &#125; el.addEventListener('compositionstart', compositionstart); el.addEventListener('compositionend', compositionend); el.addEventListener('input', input); return () =&gt; &#123; el.removeEventListener('compositionstart', compositionstart); el.removeEventListener('compositionend', compositionend); el.removeEventListener('input', input); &#125;&#125;// 使用示例// 开始监听, 默认最小间隔时间是150ms, 最大间隔时间是1000msconst removeListener = listenInput('#inputId', value =&gt; &#123; console.log(value);&#125;, 100, 1500);// 取消监听removeListener();"},{"title":"translate-you-might-not-need-redux","subtitle":"翻译<<You Might Not Need Redux>>","date":"2019-04-15","updated":"2019-05-16","path":"translate-you-might-not-need-redux/","link":"","text":"翻译《You Might Not Need Redux》闲来无事, 翻译下我挺喜欢的一个程序员 Dan Abromov 的一篇文章《You Might Not Need Redux》, 因为我对于 redux 的用法也还很浅显, 里面也还存在着错误的用法, 多看看别人的一些优秀的工程, 慢慢会有更好的体会吧.以下为翻译.你也许并不需要 Redux许多人经常在他们真的需要 Redux 之前就在项目中引入了它. “如果我的应用因为缺少了它而无法满足后续的扩展怎么办?”, 但是在之后, 开发者又会对 Redux 给代码带来的迂回逻辑感到不满. “为什么我需要新建三个文件才能完成一个小小的功能?到底为什么?”当人们遇到一些困难时会去抱怨 Redux, React, 函数式编程, 不可变数据和很多其他的事, 我也能理解他们. 把 Redux 和其它不需要”样板化”代码来更新应用状态的方式做比较然后得出 Redux 就是很繁琐的结论是很正常的事. 在某些方面来说确实如此, 设计的初衷就是这样.Redux 提供了一些取舍. 它要求你:把应用的状态描述为普通对象和数组.把应用中发生的变化描述为普通对象.把应用变化的处理逻辑描述为纯函数.不论你是否在使用 React 构建一个应用, 上面的那些限制条件都不是必要的. 进一步来说这些限制条件是非常严格的, 在你把他们使用到应用中的哪怕一部分的时候都应该考虑清楚.你是否有足够充足的理由去这样做?这些限制条件对我来说是非常有吸引力的, 因为它们能帮助建立一个有着如下特性的应用:把应用的状态保存到本地存储中, 然后开箱即用在服务端就把状态填充好, 然后把它在 HTML 中发送给客户端, 然后开箱即用序列化用户操作并将其与状态快照一起附加到自动错误报告中，以便产品开发人员可以重播它们以重现错误通过网络传递操作对象以实现协作环境，而不会对代码的编写方式进行重大更改保留撤消历史记录或进行乐观突变，而不会对代码的编写方式进行重大更改开发时在应用状态历史里实现时间旅行, 当代码变更时可以从历史变更记录里面重新计算出当前的的应用状态, 参考Redux DevTools为开发者工具提供全面的检查和控制能力来让产品开发者们能够为他们的应用开发自定义的工具在重用业务逻辑的同时提供换肤功能如果你正在开发一些可扩展的终端, JavaScript调试器或者其它的一些网页应用的话, 这是值得你去尝试一下的, 哪怕只是采用其中一部分的想法(顺带一说, 这些想法一直都存在)然而, 如果你是刚开始学习 React 的初学者, 那么不要把 Redux 作为你的第一选择.你要做的应该是按照 React 的思想去思考. 当你真的需要 Redux 或者你想尝试一些新鲜的东西时再来使用 Redux 吧. 但是在使用的时候要格外注意一些, 就像你使用其它带着强烈的主观意识的工具一样.如果按照” Redux 的方式”的方式写代码让你感到很有压力, 那么这也许是在提醒你或者你的同事们把它看的太过重要了. 它毕竟只是你的工具箱中的其中一个工具而已, 一个略带疯狂的实验.最后, 不要忘了你可以在不使用 Redux 的情况下采纳它提供的一些想法. 例如, 一个有着本地状态的 React 组件:import React, &#123; Component &#125; from 'react';class Counter extends Component &#123; state = &#123; value: 0 &#125;; increment = () =&gt; &#123; this.setState(prevState =&gt; (&#123; value: prevState.value + 1 &#125;)); &#125;; decrement = () =&gt; &#123; this.setState(prevState =&gt; (&#123; value: prevState.value - 1 &#125;)); &#125;; render() &#123; return ( &lt;div&gt; &#123;this.state.value&#125; &lt;button onClick=&#123;this.increment&#125;&gt;+&lt;/button&gt; &lt;button onClick=&#123;this.decrement&#125;&gt;-&lt;/button&gt; &lt;/div&gt; ) &#125;&#125;这样就很完美了. 我是认真的, 它是经得起考验的.本地状态就足够了Redux提供的取舍方案是为了提供一种把”发生了什么”和”状态是如何变化的”解耦的间接解决方案这种解耦始终都是正确的吗?并不是, 它是一种取舍.比如说, 我们能够用如下方式把一个 reducer 从我们的组件中分离出去:import React, &#123; Component &#125; from 'react';const counter = (state = &#123; value: 0 &#125;, action) =&gt; &#123; switch (action.type) &#123; case 'INCREMENT': return &#123; value: state.value + 1 &#125;; case 'DECREMENT': return &#123; value: state.value - 1 &#125;; default: return state; &#125;&#125;class Counter extends Component &#123; state = counter(undefined, &#123;&#125;); dispatch(action) &#123; this.setState(prevState =&gt; counter(prevState, action)); &#125; increment = () =&gt; &#123; this.dispatch(&#123; type: 'INCREMENT' &#125;); &#125;; decrement = () =&gt; &#123; this.dispatch(&#123; type: 'DECREMENT' &#125;); &#125;; render() &#123; return ( &lt;div&gt; &#123;this.state.value&#125; &lt;button onClick=&#123;this.increment&#125;&gt;+&lt;/button&gt; &lt;button onClick=&#123;this.decrement&#125;&gt;-&lt;/button&gt; &lt;/div&gt; ) &#125;&#125;注意我们刚刚在上面的代码中做到了不使用npm install就能够使用 Redux. 哇哦!你应该把这种做法使用到你的有状态的组件中吗? 大部分情况下不会的, 除非你计划能够从这种比较曲折的做法中获得收益. 在如今的开发中, 制定计划是很关键的事.Redux 库本身只是一系列的工具, 能够帮助挂载 reducers 到一个单一的全局存储对象. 用多用少都随你意但是如果你舍弃了某些东西, 请确保你能获取对应的回报."},{"title":"web-load-performance","subtitle":"网页加载优化","date":"2019-04-11","updated":"2019-04-12","path":"web-load-performance/","link":"","text":"浏览器网页加载性能优化如何让一个页面加载的更快真是一个亘古不变的话题, 一般来说最主要的衡量点是首屏的展示时间, 或者说是页面从空白到有内容展示这中间的时间间隔, 前前后后研究了很多文章和做法, 其中最核心的一点是要弄清楚html, css和js是如何联合起来影响一个页面最终的呈现过程的.参考文章相关的文章实在汗牛充栋, 这里记录一下一些写的不错的.网页加载性能优化方法研究分析关键渲染路径性能, 这是 google 的开发者给出一个文章系列, 写的非常好, 强烈建议把这个系列看完"},{"title":"toFixed","subtitle":"toFixed的精度问题","date":"2019-03-15","updated":"2019-04-11","path":"toFixed/","link":"","text":"JS 中的 toFixed精度问题在关于金额的计算中经常会出现精确到两位小数的情况, 然后如果直接使用js的number.toFixed()方法其实会导致意想不到的问题, 比如你可以猜一下下面表达式的执行结果0.1 + 0.2;(1.555).toFixed(2);第一个表达式结算结果是0.30000000000000004, 第二个表达式结果是&quot;1.55&quot;, 其实这是 js 的浮点数存储方式导致的, 具体的可以看github上的一个讨论:JavaScript 浮点数陷阱及解法, 简单来说就是 js 里面对于小数的存储是不精确的, 所以在涉及到小数的运算的时候就有可能因为精度问题出现意想不到的计算结果. 如果是一般的运算的话可以使用这个库来解决这个问题nefe/number-precision.关于toFixed()方式的说明在MDN上说是采取的四舍五入的规则, 但是实际测试并非如此, 比如你可以猜一下下面表达式的执行结果:(1.15).toFixed(1);(1.151).toFixed(1);(1.25).toFixed(1);这三个表达式的执行结果分别是&quot;1.1&quot;, &quot;1.2&quot;和&quot;1.3&quot;, 按照四舍五入根本说不通, 其实toFixed()真正的规则是银行家舍入算法银行家舍入算法银行家舍入算法规则是四舍六入五考虑, 五后非零就进一, 五后为零看奇偶, 五前为偶应舍去, 五前为奇要进一, 之所以制定出这一套规则是因为在银行金额的计算中为了尽可能少的避免损失, 因为金额的舍去和进位总体来说要保持大致相同的概率, 这样最后计算出来的帐才会不盈不亏, 具体讨论可以看这里: 为什么银行家舍入是合理的？和知乎的讨论我不知道是不是chrome更新了的原因, 前几天刚测过的银行家算法来解释toFixed()是可以解释的通的, 但是写这篇笔记的时候我再次测试却又发现与之前的测试结果不一致了, 现在怎么都解释不通了例如, 按照银行家算法, (1.555).toFixed(2)的结果应该是&quot;1.56&quot;, 但是今天的执行结果变成了&quot;1.55, 虽然满足了五前为奇但是却并没有进一, WTF???如何修复toFixed()的舍入问题不论怎样, 当日常编程中使用toFixed()碰到舍入的时候我们总希望能够按照我们所期望的真正的四舍五入那样返回结果, 所以只能手动的实现toFixed()方法.我下面只是随便实现的一个, 把原数先放大一定倍数, 然后利用Math.round()来做真正的四舍五入, 最后然后再缩小相同倍数, 这样处理一次之后就能排除特殊的五后的情况, 然后就可以使用Number.toFixed()方法得到理想中的四舍五入后的值, 简单的写了几个测试, 也许有特例是我没有覆盖到的?function toFixed(value, digits) &#123; const multiple = Math.pow(10, digits); const magnified = value * multiple; const roundedMagnified = Math.round(magnified); return ( roundedMagnified / multiple ).toFixed(digits);&#125;function test(describe, fn) &#123; console.group(describe); typeof fn === 'function' &amp;&amp; fn(); console.groupEnd();&#125;const Expect = function (result) &#123; this.result = result; this.tobe = expectResult =&gt; &#123; if(result === expectResult) &#123; console.log('passed'); &#125; else &#123; console.error(`failed: expect $&#123;result&#125; to be equal to $&#123;expectResult&#125;`); &#125; &#125;;&#125;function expect(result) &#123; return new Expect(result);&#125;// testtest('test toFixed', () =&gt; &#123; expect(toFixed(1.55, 1)).tobe('1.6'); expect(toFixed(1.45, 1)).tobe('1.5'); expect(toFixed(1.550, 1)).tobe('1.6'); expect(toFixed(1.551, 1)).tobe('1.6'); expect(toFixed(1.552, 1)).tobe('1.6'); expect(toFixed(1.450, 1)).tobe('1.5'); expect(toFixed(1.451, 1)).tobe('1.5'); expect(toFixed(1.452, 1)).tobe('1.5'); expect(toFixed(1.55, 2)).tobe('1.55'); expect(toFixed(1.45, 2)).tobe('1.45'); expect(toFixed(1.550, 2)).tobe('1.55'); expect(toFixed(1.551, 2)).tobe('1.55'); expect(toFixed(1.552, 2)).tobe('1.55'); expect(toFixed(1.450, 2)).tobe('1.45'); expect(toFixed(1.451, 2)).tobe('1.45'); expect(toFixed(1.452, 2)).tobe('1.45');&#125;);"},{"title":"constraint-validation","subtitle":"h5的原生表单校验api","date":"2019-02-25","updated":"2019-02-25","path":"constraint-validation/","link":"","text":"h5 原生表单校验api我们通常会对表单的 input 的做各种各样的校验, 比如长度, 大小, 格式等等, 其实在h5中为了方便这些校验原生就有不少的校验类型和方式, 只不过错误提示的样式由于各个浏览器不太一样, 而且无法自定义, 产品和设计一般都不会认可这样的表现, 所以目前还是比较少用到浏览器原生的校验, 不过了解一下还有没有坏处的.这里我放一篇对 h5 原生的校验描述的比较不错的文章HTML5利用约束验证API来检查表单的输入数据另外可以看一下 MDN 的资料约束验证, 目前可用的校验方式有: pattern, min, max, required, step, maxlengthinput 目前支持的类型有传统的10种, 加上 h5 中新增的13种, 一共是23种.传统的10种| type | description || —- | —- || text | 文本 || password | 密码, 输入字符会被以*隐藏 || file | 点击上传文件 || radio | 单选 || checkbox | 多选 || hidden | 隐藏的字段 || button | 按钮 || image | 图像形式的提交按钮 || image | 文本 || reset | 重置表单输入框 || submit | 提交表单 |h5 新增的13种| type | description || —- | —- || number | 数字输入 || tel | 电话号码 || email | 邮件地址 || url | url || range | 一定范围的数字, 滑动选择形式 || color | 点击弹出颜色选择框 || search | 语义化, 表示搜索, 与 text 表现一直 || date | 选择年-月-日 || month | 选择年-月 || week | 选择年-周 || time | 选择时-分 || datetime | 选择年-月-日-时-分 UTC时间 || datetimelocal | 选择年-月-日-时-分 本地时间 |"},{"title":"BFC","subtitle":"BFC","date":"2019-02-25","updated":"2019-02-25","path":"BFC/","link":"","text":"BFC (BLOCK FORMATTING CONTEXT)关于 BFC (BLOCK FORMATTING CONTEXT: 块格式化上下文)这个专有名词可能听得不多, 但是在实际的页面布局中实际上却是会经常碰到的, 只是没有特意去注意这个现象而已, 这里记录一下它是如何影响我们的布局的.BFC 解释9.4.1 Block formatting contextsFloats, absolutely positioned elements, block containers (such as inline-blocks, table-cells, and table-captions) that are not block boxes, and block boxes with ‘overflow’ other than ‘visible’ (except when that value has been propagated to the viewport) establish new block formatting contexts for their contents.In a block formatting context, boxes are laid out one after the other, vertically, beginning at the top of a containing block. The vertical distance between two sibling boxes is determined by the ‘margin’ properties. Vertical margins between adjacent block-level boxes in a block formatting context collapse.In a block formatting context, each box’s left outer edge touches the left edge of the containing block (for right-to-left formatting, right edges touch). This is true even in the presence of floats (although a box’s line boxes may shrink due to the floats), unless the box establishes a new block formatting context (in which case the box itself may become narrower due to the floats).For information about page breaks in paged media, please consult the section on allowed page breaks.by - w3c: 9.4.1 Block formatting contexts创建一个 BFC第一段在描述如何创建一个 BFC, 目前根据总结有如下14种方法(别担心, 实际我们常用的并没有那么多)可以使得一个区域变成一个 BFC:根元素或包含根元素的元素，这里我理解为body元素浮动元素（元素的float不是none）overflow值不为visible的块元素绝对定位元素（元素的position为absolute或fixed）行内块元素（元素的display为inline-block）弹性元素（display为flex或inline-flex元素的直接子元素）网格元素（display为grid或inline-grip元素的直接子元素）表格单元格（元素的display为table-cell，html表格单元格默认为该值）表格标题（元素的display为table-caption，html表格标题默认为该值）匿名表格单元格元素（元素的display为table、table-row、table-row-group、table-header-group、table-footer-group（分别是html table、row、tbody、thead、tfoot的默认属性）或inline-table）display值为flow-root的元素contain值为layout、content或strict的元素多列容器（元素的column-count或column-width不为auto，包括column-count为1）column-span为all的元素始终会创建一个新的BFC，即使该元素没有包裹在一个多列容器中其中前六点是我们目前比较常碰到的情况, 尤其是第一点很容易忽略Margin Collapse第二段在描述在一个 BFC 内部的子元素在垂直方向上会从顶部开始按照自上而下的顺序排布, 两个子元素 box 之间的距离由 margin 决定, 相邻(含义见下面)的 box 之间的 margin (margin-bottom和margin-bottom) 会发生折叠[margin collapse]现象, 折叠具体表现为如下三点:如果二者的 margin 都是正数或者负数, 那么最后二者之间的距离是二者中绝对值大的那一个如果一个为正, 另一个为负, 那么最后二者之间的距离是二者相加的和同时要注意这样的折叠是有条件的, 除了满足上面说的要在同一个 BFC 中的相邻子元素之间, 还有如下条件:在定位规则为正常文档流中的块级盒(非float, 非绝对定位), 且在同一 BFC是垂直方向上的 margin两 margin 相邻, 中间无任何间隔包括包含 padding, boarder, line-box, clearance(clear属性), 意味着会发生折叠的两个 margin 是直接接触的, 没有被任何东西隔开相邻的情况是指如下两种:兄弟: 两个子元素之间的 margin-bottom 和 margin-top父子: 父容器的 margin-top 和第一个子元素的 margin-top之间, 父容器的 margin-bottom 和 最后一个子元素的 margin-bottom 之间水平排布第三段内容简单一点, 是说在 BFC 内部的子元素的左边距会与 BFC 容器的左边对齐(从右到左布局的话那么就对齐到右边)(我目前没有发现用途).避免高度坍塌BFC 的另外一个特点就是可以避免父容器的高度坍塌, 在 float 布局中如果子元素浮动了, 那么父元素的高度在计算的时候就不会计算子元素的高度(父元素的宽度仍然会计算浮动子元素的宽度), 那么很容易出现父元素高度不高, 导致子元素在视觉上出现在父元素外面的情况, 而 BFC 的一个特点就是会包納内部的浮动元素, 所以如果使用overflow: auto或者其它的方式使得父容器变为一个 BFC 容器的话, 那么父元素就会包含浮动的子元素了, 也就不会出现高度坍塌了.参考资料https://juejin.im/post/5b704f18e51d4566612667c2"},{"title":"ES6-map-set-symbol","subtitle":"ES6中新的数据类型","date":"2019-01-18","updated":"2019-02-26","path":"ES6-map-set-symbol/","link":"","text":"ES6中新的数据类型在ES6里面引入了一些新的数据类型, 包括 Map / Set / Symbol 等等, 这里了解一下他们的用法和使用场景.Map我们之前存储键值对形式的数据使用的都是{}这样的Object对象, 但是很大的一个确定是键只能使用字符串, 即使传入的不是字符串内容, 内部也会将传入的值转换为字符串类型来存储, ES6中推出的Map可以解决这个局限性, Map中存储的键和值都可以是任意的类型, 是一种更完善的 Hash 结构实现.Map相关APInew Map()构造函数// 构造函数const a = new Map();// 或者我们也可以传入数组作为构造函数的参数来生成一个 Mapconst b = new Map([ ['name', 'krics'], ['gender', 'male']]); // =&gt; &#123;\"name\" =&gt; \"krics\", \"gender\" =&gt; \"male\"&#125;关于传入数组作为构造函数的参数然后生成 Map 时所发生的事情可以按照如下过程理解, 实际上会循环数组本身, 然后对每个子元素取出它的第一个值作为key, 第二个值作为value, 赋值到空的 Map 中, 注意是只会用到子元素的前两个值, 如果子元素中有更多的值, 那么并不会被赋值到 Map 中, 会被忽略掉.const arr = [ ['name', 'krics'], ['gender', 'male']];const b = new Map();arr.forEach(([key, value]) =&gt; b.set(key, value));除了数组之外, 任何具有 Iterator 接口、且每个成员都是多个元素的数组的数据结构的都可以作为 Map 构造函数的参数. 例如使用 Set 类型数据作为参数:const set = new Set([ ['name', 'krics'], ['gender', 'male']]);const c = new Map(set); // =&gt; &#123;\"name\" =&gt; \"krics\", \"gender\" =&gt; \"male\"&#125;Map.set(key, value)添加值参数key和value都可以是任意类型的, 并且执行后会返回当前Map对象, 所以可以链式调用Map.set(key1, value1).set(key2, value2).key实际是和内存地址绑定的, 也就是说Map.set({}, 1).set({}, 2)会添加两个键值对到对象中, 因为两次使用的{}都会有各自的地址, 不是同一个对象, 如果对同一个键多次赋值, 最后一次会覆盖之前的值.对于键值是否相同的判断可以大致理解为===判断, 唯一不同的是===认为NaN和NaN不等, 但是在Map中会被认为相同, 作为同一个键.Map.get(key)取值返回对应的值, 如果Map对象中没有这个键, 则返回undefinedMap.has(key)判断是否有该键有则返回true否则返回falseMap.delete(key)删除某个键值对删除成功返回true否则返回falseMap.clear()清除所有的键值对清除所有的键值对, 没有返回值Map.size当前键值对的数量返回当前Map对象中的键值对数量遍历MapMap.keys() 返回键名的遍历器Map.values() 返回键值的遍历器Map.entries() 返回所有成员的遍历器Map.forEach() 遍历 Map 的所有成员需要特别注意的是，Map 的遍历顺序就是插入顺序.Map与其他数据类型的转换Map转为数组, 由于扩展运算符(...)底层实际调用的是数据结构的Iterator接口,因此只要具有Iterator接口的对象，都可以使用扩展运算符, Map也不例外.// 这里先使用一个数组生成了一个 map, 最后又使用生成的 map 转换得到了原来的数组const d = new Map([ ['name', 'krics'], ['gender', 'male']]);const arr = [...d]; // =&gt; [ [\"name\", \"krics\"], [\"gender\", \"male\"] ]弱化的WeakMapWeakMap和Map的结构与用法基本相似, 不过存在一些比较重要的区别.WeakMap只接受对象作为键名（null除外），不接受其他类型的值作为键名WeakMap不能遍历, 也就是没有keys(), values(), entries()方法, 并且也没有size属性和clear()方法, 它保留的只有四个方法set(), get(), has()和delete()之所以特意设计WeakMap这个类型, 实际是为了解决浏览器的内存释放问题, 浏览器内存的垃圾回收机制中其中一种叫引用计数法, 当一个对象的被引用次数大于等于1的时候, 浏览器是不会去清除回收这个对象的, 在老旧的IE中经常出现代码中引用了某个DOM元素, 但是由于当时的底层机制, 这个引用无法被清除, 导致DOM对象一直留存在内存中, 最后可能就会拖垮浏览器(现代的浏览器不会这样了), 所以考虑到有时候我们并不需要一个对象一直被引用导致内存空间无法被回收, 然后设计了WeakMap这个类型.WeakMap中的键名所引用的对象是不会被引用计数法算作是引用的, 也就是说在内存回收的时候, 如果别的地方都没有使用这个对象了, 即使在WeakMap中有键名是在引用这个对象的, 那么浏览器也还是会回收这个对象, 释放掉它占用的内存. 需要注意的是这个弱化的过程只是弱化了键名的引用, 键值如果引用了某个对象, 那个对象是会被算做引用+1的.一旦键名引用的对象被回收掉了, 那么WeakMap中对应的这一项也会被自动清除, 不需要我们手动delete()删除这一项. 一个典型应用场景是，在网页的DOM元素上添加数据，就可以使用WeakMap结构。当该DOM元素被清除，其所对应的WeakMap记录就会自动被移除. 更详细的例子可以查看这里.SetES6 为了改善之前一直使用{}来创建键值对形式的数据而新增了Map, 同样为了改善数组形式数据的使用而新增了Set, Set类似于数组, 但是其中的值都是唯一的, 不存在重复.(不会重复这一点可以用来去重或者交集并集等等)Set相关APISet本身是一个构造函数, 参数可以是数组或者其它有iterable接口的数据. 例如:const a = new Set();const b = new Set([1, 2, 3, 2]); // a =&gt; 1, 2, 3const c = new Set('aabaa'); // c =&gt; a, bArray.from()可以把Set转为普通数据.其它api2.1 add(): 添加数据2.2 delete(): 删除数据2.3 clear(): 删除所有数据2.4 has(): 判断是否有某个数据2.5 size: 返回数据数目2.6 keys(): 遍历键(与值实际相等)2.7 values(): 遍历值2.8 entries() 遍历键值对(键与值相等)2.9 forEach(): 遍历值WeakSetES6 同样也为Set提供了WeakSet类型, 与WeakMap十分相似, WeakSet中的值只能是对象, 不能是其他类型的值, 同样也是不计算引用次数的. 使用时可以用new WeakSet()来构建, 其他api与Set一致, 不过出于跟WeakMap相同的原因, 也是不能遍历的."},{"title":"Proxy","subtitle":"ES6的新特性-Proxy(代理)","date":"2019-01-17","updated":"2019-01-21","path":"Proxy/","link":"","text":"拥抱ES6中的新API–ProxyES6带来了很多新的方便易用的API, Proxy(代理)就是其中之一, 意思可以理解为对象的代理, 实际上是一个构造函数, 通过这个构造函数我们可以对某个对象进行包装, 然后返回一个新的对象, 然后我们所有对原对象的操作都可以转移到这个新的对象上, 并且我们的操作过程是可以被拦截和过滤的, 这就类似于你请的律师一样, 他会为你处理你的事情, 并在处理的过程中进行一些你设定好的操作, 称为代理.它的产生我之前探索过Object.defineProperty()这个API, 这个API通过定义对象的属性的get和set存取描述符也可以在想要操作这个对象的时候捕捉到那些行为, 与 Proxy 非常类似, 不过 Proxy 可以认为是前者的升级版, 前者在ES5中就已经有了, 所以低版本的浏览器或者老旧的IE也可以使用, 其中Vue2.0及以下就是使用的Object.defineProperty()来实现的数据双向绑定, 所以可以兼容低版本的浏览器, 不过 Proxy 是在ES6中新引入的, 功能比前者更全面, 能够解决之前解决不了的部分属性变化的拦截问题, Vue作者本人尤雨溪在最近的一次演讲中表示, 今年下半年将会推出的Vue3.0中将使用 Proxy 来代替之前的Object.defineProperty(), 这样新的Vue3.0也就无法兼容低版本和IE浏览器(而且这个兼容性问题无法使用polyfill来弥补), 关于二者的详细区别, 也可以参考掘金的这篇文章vue3.0 尝鲜 – 摒弃 Object.defineProperty，基于 Proxy 的观察者机制探索.使用基本语法:const p = new Proxy(target, handler);参数说明:target: 用Proxy包装的目标对象（可以是任何类型的对象，包括原生数组，函数，甚至是另一个代理.handler: 一个对象，其属性是当执行一个操作时定义代理的行为的函数.使用示例:const handler = &#123; get(target, prop) &#123; console.log(`getting $&#123;prop&#125;`); return prop in target ? target[prop] : 200; &#125;, set(target, prop, value) &#123; console.log(`setting $&#123;prop&#125; to $&#123;value&#125;`); target[prop] = value; &#125;&#125;;const t = &#123;&#125;;const p = new Proxy(t, handler);p.name = 'krics'; // =&gt; setting name to kricsp.name; // =&gt; getting namet; // =&gt; &#123;name: 'krics'&#125;发生了什么p是对t对象进行包装过后的代理对象, 当我们给p设置新属性的时候, 在代理对象内部会调用handler中的set函数, 将新属性设置给t对象, 当我们需要获取p的某个属性的时候, 就会调用handler中的get函数, 然后返回对应的值, 感觉起来就好像我们是在操作t对象一样, 这里面可以挖掘出更大的潜力的就是console.log()这段代码, 我们在实际情况中可以在这个地方进行任意的处理, 比如执行一个函数, 或者通知消息订阅者这里的数据发生了变化, 然后去更新视图等等.数据双向绑定示例我拿一个简单的输入框输入文字, 然后页面上同步显示出我输入的文字作为示例// html content// &lt;input type=\"text\" class=\"input\" /&gt;// &lt;p class=\"text\"&gt;&lt;/p&gt;const Text = document.getElementsByClassName('text')[0];const Input = document.getElementsByClassName('input')[0];const p = new Proxy(&#123;&#125;, &#123; set(target, prop, value) &#123; Text.innerHTML = value; target[prop] = value; &#125;&#125;);Input.addEventListener('input', e =&gt; &#123; const &#123; target: &#123; value &#125; &#125; = e; p.text = value;&#125;);关于Reflect在看Proxy相关的内容的时候看到了Reflect这个同样在ES6中引入的对象, 而且在js之后的发展中这个对象上将会部署越来越多的方法, 比如将Object对象的一些明显属于语言内部的方法（比如Object.defineProperty），放到Reflect对象上。现阶段，某些方法同时在Object和Reflect对象上部署，未来的新方法将只部署在Reflect对象上。也就是说，从Reflect对象上可以拿到语言内部的方法。修改某些Object方法的返回结果，让其变得更合理。比如，Object.defineProperty(obj, name, desc)在无法定义属性时，会抛出一个错误，而Reflect.defineProperty(obj, name, desc)则会返回false。让Object操作都变成函数行为。某些Object操作是命令式，比如name in obj和delete obj[name]，而Reflect.has(obj, name)和Reflect.deleteProperty(obj, name)让它们变成了函数行为。Reflect对象的方法与Proxy对象的方法一一对应，只要是Proxy对象的方法，就能在Reflect对象上找到对应的方法。这就让Proxy对象可以方便地调用对应的Reflect方法，完成默认行为，作为修改行为的基础。也就是说，不管Proxy怎么修改默认行为，你总可以在Reflect上获取默认行为。更详细的内容可以参考这里之所以在这里说起这个新的对象, 是因为Reflect和Proxy搭配起来使用非常方便(例如上面说的第四点)我们可以把之前写过的Proxy使用的代码里面的handler部分改一点东西, 让它更加合理const handler = &#123; get(target, prop, receiver) &#123; console.log(`getting $&#123;prop&#125;`); return Reflect.get(target, prop, receiver); &#125;, set(target, prop, value, receiver) &#123; console.log(`setting $&#123;prop&#125; to $&#123;value&#125;`); return Reflect.set(target, prop, value, receiver); &#125;&#125;;与之前的代码的区别是我们不再自己实现获取属性的值或者设置属性的值的方法, 转而调用原生的默认的get和set来完成操作, 更加可靠.关于Reflect的API, 可以参见下面.需要说明的是关于上面使用的Reflect.get和Reflect.set中的第三个参数receiver, 这个参数是一个可选项, 代表this的指向(即上下文), 传入一个对象之后, 内部的操作如果用到this, 那么将会使用传入的receiver对象.Reflect上已经部署的方法目前已经部署了13个, 未来会有更多.Reflect.apply(target, thisArg, args)Reflect.construct(target, args)Reflect.get(target, name, receiver)Reflect.set(target, name, value, receiver)Reflect.defineProperty(target, name, desc)Reflect.deleteProperty(target, name)Reflect.has(target, name)Reflect.ownKeys(target)Reflect.isExtensible(target)Reflect.preventExtensions(target)Reflect.getOwnPropertyDescriptor(target, name)Reflect.getPrototypeOf(target)Reflect.setPrototypeOf(target, prototype)对比Object.defineProperty()Object.defineProperty()每次只能劫持一个属性, 如果一个对象里面有多个属性需要劫持, 那么就需要不断的循环来重复处理所有需要劫持的属性, 另外如果对象后期新增了属性, 那么新增的属性是不会被自动劫持的, 这也就是为什么在Vue中我们需要把进行双向绑定的属性提前定义好, 因为后面新写入的属性, Vue是没法自动去进行劫持绑定的(需要手动调用Vue提供的函数进行处理), 但是Proxy就没有这些缺点, 因为他是一次劫持整个对象, 那么对象中的属性自然也会被一次性都劫持, 而且对于新增的属性, 因为也同样属于这个对象, 那么也自然会被劫持, 使用起来方便了很多. Proxy的缺点目前来说很明显, 就是无法磨平的兼容性.参考资料vue3.0 尝鲜 – 摒弃 Object.defineProperty，基于 Proxy 的观察者机制探索面试官: 实现双向绑定Proxy比defineproperty优劣如何?记一次思否问答的问题思考：Vue为什么不能检测数组变动ProxyMDN-ReflectECMAScript 6 入门-Reflect"},{"title":"todo","subtitle":"待办列表","date":"2019-01-16","updated":"2019-05-15","path":"todo/","link":"","text":"TODO日常TODO ssh + github 工作原理 文章 base64 IIFE 验证微信小程序的 hidden 问题 js 位运算 js 数组常用函数 unicode-utf8 微信小程序页面生命周期及 navigate，参考 js按值传递 AST 语法树 CommonJS-seaJS AMD-CMD Object.defineProperty() DOM级别 服务器搭建 https 浏览器原生表单验证 ES6 新数据类型 toFixed() 精度问题, 银行家舍入算法 input 事件顺序 docker async-promise-generator Redux 源码 requestAnimatinoFrame() CSRF 获取元素位置及大小 js继承 vue flux 微信小程序源码分析"},{"title":"SASS","subtitle":"SASS","date":"2018-11-28","updated":"2018-11-28","path":"SASS/","link":"","text":"SASS 笔记以前使用 SASS 都比较浅显, 正好最近写的多了, 所以记录一下笔记.何为 SASS"},{"title":"http-2.0","subtitle":"HTTP/2.0 笔记","date":"2018-11-16","updated":"2018-11-19","path":"http-2-0/","link":"","text":"关于 HTTP/2.0最近折腾了一段时间的 HTTP/2.0, 目前来说国内外很多大厂都已经用上了 HTTP/2.0, 部署起来也很容易, 这里关于协议的一些细节及部署过程做一个记录.主要参考的是屈屈的博客 HTTP/2.0 系列文章: HTTP/2 资料汇总SPDY 和 HTTP/2.0在 HTTP/2.0 标准正式推出之前, google 先实验性的推出了新的传输层协议 SPDY, 由于 SPDY 表现优异, 于是 google 慷慨的把这个协议提交到了 IETF, 之后 IETF 对这个标准进行了进一步的完善, 也改名叫做 HTTP/2.0. 所以你可以把 SPDY 看做 HTTP/2.0 的前身, 随着 HTTP/2.0 的正式标准化, SPDY 也就完成了它的历史使命, 逐渐在退出历史舞台.我们之前大多数使用的都是 HTTP/1.1, 那么在服务器和客户端交互的时候应该如何恰当的升级通信协议呢?首先 SPDY 是基于 SSL/TLS 的(也就是说如果要使用 SPDY, 那么就必须部署 HTTPS), 当服务器和浏览器在通过三次握手建立 TCP 连接之后, 下一步就要协商 SSL/TLS 加密协议的细节(版本, 算法和加密套件等), 在这个协商过程中就把 SPDY 协议的协商过程也加进去了, 为了协商 SPDY 协议谷歌开发了一个名为下一代协议协商Next Protocol Negotiation(NPN)的 SSL/TLS 扩展，用于在客户端连接服务器时协商是否采用 SPDY 协议。SPDY 协议是由 Web 服务器所实现支持的，而 NPN 则是由 OpenSSL 等 SSL 实现支持的。由 SPDY 标准之后的 HTTP/2.0 协议在协商的过程也发生了一些变化, 由原来的 NPN 变为了应用层协议协商Application-Layer Protocol Negotiation(ALPN), 他们的作用是相同的, 都是为了在建立连接的时候进行协议协商以便能够升级到 SPDY 或者 HTTP/2.0. 但是他们的做法有所不同而且是不兼容的, 但是NPN 和 ALPN 可以并存，但是会客户端会优先选择 ALPN在协商协议的时候, NPN 是服务器发送所支持的协议列表，由客户端进行选择。而 ALPN 则是客户端发送该列表，由服务端选择.在 NPN 中，最终的选择结果是在 Change Cipher Spec 之后发送给服务端的，也就是说是被加密了的。而在 ALPN 中，所有的协商都是明文的.目前的问题是NPN 已经广泛地被 OpenSSL 支持，而 ALPN 则目前只有最新的 openssl-1.0.2 才支持, 而我们目前使用的几个主流 Linux 发行版的 OpenSSL 版本都还不支持 ALPN, 而同时这个 OpenSSL 是系统相当低层的库, 被众多的其他软件所依赖, 一般情况下没有谁会去升级这个库.所以在之前很多网站想要享受更加优秀的网站加载速度采用的都是 SPDY 协议, 可是自从 Chrome 51 开始, 谷歌就去掉了对 SPDY 和对 NPN 的支持, 也就是说在这之后浏览器将无法使用 NPN 来和服务器协商进行协议的升级, 所以如果你的 Web 服务器使用的是 openssl-1.0.2 以下的版本，不支持 ALPN 协商，那么 Chrome 51 及以后版本就会以 HTTP/1 协议访问你的网站(当然其它的浏览器就不是这样了)。"},{"title":"yahoo-best-practices-for-speeding-up-your-Web-Site","subtitle":"yahoo 关于网站速度优化的军规","date":"2018-11-15","updated":"2018-11-15","path":"yahoo-best-practices-for-speeding-up-your-Web-Site/","link":"","text":"yahoo 的网站优化实践军规yahoo 的网站优化军规已经出来很多年了, 我是最近才看到, 然后做一下笔记, 也比对一下自己现在做的怎么样.原文地址: Best Practices for Speeding Up Your Web Site掘金上也有不少好文章来详细阐述的: 前端性能优化之雅虎35条军规减少 HTTP 请求使用 CDN添加Expires或者Cache-Control缓存控制头对除了图片和 PDF 这类文件以外的文件(如 CSS, JS, 或者 application/json等)使用 Gzip样式放在头部脚本放在底部避免使用 CSS 表达式脚本和样式使用外链形式减少 DNS 查询压缩脚本和样式文件避免重定向移除重复的脚本配置 ETags缓存 Ajax 数据尽早刷新缓冲区Ajax 尽量使用 GET 方式延迟加载暂时不必要的资源预先加载可能用到的资源减少页面 DOM 元素数量资源分散到不同的域上减少 iframes 的数量避免404减少 cookie 大小把资源部署到不用发送 cookie 的域上减少访问 DOM 的次数合适处理事件绑定使用&lt;link&gt;而不是@importCSS 中避免使用 AlphaImageLoader优化及压缩图片优化 CSS 雪碧图选用尺寸刚好合适的图片, 不要缩放使用使用小的 favicon, 同时注意缓存该文件文件大小不要超过25k(这一条目前来说可能过时了, 后期查证)把多个文件合并成一个文件, 减少 HTTP 数量避免空src的img"},{"title":"nginx","subtitle":"nginx 部署及配置笔记","date":"2018-11-08","updated":"2018-11-12","path":"nginx/","link":"","text":"nginx 的部署与配置笔记现在很多网站用的都是 nginx 作为代理服务器, 所以为了进行 web 性能的优化, 自然也要折腾一下 nginx 的配置的.我的远程主机环境:# linux 通用查看系统版本lsb_release -a# LSB Version: :core-4.1-amd64:core-4.1-noarch# Distributor ID: CentOS# Description: CentOS Linux release 7.4.1708 (Core)# Release: 7.4.1708# Codename: Corenginx 的安装参考文章: nginx服务器详细安装过程（使用yum 和 源码包两种安装方式，并说明其区别）安装 nginx 前要先安装 nginx 编译及运行的依赖环境# yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-develnginx 一般来说有两种安装方式: yum安装和源码包自行编译安装, 新手推荐前一种, 想折腾的话或者老手使用后一种yum安装是在线安装, 好处是简单方便, 不易出错, 但是缺点是使用的其实是别人编译好的二进制版本, 不能自定义其中加载的模块, 不过目前来 centos 官方提供的那个版本还是比较实用的# 首先把 nginx 的源加载 yum 里面vi /etc/yum.repo.d/nginx.repo然后在文件里添加如下内容[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1然后就可以使用yum install nginx安装最新版了, 也可以yum install nginx-1.6.3安装指定版本.安装之后可以使用rpm -ql nginx查看安装目录, 卸载时使用rpm -e nginx, 如果因为依赖包导致卸载失败，可以尝试rpm -e --nodeps nginx来卸载，这个命令相当于强制卸载，不考虑依赖问题。使用这种方式安装之后 nginx 会被自动添加到系统服务里面, 也就是说可以直接使用serivce nginx {option}来启动或者关闭 nginx.源码包编译安装, 好处是编译的时候是根据你本机的条件和环境进行编译的, 性能更好一些,同时也可以在编译的时候自定义模块# 可以获取指定版本的 nginx, 可以使用 -P 指定下载目录wget -c &lt;-P&gt; &lt;destDir&gt; https://nginx.org/download/nginx-1.11.6.tar.gz# 然后解压下载的压缩包, 可以使用 -C 指定解压目录tar -zxvf nginx-1.11.6.tar.gz &lt;-C&gt; &lt;destDir&gt;# 然后进行解压后的目录cd nginx-1.11.6# 然后先进行编译配置, 直接使用 ./configure 表示使用默认配置, 也可以在后面附加参数表示一些其他的模块之类的, 请具体根据使用来配置./configure# 然后进行编译安装make &amp;&amp; make install一般来说编译安装后的二进制文件都在/usr/local/目录下, 如果需要卸载的话直接在这里删除对应的目录就可以, 同时启动 nginx 也可以在这里使用二进制文件直接启动, 见下文 nginx 的使用.使用源码包编译安装的好处是是可以后期为 nginx 添加各种各样的模块.比如我在第一次安装的并没有安装 SSL 相关的模块, 后期我想开启 SSL, 这个时候就需要给 nginx 添加ngx_http_ssl_module模块.注意在添加的时候为了保留之前的一些配置, 我们需要先查看之前编译的configure配置项, 你可以使用./nginx -V来查看, 我的输出如下:nginx version: nginx/1.15.2built by gcc 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)configure arguments: --prefix=/usr/local/nginx可以看到我的版本是1.15.2, 我之前的编译参数是--prefix=/usr/local/nginx, 也就是只制定了 nginx 的配置文件路径, 那么我现在需要在原来的基础上添加新的参数--with-http_ssl_module才能编译一个新的带有 SSL 模块的 nginx 二进制文件.找到原来的源码包, 没有的话就下载一个跟你现在用的是同一个版本的 nginx 源码包, 然后解压, 进入解压后的目录在解压后的目录执行编译前的配置./configure --prefix=/usr/local/nginx --with-http_ssl_module, 注意这里一定要把你原来的参数都拷贝过来, 然后在后面添加新的, 要不然编译出来的东西可能跟你原来的不兼容接下来执行make, 这里可千万别手快执行make &amp;&amp; make install, 如果你insall了那么你之前的 nginx 的配就都丢了, 所以我们这里只需要编译出一个可用的 nginx 的二进制版本, 然后手动替换掉原来的即可.新编译的 nginx 文件在 objs/nginx# 将原来的`/usr/local/nginx/sbin/nginx`备份cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.back# 请先停止 nginx 服务, 然后再删除原来的 nginx 文件rm -f /usr/local/nginx/sbin/nginx# 把新的 nginx 文件拷贝到原来的地方cp objs/nginx /usr/local/nginx/sbin/nginx然后再正常启动 nginx 即可使得新的功能生效nginx 的使用有两种方式启动 nginx, 但是后一种相对来说方便一些, 推荐使用.直接在安装目录使用 nginx 的命令进行 nginx 的启动和关闭# 启动/usr/local/nginx/sbin/nginx# 检查默认配置文件/usr/nginx/sbin/nginx -t# 检查指定配置文件/usr/nginx/sbin/nginx -t -c &#123;configFileDir&#125;# 使用指定配置文件启动 nginx/usr/nginx/sbin/nginx -c &#123;configFileDir&#125;# 关闭 stop 表示立即停止, quit 表示平滑停止, reopen 表示重新启动 reload 不中断服务重新加载配置文件/usr/local/nginx/sbin/nginx -s &#123;stop|quit|reload|reopen&#125;# 通过进程查看及关闭 nginxps -ef | grep nginx# 从容停止Nginx：kill -QUIT 主进程号# 快速停止Nginx：kill -TERM 主进程号# 强制停止Nginx：kill -9 nginx配置 nginx 的启动和关闭到系统服务在/etc/init.d/目录下新建文件nginx, 把这些内容拷贝到文件中赋予脚本可执行权限chmod +x /etc/init.d/nginx修改系统服务之后使用systemctl daemon-reload重新加载一下才能生效可以吧 nginx 服务配置成开机启动 chkconfig nginx on有如下命令可执行:service nginx &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;# 参数说明# start 启动 nginx# stop 停止 nginx# status 查看 nginx 的状态# restart 重启 nginx, 会先中断 nginx, 然后重新启动, 如果配置文件有误, 那么将无法启动 nginx# reload 重新加载配置文件, 不会中断 nginx 服务, 如果新的配置文件有误, 那么会使用上一次正确的配置文件, 保证服务正常运行# configtest 检查配置文件是否正确nginx 的配置nginx 的配置相对来说是比较繁杂的, 所以我放到最下面来说, 后期持续补充.参考文档: nginx服务器安装及配置文件详解gzip压缩功能设置gzip 相关配置可放在 http{} 或 server{} 或 location{} 层级，若不同层级有重复设置优先级为 location{} &gt; server{} &gt; http{}gzip 配置参数如下# 打开 gzip 压缩gzip on;# 进行压缩的最小文件大小, 小于这个大小的不进行压缩gzip_min_length 1k;# 压缩结果数据流存储所用空间，下面表示以16k为单位，按照原始数据大小以16k为单位的4倍申请内存。默认值是申请跟原始数据相同大小的内存空间去存储gzip压缩结果。gzip_buffers 4 16k;# 采用http协议版本 默认是1.1 ，对于1.0的请求不会压缩，如果设置成1.0，表示http1.0以上 的版本都会压缩。(如果使用了 proxy_pass 进行反向代理，那么nginx和后端的 upstream server之间默认是用 HTTP/1.0协议通信的。)gzip_http_version 1.0;# 压缩级别（1~9，一般为平衡文件大小和CPU使用，5是常用值，当然跟实际机器的情况有关） 级别越高, 压缩比越大, 但是 cpu 的性能消耗也越高, 同时在压缩到一定程度之后即使再进行压缩文件体积也不会再有明显的减小了. 一般取值在4~6, 这里有一组测试数据; text/html - phpinfo():; 0 55.38 KiB (100.00% of original size); 1 11.22 KiB ( 20.26% of original size); 2 10.89 KiB ( 19.66% of original size); 3 10.60 KiB ( 19.14% of original size); 4 10.17 KiB ( 18.36% of original size); 5 9.79 KiB ( 17.68% of original size); 6 9.62 KiB ( 17.37% of original size); 7 9.50 KiB ( 17.15% of original size); 8 9.45 KiB ( 17.06% of original size); 9 9.44 KiB ( 17.05% of original size); application/x-javascript - jQuery 1.8.3 (Uncompressed):; 0 261.46 KiB (100.00% of original size); 1 95.01 KiB ( 36.34% of original size); 2 90.60 KiB ( 34.65% of original size); 3 87.16 KiB ( 33.36% of original size); 4 81.89 KiB ( 31.32% of original size); 5 79.33 KiB ( 30.34% of original size); 6 78.04 KiB ( 29.85% of original size); 7 77.85 KiB ( 29.78% of original size); 8 77.74 KiB ( 29.73% of original size); 9 77.75 KiB ( 29.74% of original size)gzip_comp_level 5;# 压缩文件类型（默认总是压缩 text/html类型，其中特别说明的是application/javascript和text/javascript最好都加上，若页面script标签的type不同则有可能发生部分js文件不会压缩，默认type为application/javascript） 一般来说对图片不进行压缩, 因为图片压缩比较耗时而且压缩比也很低gzip_types application/atom+xml application/javascript application/json application/rss+xml application/vnd.ms-fontobject application/x-font-ttf application/x-web-app-manifest+json application/xhtml+xml application/xml font/opentype image/svg+xml image/x-icon text/css text/plain text/javascript text/x-component;# 代表缓存压缩和原始版本资源，避免客户端因Accept-Encoding不支持gzip而发生错误的现象（现在一般都采用gzip） 开启此参数以后会在返回头里面看到一个 Vary 字段, 里面会有一个 Accept-Encoding 字段, 代表此资源有着多个版本, 比如 gzip 压缩版 和不压缩版, 关于 Vary 字段的解释可以查看这里: https://imququ.com/post/vary-header-in-http.htmlgzip_vary on;# 禁止IE6进行gzip压缩（当然现在已经基本没有人使用IE6了）gzip_disable &quot;MSIE [1-6]&quot;;参考文章:Nginx配置指北之gzipHTTPS 配置如果要启用 nginx 的 SSL 配置, 那么需要 nginx 安装的时候包含了http_ssl_module模块, 默认 nginx 是不会安装这个模块的, 可以使用./nginx -V查看 nginx 安装时的配置参数里面有没有这个模块, 如果没有这个模块, 那么我们可以按照上面编译安装的步骤编译一个新的包含这个模块的 nginx 二进制文件, 然后替换掉现在的即可. 然后在 server{} 层级中加入如下配置(请根据自己情况修改)详细配置说明可以查看Nginx 配置 HTTPS 服务器# 网站域名server_name example.com# 表示监听 443 端口, 协议为 ssllisten 443 ssl;# 证书文件的位置ssl_certificate example.com.crt;# 证书私钥文件的位置ssl_certificate_key example.com.key;# SSL 协议具体版本ssl_protocols TLSv1 TLSv1.1 TLSv1.2;# SSL 算法ssl_ciphers HIGH:!aNULL:!MD5;上面的配置是必须的, 另外还有一些配置依据个人情况可以添加. 另外你需要首先申请自己的网站证书才行.例如安全协议的具体版本ssl_protocols和算法ssl_ciphers, 由于这两个命令的默认值已经好几次发生了改变，因此不建议显性定义，除非有需要额外定义的值，如定义 D-H 算法, 具体查看Nginx 配置 HTTPS 服务器进行配置.HTTP/2.0 配置既然已经上了 HTTPS, 那么干脆一鼓作气上到 HTTP/2.0, 根据规范来说 HTTP/2.0 是不需要依赖 HTTPS 的, 但是目前的现状来说, 各个浏览器都是要求在 HTTPS 的环境中才能启用 HTTP/2.0. nginx 要启用 HTTP/2.0 需要http_v2_module和http_ssl_module这两个模块, 如果之前的编译安装时没有这两个模块, 那么就需要重新加上参数再编译一份. 这里省略我再次编译的过程(同上), 只是编译参数改为./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module.更新了 nginx 之后就要在 nginx 的配置文件里面开启 HTTP/2.0, 告诉客户端我们支持 HTTP/2.0 了. 配置很简单, 只需要在之前的listen字段中增加一个http2即可.目前 IE11+ 以及其他主流浏览器都已经支持 HTTP/2.0, 而且就算客户端不支持结果也是正常的使用现在的 HTTP/1.1, 不会影响页面访问.例如:# 改为listen 443 ssl http2;这里有一个小坑, 在启用 HTTP/2.0 之前, 我们可能把80端口和443端口放在同一个 server 里面监听, 但是如果我们想要启用 HTTP/2.0, 那么就必须把80端口拿出去单独放在一个 server 里面, 监听80端口的并不能启用 HTTP/2.0, 所以如果你想要为网站同时启用 HTTP 和 HTTP/2.0, 那么你在 nginx 配置文件里面就至少需要写两个 server, 一个监听80端口, 另一个监听443端口.关于 HTTP/2.0 的相关文章, 尤其是升级及浏览器兼容问题可以查看屈屈的博客谈谈 HTTP/2 的协议协商机制.我自己的总结如下: 在浏览器和服务端建立 TCP 连接之后, 如果是 http 协议, 那么此时就可以进行数据传输了, 如果是 https 协议, 那么就还需要建立安全的 TLS 连接, 由于 TLS 有多个版本, 也有不同的加密算法, 那么浏览器和服务器就需要进行协商, 确定一个版本和算法等信息来进行数据加密, 协商是通过握手来实现的, 首先客户端会发送一个client hello握手信息, 里面包含了客户端支持的各种协议以及算法等信息, 然后服务端收到这个信息之后会在这些支持的协议里面选出自己也支持的协议和算法, 然后确定最后要采用的协议和算法(例如 HTTP/2.0 &gt; HTTP/1.1)通过server hello握手信息返给客户端, 这样双方就确定了一组对应的协议和算法进行后续的数据传输. 所以可以看到服务器在升级到了 HTTP/2.0 之后, 如果用户使用的浏览器也支持 HTTP/2.0, 那么协商之后双方就会无痛升级到 HTTP/2.0 进行通信, 享受 HTTP/2.0 带来的种种好处, 而如果用户的浏览器不支持 HTTP/2.0, 那么协商之后就会采用原来的 HTTP/1.1进行通信, 并不会影响现在的业务."},{"title":"length-of-url","subtitle":"关于URL长度的笔记","date":"2018-11-07","updated":"2018-11-07","path":"length-of-url/","link":"","text":"关于URL长度的笔记在了解 cookie 的大小限制的时候看到了一片记录关于 URL 长度的博客, 所以收藏了下来.原文: GET传参最大长度的理解误区作者: zhongxia为防止原文丢失, 这里直接转载一份.GET传参最大长度的理解误区时间：2016-10-17 14:59:38作者：zhongxia零、总结文章数据来源于网络，可能存在变动，但是原理是一样的。HTTP 协议 未规定 GET 和POST的长度限制GET的最大长度显示是因为 浏览器和 web服务器限制了 URI的长度不同的浏览器和WEB服务器，限制的最大长度不一样要支持IE，则最大长度为2083byte，若只支持Chrome，则最大长度 8182byte一、误解大家都知道http 中 存在 GET 和 POST 这两种最常用的请求方式。（PUT，DELETE不在本文讨论范围之内）误解：HTTP 协议下的 Get 请求参数长度是有大小限制的，最大不能超过XX，而 Post 是无限制的。1、首先即使有长度限制，也是限制的是整个 URI 长度，而不仅仅是你的参数值数据长度。2、HTTP 协议从未规定 GET/POST 的请求长度限制是多少。以下内容摘自 《关于 HTTP GET/POST 请求参数长度最大值的一个理解误区》， 文章时间为 2013年的。可能以当前最新的浏览器有出入The HTTP protocol does not place any a priori limit on the length of a URI. Servers MUST be able to handle the URI of any resource they serve, and SHOULD be able to handle URIs of unbounded length if they provide GET-based forms that could generate such URIs. A server SHOULD return 414 (Request-URI Too Long) status if a URI is longer than the server can handle (see section 10.4.15).Note: Servers ought to be cautious about depending on URI lengths above 255 bytes, because some older client or proxy implementations might not properly support these lengths.3、所谓的请求长度限制是由浏览器和 web 服务器决定和设置的，各种浏览器和 web 服务器的设定均不一样，这依赖于各个浏览器厂家的规定或者可以根据 web 服务器的处理能力来设定。The limit is in MSIE and Safari about 2KB, in Opera about 4KB and in Firefox about 8KB, (255 bytes if we count very old browsers) . We may thus assume that 8KB is the maximum possible length and that 2KB is a more affordable length to rely on at the server side and that 255 bytes is the safest length to assume that the entire URL will come in.If the limit is exceeded in either the browser or the server, most will just truncate the characters outside the limit without any warning. Some servers however may send a HTTP 414 error. If you need to send large data, then better use POST instead of GET. Its limit is much higher, but more dependent on the server used than the client. Usually up to around 2GB is allowed by the average webserver. This is also configureable somewhere in the server settings. The average server will display a server-specific error/exception when the POST limit is exceeded, usually as HTTP 500 error.IE 和 Safari 浏览器 限制 2kOpera 限制4kFirefox 限制 8k（非常老的版本 256byte）如果超出了最大长度，大部分的服务器直接截断，也有一些服务器会报414错误。HTTP 1.1 defines Status Code 414 Request-URI Too Long for the cases where a server-defined limit is reached. You can see further details on RFC 2616. For the case of client-defined limits, there is no sense on the server returning something, because the server won’t receive the request at all.详细可以看 RFC2616The server is refusing to service the request because the Request-URI is longer than the server is willing to interpret. This rare condition is only likely to occur when a client has improperly converted a POST request to a GET request with long query information, when the client has descended into a URI “black hole” of redirection (e.g., a redirected URI prefix that points to a suffix of itself), or when the server is under attack by a client attempting to exploit security holes present in some servers using fixed-length buffers for reading or manipulating the Request-URI.二、各个浏览器和web服务器的最大长度总结以下内容摘自《GET请求中URL的最大长度限制总结》， 文章内容是 2016年9月，相对比较符合当前的最新现状。在网上查询之后，浏览器和服务器对url长度都有限制，现总结如下。浏览器1、IEIE浏览器（Microsoft Internet Explorer） 对url长度限制是2083（2K+53），超过这个限制，则自动截断（若是form提交则提交按钮不起作用）。2、firefoxfirefox（火狐浏览器）的url长度限制为 65 536字符，但实际上有效的URL最大长度不少于100,000个字符。3、chromechrome（谷歌）的url长度限制超过8182个字符返回本文开头时列出的错误。4、SafariSafari的url长度限制至少为 80 000 字符。5、OperaOpera 浏览器的url长度限制为190 000 字符。Opera 9 地址栏中输入190 000字符时依然能正常编辑。服务器1、ApacheApache能接受url长度限制为8 192 字符2、IISMicrosoft Internet Information Server(IIS)能接受url长度限制为16 384个字符。这个是可以通过修改的（IIS7）configuration/system.webServer/security/requestFiltering/requestLimits@maxQueryStringsetting.&lt;requestLimits maxQueryString=&quot;length&quot;/&gt;3、Perl HTTP::DaemonPerl HTTP::Daemon 至少可以接受url长度限制为8000字符。Perl HTTP::Daemon中限制HTTP request headers的总长度不超过16 384字节(不包括post,file uploads等)。但当url超过8000字符时会返回413错误。这个限制可以被修改，在Daemon.pm查找16×1024并更改成更大的值。4、ngnix可以通过修改配置来改变url请求串的url长度限制。client_header_buffer_size 默认值：client_header_buffer_size 1klarge_client_header_buffers默认值 ：large_client_header_buffers 4 4k/8k由于jsonp跨域请求只能通过get请求，url长度根据浏览器及服务器的不同而有不同限制。若要支持IE的话，url长度限制为2083字符，若是中文字符的话只有2083/9=231个字符。若是Chrome浏览器支持的最大中文字符只有8182/9=909个。三、参考文章GET请求中URL的最大长度限制总结关于 HTTP GET/POST 请求参数长度最大值的一个理解误区"},{"title":"service-worker","subtitle":"service-woerker","date":"2018-11-04","updated":"2018-11-13","path":"service-worker/","link":"","text":"service-workerservice worker (服务工作线程)可以为网页提供离线访问的功能, 除此之外当然也有推送通知和后台同步的功能, 它是一种 JavaScript 线程, 可以独立在主线程外独立运行, 但是无法直接访问和操作 DOM , 服务工作线程通过响应 postMessage 接口发送的消息来与其控制的页面通信, 页面可在必要时对 DOM 执行操作.使用前提网站必须是 https 的, 本地开发的话也可以使用 localhost 和 127.0.0.1兼容性目前来说 IE 系列都不支持, Edge 从17开始支持, 其他PC段浏览器基本都没有太大问题, 移动端 IOS Safari 从11.4开始支持, 安卓浏览器从67(发布于2017.03)开始支持, QQ和UC等都已经支持. 一般来说在注册 service worker 之前可以先通过&#39;serviceWorker&#39; in navigator检查一下是否支持, 不支持则不进行注册.注册 service worker如果在页面加载完成之前就直接注册 service worker, 会影响到页面的加载过程, 所以推荐的做法是在load事件里面去注册if ('serviceWorker' in navigator) &#123; window.addEventListener('load', function() &#123; navigator.serviceWorker.register('/sw.js').then(function(registration) &#123; // Registration was successful console.log('ServiceWorker registration successful with scope: ', registration.scope); &#125;).catch(function(err) &#123; // registration failed :( console.log('ServiceWorker registration failed: ', err); &#125;); &#125;);&#125;需要注意的是 service worker 文件的位置决定了这个它能控制的页面和请求范围, 最多只能控制到本目录, 可以通过scope参数指定目录, 但是也不能高于所在目录, 所以经常会把这个文件直接放在根目录, 这样就可以控制到整个域下面的文件和请求.chrome 里面可以通过chrome://serviceworker-internals来查看已经开启的 service worker, 在控制台的 Application 里的 Servie Worker 也可以查看.安装 service worker页面在注册了 service worker 之后就可以到下一个生命周期install, 一般在这个生命周期里进行一些文件的缓存, 有如下三个过程:打开缓存缓存文件确认所需文件是否全部缓存成功const CACHE_NAME = 'my-site-cache-v1';const urlsToCache = [ '/', '/styles/main.css', '/script/main.js'];self.addEventListener('install', evt =&gt; &#123; // Perform install steps evt.waitUntil( caches.open(CACHE_NAME) .then(cache =&gt; &#123; console.log('Opened cache'); return cache.addAll(urlsToCache); &#125;) );&#125;);caches.open()用来打开一个特定名称的缓存, 你可以理解为名称空间, 将要被缓存的文件都会被存在这个空间里面.cache.addAll()用来缓存一个 url 列表的所有文件, 它会根据 url 创建对应的 request, 如果本地没有这个请求对应的 response, 那么就会发起请求拿到对应的 response, 然后以 requst 为键名, 对应的 response 为键值, 对响应数据进行缓存. 添加单个缓存 url 可使用cache.add().event.waitUntil()用来延长一个事件的生命周期, 例如在上面的调用中, 它延迟将被安装的worker视为 installing ，直到传递的 Promise 被成功地resolve. 这主要用于确保：服务工作线程在所有依赖的核心cache被缓存之前都不会被安装. 如果有文件缓存失败, 那么本次安装就会失败, 之后会自动重试.激活 service worker当一个 service worker 被安装了以后在生命时间进入激活(activate)状态呢? 一般来说如果是首次加载此页面, 那么在安装install完成以后就会进入激活状态, 但是如果此页面之前被旧的 service worker 控制, 那么新的 service worker 会进入waiting状态, 等到此页面被关闭然后被重新打开的时候, 新的 servie worker 才会接管这个页面, 你也可以使用skipWaiting()使得新的 service worker 跳过waiting状态, 直接进入activate状态, 当新的 servie worker 进入activate状态以后, 如果页面是在新的 service worker 被激活之前就加载了的, 那么这个页面的请求仍然还不受 service worker 控制, 如果你希望之前打开或加载的页面也能收到新的 servie worker控制, 一种方式是你可以使用clients.claim()来使得新的 servie worker 控制还未受控制的页面, 另一种方式就是关闭并重新打开页面, 注意如果只是刷新本页面, 那么本页面仍然还是受原来的 service worker 控制的.通过navigator.serviceWorker.controller(其将为null或一个服务工作线程实例)检测客户端是否受控制缓存 fetch当 service worker 被安装以后, service worker 就可以拦截 fetch 请求, 可以在这个时候返回缓存中的数据, 如果没有对应的缓存的话, 你可以手动发起这个请求, 然后将请求的结果返回给页面, 这里的作用相当于一个网络代理.self.addEventListener('fetch', function(event) &#123; event.respondWith( caches.match(event.request) .then(function(response) &#123; // Cache hit - return response if (response) &#123; return response; &#125; // IMPORTANT: Clone the request. A request is a stream and // can only be consumed once. Since we are consuming this // once by cache and once by the browser for fetch, we need // to clone the response. var fetchRequest = event.request.clone(); return fetch(fetchRequest).then( function(response) &#123; // Check if we received a valid response if(!response || response.status !== 200 || response.type !== 'basic') &#123; return response; &#125; // IMPORTANT: Clone the response. A response is a stream // and because we want the browser to consume the response // as well as the cache consuming the response, we need // to clone it so we have two streams. var responseToCache = response.clone(); caches.open(CACHE_NAME) .then(function(cache) &#123; cache.put(event.request, responseToCache); &#125;); return response; &#125; ); &#125;) );&#125;);对所有的 fetch 请求进行拦截, 然后在缓存中搜索这个 request, 如果找到了, 那么就直接返回之前缓存的对应的 response, 如果没有找到, 那么就需要手动发起一个同样的请求, 注意 resquest 和 response 都是流对象, 只能读取一次, 所以在上面的代码中需要复制clone()这个流一份, 然后才能再次使用, 当获得返回数据的时候, 判断是正常响应的数据 status === 200然后就把这个数据缓存一份备用, 同时这个数据也会给浏览器一份作为响应.更新 service worker页面每次加载时都会下载一份 service worker 文件然后和以前的作对比, 如果发现不一样, 那么就会安装新的 service worker, 同时旧的不会被马上删除, 而是可以继续控制它已经控制的页面, 只是新打开的页面会被新的 service worker 接管, 当旧的页面全部都被关闭的时候, 旧的 service worker 就全面失效了, 新的 service worker 就是唯一的控制者了. 那么在新旧交替的一个时间, 新的 service worker 虽然已经安装完成, 且触发了 install 事件, 但是在旧的页面上会处于 waiting 状态, 如果希望新的 service worker 能够在安装后马上生效, 那么可以使用skipWaiting()来跳过 waiting 状态, 直接进入 activate 状态.更新缓存有时候我们希望能够更新缓存, 让页面能够取到最新的数据.手动更新缓存的方法self.addEventListener('activate', function(event) &#123; var cacheWhitelist = ['pages-cache-v1', 'blog-posts-cache-v1']; event.waitUntil( caches.keys().then(function(cacheNames) &#123; return Promise.all( cacheNames.map(function(cacheName) &#123; if (cacheWhitelist.indexOf(cacheName) === -1) &#123; return caches.delete(cacheName); &#125; &#125;) ); &#125;) );&#125;);我们可以在 service worker 处于 activate 状态之后设置一份白名单, 然后遍历缓存, 凡是不是这个白名单里面的缓存都删除掉, 那就可以起到手动更新缓存的作用.三大特性研究参考文章: 【PWA学习与实践】(8)使用Service Worker进行后台同步 - Background Sync资源请求(fetch)这一点在上面的文件和请求缓存里面已经涉及到了.推送通知(push)推动通知(push)依赖Notification API和PUSH API, 目前来说这两个 API 的兼容性也不容乐观, 基本没法实用, 所以暂时不做多的讨论. 如果想要了解更多, 请查看上面的那篇文章.后台同步(sync)后台同步(sync)依赖于Background Sync API, 目前来说这个 API 的兼容惨不忍睹, 几乎只有 chrome 自家的产品支持. 所以在目前的阶段, 暂时不多去讨论后台同步这个部分. 可以查看上面那篇文章了解更多.参考文档服务工作线程"},{"title":"web-font","subtitle":"网页字体加载过程及优化","date":"2018-11-01","updated":"2018-11-12","path":"web-font/","link":"","text":"网页字体加载过程及优化现在很多网站为了视觉效果都在使用在线字体, 系统自带的字体可以直接使用, 但是自定义的在线字体需要通过@font-face来加载. 这里主要结合我自己的博客的实践来记录一下网页字体的加载过程及优化.在线字体格式目前来说有如下四种字体格式, WOFF, SVG, EOT和OTF/TTF, 兼容性可以在caniuse上面关注最新的情况WOFFWOFF全称是”Web Open Font Format”, 这种字体专门用于网络, 是由 Mozilla 与 Type Supply, LettError 及其他组织协同开发的一种网页字体格式, 使用了OpenType (OTF)和TrueType (TTF)字体里的存储结构和压缩算法, 所以在传输的时候可以节省带宽, 加载更快, 目前兼容性来说, IE9+以及其他绝大部分浏览器都可以使用, 是现在的大潮流, 推荐使用这种字体OTF/TTF全称是”OpenType Font”和”TrueType Font”, 是Windows 和 Mac 系统最常用的字体格式, 不过容易被非法复制, 目前的支持情况来说IE9+以上是部分支持, 其余的主流浏览器都没问题.SVGSVG全称是”Scalable Vector Graphics”, 是一种用矢量图格式改进的字体格式，体积上比矢量图更小. 兼容性极差, 基本上只有safari系列支持EOT微软自家开发的字体, 也只有IE全系列支持, 连Edge都不支持关于字体的编辑推荐一个在线工具FontEditor, 十分好用, 可以删除或者添加字体里面的字符集, 包括多个字体文件合成一个字体, 我目前就是把我博客中使用的Roboto Mono字体和Iconfont字体合成了一个字体文件, 同时删除了Roboto Mono中ASCII码字符集以外的字体, 因为我只用这个字体来渲染代码中出现的英文和数字等, 不需要其他的字符, 字体文件大小从原来的110k直接缩小成了18k.@font-face@font-face格式:/* 完整格式, 不过我们日常使用时可能只会涉及到其中少数几个 */@font-face &#123; [ font-family: &lt;family-name&gt;; ] || [ src: &lt;src&gt;; ] || [ unicode-range: &lt;unicode-range&gt;; ] || [ font-variant: &lt;font-variant&gt;; ] || [ font-feature-settings: &lt;font-feature-settings&gt;; ] || [ font-variation-settings: &lt;font-variation-settings&gt;; ] || [ font-stretch: &lt;font-stretch&gt;; ] || [ font-weight: &lt;font-weight&gt;; ] || [ font-style: &lt;font-style&gt;; ] [ font-daipsy: &lt;font-display&gt;;]&#125;/* 例如, src 中可以使用 local 加载本地计算机的字体, url 用来加载在线的字体(注意跨域问题), 指定 format 可以帮助浏览器更快解析字体 可选 format 有 【truetype(.ttf)、opentype（.otf）、truetype-aat、embedded-opentype(.eot)、svg(.svg)、woff(.woff)】 */@font-face &#123; font-family: MyHelvetica; src: local(\"Helvetica Neue Bold\"), local(\"HelveticaNeue-Bold\"), url(MgOpenModernaBold.ttf) format('turetype'); font-weight: bold;&#125;在css中使用@font-face定义字体, 当浏览器在解析到这一行css时并不会马上去下载这个字体, 而是会继续解析建立DOM树和CSSOM树, 只有当DOM树和CSSOM树结合生成渲染树的时候浏览器会进行一个判断, 如果在渲染树中存在一个会被渲染出来的节点(也就是display不能为none, 见下面”什么样的节点不会出现在渲染树中”)使用了这个字体, 那么浏览器在这个时候才会开始下载这个字体, 至于字体什么时候下载完毕那就不一定了, 同时渲染过程并不会被这个下载过程给阻塞, 那么在此时不确定所需字体是否加载完毕的时候该如何处理采用了这个字体的文字呢?什么样的节点不会出现在渲染树中只有display:none的节点不会出现在渲染树中, 而其他的例如visibility:hidden;或者opacity:0;都是会出现在渲染树中的, 因为后面的几种情况虽然也是元素在页面不可见, 但是会在页面上占据它自己的空间, 这会影响到页面的布局, 同时这样的元素中的字体的大小和样式是会影响这个元素所占据的空间的大小的(例如span元素等的大小是被字体撑开的), 所以这样的元素中的字体当然是会被加载的, 因为浏览器要根据元素占据的空间大小去布局.由此引发出了三种解决方案FOUT, FOIT和FOIT 3S, 浏览器采取哪一种根据浏览器不同也有差异, 不过好消息是除了IE和Edge以外(对我来说基本是不考虑IE系列的…)的chrome, firefox, safari和opera都采用了第三种方案FOIT 3S. 下面简单介绍一下三种方案:FOUT(Flash of Unstyled Text)当我们在 @font-face 中按优先级顺序定义了一系列字体（称之为 Font Stack）时，如果定义的最高优先级的字体在设备的字库中没有找到、或者引用了 WebFont 但是字体文件没有被加载，那么浏览器会继续轮询 Font Stack，直到找到可用的字体（这个过程就是寻找 fallback 字体）并先渲染出来；当自定义的字体文件被加载以后，浏览器会用这个字体文件重新渲染一遍画面。这有可能造成页面已经展示给用户以后页面的布局再次发生改动。而且，设计师并不喜欢 FOUT，因为这意味着有可能先让访客看到并不好看的备用字体、再看到好看的设计好的字体。但是 FOUT 不会因为字体文件无法加载而导致用户啥都看不到。IE 自从诞生之日起就在使用这种模式，现在 Edge 也在使用这种模式.FOIT(Flash of Invisible Text)这是浏览器处理在设备的字库中没有找到、或者字体文件尚未被下载时的另一种方案。如果检测到设定了当前优先级下有设置自定义字体文件，那么浏览器就会不显示任何内容，直到字体显示出来。这有可能造成访客可能需要等待很长一段时间才能看见网页的内容；如果网络环境较为恶劣，甚至有可能会导致有的内容永久不可见。Safari 曾经在很长的一段时间内使用这种模式，并且 iOS WebKit 仍然在使用这种模式，Opera 也曾短暂使用过。(注: 目前这个方案已经被抛弃了)FOIT 3S这应该是一个比较折中的解决方案，并且目前 Chrome、Firefox、Safari 都在使用。在 3s 内使用了自定义字体样式的使用 FOIT 模式，在一定时间内（1s，3-5s，也可能是 10s，具体看浏览器和版本）使用 FOIT，如果字体仍然没有加载出来就降级到 FOUT 以改善用户的浏览体验。–Web Font 123 - 再谈 WebFont 优化我们可以使用@font-face中指定font-display来告诉浏览器该采用哪种方案, 一共有四个选项: auto, swap, fallback和optional不指定的情况下默认值是auto则浏览器会采用FOIT 3S方案指定为swap则浏览器会采用FOUT方案指定为fallback则浏览器会等待一个极短的时间(大约100ms), 在这个时间之前不会显示任何内容, 这个时间结束之后如果字体还没有加载完成, 那么会采用优先级较低的字体来渲染, 之后等字体加载结束之后再使用正确的字体来重新渲染(根据我的测试, 如果这个字体加载的时间太长, 比如5s, 这个时间我没有准确测量过 那么即使之后字体加载完成了, chrome也不会再去重新渲染该字体, 如果短于这个时间, chrome是会去重新用正确的字体渲染的)指定为optional则浏览器会采用和fallback类似的做法, 只不过等待字体加载的时间会更短(比如上面是5s, 那么现在可能只会等待加载1s)FontFaceSet除了在css中使用@font-face加载在线字体之外, js里面也有手动加载在线字体的API, 只不过目前还有一定兼容性问题, 但是我关心的chrome, firefox和safari的最近的版本都已经支持了, 所以对我来说是可以使用的. 关于这个API的定义可以参考CSS的这份草案, 也可以参考这篇文章的实践, 我自己归纳如下:new FontFace()这个API用来生成一个FontFace字体实例, 接受三个参数, 第一个是字体名(对应@font-face中的font-family), 第二个是字体的的路径(对应@font-face中的src), 第三个是字体的其它信息(例如@font-face中的font-style和font-weight等), 第三个参数也可以不传, 返回一个FontFace字体实例对象const robotoMono = new FontFace('Roboto Mono', 'url(\"https://store.kricsleo.com/blog/static/fonts/RobotoMono-Regular.ttf\")', &#123; style: 'normal', weight: '400',&#125;);[FontFace].load()这个API仅用来加载字体文件, 也就是浏览器会去下载对应的字体文件, 返回一个Promise对象, resolve时会抛出对应的FontFace对象, 可以自行捕获加载错误或者定义加载成功后的行为, 需要注意的是此时字体加载成功以后页面上的文字也不会使用该字体去渲染, 还需要使用下面的add()方法把字体加到FontFaceSet中才可以使用robotoMono.load().then(fontFace =&gt; &#123; console.log(fontFace.family, 'loaded successfully!');&#125;, fontFace =&gt; &#123; console.error('failed: ', fontFace.status);&#125;);[FontFaceSet].load()这个API也可以用来加载字体, 只不过这个API可以不用先生成一个FontFace的实例, 可以使用CSS中已经定义的字体, 然后用这个API来手动加载已经定义的字体, 可以参考MDN// 第一个参数为字体的相关信息, 分别是'font-style' 'font-weight', 'font-size'和'font-family'// 第二个参数为字体中的某个字符, 可以用来限制加载的字体中必须有这个字符document.fonts.load('italic bold 16px Roboto', 'ß').then(fontFace =&gt; &#123; console.log(fontFace.family, ' has been loaded successfully!');&#125;, fontFace =&gt; &#123; console.warn('loading error...');&#125;);[FontFaceSet].add()这个API用来把字体实例加到文档的字体列表FontFaceSet中, 使得字体可以被使用, 返回添加了字体实例之后的FontFaceSet对象document.fonts.add(robotoMono);[FontFace.]status这个API用来访问字体的状态, 共有四种, unloaded, loading, loaded和error, 一旦加载并准备好字体，loaded的Promise就会完成console.log(robotoMono.status);robotoMono.loaded.then(fontFace =&gt; &#123; console.log(fontFace.family, 'loaded successfully!');&#125;, fontFace =&gt; &#123; console.error('failed: ', fontFace.status);&#125;);[FontFaceSet].ready这个API用来作为一系列字体加载的结果的回调, 当所有字体都成功加载时就会触发Promise的完成document.fonts.ready.then(fontFaceSet =&gt; &#123; console.log('All fonts have been loaded successfully!');&#125;);轮子为了达到通过js来定义和控制CSS字体的下载及替换默认的延迟下载行为的目的, 现在已经有一些可以使用的轮子, 比如fontfaceobserver和Web Font Loader, 其实原生的API也挺好用的而且比较简洁, 如果不想引入第三方库的话自己手写一下挺好的."},{"title":"optimize-my-blog","subtitle":"个人博客改造过程","date":"2018-10-21","updated":"2019-04-24","path":"optimize-my-blog/","link":"","text":"hexo主题 MaterialFlow 主题改造打算对博客的访问速度和样式做一个改版优化.因为看到屈屈的博客做了很多优化, 体验很好, 所以自己私下想要pk一下 目前使用的网站评测主要有google的PageSpeed Insights和GTmetrix, 屈屈在PageSpeed Insights上的评分是97分, 那么我的目标是98分及以上.目标精简页面请求数-不超过5个目前已经删除掉多余的请求, 现在已经删减到5个, 分别是页面html, 脚本index.js, 样式style.css, 字体RobotoMono-Iconfont以及图标favicon.ico, 第一次请求会加载这五个, 从第二次开始就只会有一个请求, 就是页面html, 这个是必须的, 其余的四个均在缓冲中(如果用户没有手动清除缓存的话)减少请求大小-单个请求不超过50k目前都已经控制到30k以内, 除开一些特例, 目前页面上最大的请求就是页面本身(这个是正常且自然的), 其次就是页面上的图片, 这个我会尽量压缩, 但是也是在可以接受的范围, 其他的css, js, 和字体都在20k以内控制首屏加载时间-不超过1s目前首屏加载时间相当快了, 因为其实只是先显示一个加载动画, 然后等css加载完毕以后再显示主要内容静态文件上cdn-七牛云cdn目前js和css还有字体文件都已经使用七牛云的cdn服务升级https目前全站资源都切换到了https,主域名kricsleo.com已经使用github提供的免费https服务, cdn域名store.kricsleo.com也使用在阿里云上申请到的SSL证书升级到了https干掉jquery之前的主题使用的是jquery来实现一些功能, 现在已经将相关逻辑都使用原生js改写, 目前没有任何第三方依赖精简字体文件中文字体采用系统自带的字体渲染, 英文字体系统自带的比较难看, 加上我很喜欢google的一个字体Roboto Mono, 所以犹豫了很久决定为了网站的风格稍微牺牲一点速度, 还是采用@font-face加载网络字体, 同时因为我用到了一些图标, 所以最后我决定自己把英文字体和iconfont的图标进行合并, 同时删除掉我用不到的字体和字符, 找到了一个很好用的在线编辑字体的工具FontEditor, 把Roboto Mono中我用不到的基本都删掉了, 最后剩下的大概只有ASCII里面的字符, 同时把在阿里图标库找到的我要用的iconfont图标加了进去, 最后生成了一个适合我的RobotoMono-Iconfont字体文件, 大小只有17k, 最后将这个文件放到了我的cdn上由页面引用优化图片加载-懒加载图片很容易会拖慢网页的加载, 所以我对图片做了懒加载, 这里涉及到一个hexo的渲染问题, 我稍后来细写这一块.目前的效果是随着页面的滚动, 当图片进入视区中时才会去下载这个图片并显示.避免css的加载和解析拖慢首屏的展现这一块和控制首屏展现时间一起写.过程记录对于上面的目标里面的部分记录一下达成的过程压缩所有资源我使用的hexo生成的博客静态文件, 压缩的时候使用相关资料关于浏览器渲染字体的过程:Web Font 123 - 再谈 WebFont 优化渲染字体的方式原生有三种: FOUT(Flash of Unstyled Text), FOIT(Flash of Invisible Text)和FOIT 3S(3s前为FOIT, 3s后还未加载完毕则降级为FOUT)优化关键渲染路径html, css 和 JavaScript 之间的依赖关系关键渲染路径系列文章;普通: 停止解析 dom, 单线程转为下载并立即执行 js, 在 js 处理完毕之后再继续解析 dom, 会阻塞 dom 的解析和渲染defer: 并行下载 js 文件, 但是将其执行时间推迟到 dom 构建完毕在domContentLoaded时间之前, 不会阻塞 dom 的解析但会阻塞dom 的渲染, 按照规范来说 js脚本是按照顺序执行的, 但是各个浏览器的实现可能不一样, 在实际中无法保证顺序执行这一点, 相当于把 js 脚本位置移动到&lt;body&gt;底部, 脚本在执行的时候dom 已经构建完毕, 可以操作 dom;async: 并行下载 js 文件, 下载完成后立即执行, 执行时间可能在domContentLoaded之前, 也可能在domContentLoaded之后, 但是一定在 load 事件之前, 不会阻塞 dom 的解析和渲染, 但是在执行时不保证 dom 构建完毕, 同时也不保证各个脚本的执行顺序, 也就是说如果你的脚本里面有操作 dom 的地方, 那么这个地方可能会报错, 因为对应的 dom 节点可能还没有构建完成, 所以需要避免在此类脚本中操作 dom;值得注意的是，向 document 动态添加 script 标签时，async 属性默认是 true，css 加载优化只显示头部和右侧css加载不会阻塞DOM树的解析css加载会阻塞DOM树的渲染css加载会阻塞后面js语句的执行、js 可以阻塞 dom 树的构建和渲染实际上，内联脚本始终会阻止解析器，除非您编写额外代码来推迟它们的执行–使用 JavaScript 添加交互preload firefox不支持总体步调速度: 请求数: 页面初始请求不超过6个(现在是5个) 请求大小: 最大请求大小不超过150k 不超过2s 加载完毕 静态文件采用 cdn 缓存 图片懒加载 干掉 jquery 字体文件太大了, 采用在线字体处理, 去除多余文字, 加入需要的 iconfont 考虑内联或者其它方式处理 css, 目前 css 严重阻碍首屏展现样式 整体风格天蓝色 采用卡片式布局(可以考虑重写, 既可以练习自己的建站技巧, 也可以去除原本 css 中的冗余部分)安全 全站升级为 https 七牛云空间也一并配置 https评论等到前三点稳定以后再开启评论合适/速度快/国内可访问的评论系统搜索 等到前四点稳定以后再考虑转用其他搜索实现毫秒级响应(第三方搜索或者自己部署 Elasticsearch)目前采用的是hexo-generator-search生成的站内静态文件.2019-04-24更新: 在阿里云的服务器上部署了 docker 环境, 然后在 docker 中部署了 Elasticsearch, 实现了搜索, 不过目前使用的搜索域名是’try.kricsleo.com’,然后下一个问题是我的 markdown 文章如何导入 es 中, 每次新建或者更新文章时如何同步的更新 es 中的数据?"},{"title":"Promise-Generator","date":"2018-10-18","updated":"2019-05-10","path":"Promise-Generator/","link":"","text":"异步解决方案本文是为了解js的异步操作解决方案发展过程. 从原始的回调地狱到ES6的Promise和Generator再到ES7提案阶段的async.这篇笔记也拖了好久了, 该是时候丰富一下了.回调地狱我们之前会把异步的事件写在回调函数里面, 如果有一系列的异步事件, 并且这些事件是按照顺序触发的, 那么我们的代码最后的结构很可能就是回调里面放回调再放回调, 一层层往里面嵌套, 堪称’地狱’.下面的部分中我会使用setTimeout来模拟异步操作function delay(fn, time = 1500) &#123; setTimeout(() =&gt; &#123; fn(); &#125;, time);&#125;// 按序打印三个日志delay(() =&gt; &#123; console.log('step 1'); delay(() =&gt; &#123; console.log('step 2'); delay(() =&gt; &#123; console.log('step 3'); &#125;) &#125;)&#125;)Promise为了避免回调地狱的代码横向发展, 社区最早提出和实现了Promise, 后来被 ES6 纳入了标准中, 使得代码从横向发展变成了链式的纵向发展. 通过then()来执行回调, 使得代码的逻辑变得清晰, 写法也更简洁. 关键点有四个个, resolve, reject, then和catch.then始终返回一个Promise, 如果返回值本身不是一个Promise的话那么会将其包装成一个Promise, 这样可以保证then的链式调用, 方便使用catch实际上是then的第二个参数的语法糖, 可以理解为then(null, rejection)的别名, 也就是说可以使用catch来省略then的第二个参数捕获错误的繁杂写法, 看起来更像是链式的调用. 同时catch也是始终返回一个Promise的常见的写法如下:// 创建一个 Promise 对象const promise = new Promise( (resolve, reject) =&gt; &#123; // ... some code if (/* 异步操作成功 */)&#123; resolve(value); &#125; else &#123; // 异步操作失败 reject(error); &#125;&#125;);// 对这个 Promise 对象进行链式操作promise.then(value =&gt; &#123; // success&#125;, error =&gt; &#123; // failure&#125;).catch(error =&gt; &#123; // js error&#125;);我们使用Promise来改写上面的按序打印三个日志的方法function delayP(fn, time = 1500) &#123; return new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; resolve(fn()); &#125;, time) &#125;);&#125;delayP(() =&gt; &#123; console.log('step 1');&#125;).then(() =&gt; delayP(() =&gt; console.log('step 2'))) .then(() =&gt; delayP(() =&gt; console.log('step 3')))看起来是把代码的横向发展变成了纵向发展, 使得逻辑流程更易于理解一点, 但是这种方式感觉也并没有太优雅, 所以回调的写法还在继续进化其他api:Promise.all(iterable) 参数为一个Promise数组, 返回值是一个Promise当参数数组中的所有项都resolve或者有任何一项出现reject时, 返回值立刻执行then, resolve的时候接受到的参数也是一个数组, 每一项是all()里面的数组项对应的结果, reject的时候参数就是数组中最先reject的那一项的结果const step1 = delayP(() =&gt; console.log('step 1'));const step2 = delayP(() =&gt; console.log('step 2'));Promise.all([step1, step2]) .then(values =&gt; console.log(values)) .catch(err =&gt; console.log(err))Promise.race(iterable) 参数为一个Promise数组, 返回值是一个Promise当参数数组中有任何一项执行结束, 返回值就立刻执行then, resolve和reject的参数都是最先执行结束的那个Promise的结果注意上面两个api参数数组里面如果有某一项不是Promise, 那么会被包装成Promise, 类似Promise.resolve()Generatorcallback, Promise, Generator和async的发展过程如下:Generator 函数有多种理解角度。语法上，首先可以把它理解成，Generator 函数是一个状态机，封装了多个内部状态。执行 Generator 函数会返回一个遍历器对象，也就是说，Generator 函数除了状态机，还是一个遍历器对象生成函数。返回的遍历器对象，可以依次遍历 Generator 函数内部的每一个状态。形式上，Generator 函数是一个普通函数，但是有两个特征。一是，function关键字与函数名之间有一个星号；二是，函数体内部使用yield表达式，定义不同的内部状态（yield在英语里的意思就是“产出”）– Generator 函数的语法Generator函数最大的特点是可以通过yeild关键字来交出js的执行权, 从而可以让函数里面的内容在任意位置停下来, 交出执行权, 让函数外面的代码获得执行权, 等到该函数重新获得执行权的时候可以接着上次的断点继续执行.在这种交换执行权的过程中也可以传递数据, 调用用next(arg)括号里面的arg会被传递给函数内部, 在函数里相应的地方可以获取传进来的arg, 同时调用next(arg)会返回一个对象, 对象里面包含两个值value和done, value是函数中断点处向外传递的数据, done是Boolean型的值, 表示该函数是否已经执行完毕Generator可以单独使用, 也可以和Promise配合起来使用, 每一个yield都会停止Generator函数的运行, 而每一次调用next()都可以让函数接着运行直到下一个yield处, 就像个懒人一样, 抽一鞭子才会动一下(鲁迅说的). 所以如果需要Generator函数自动运行直到函数结束的话一般会搭配上一个自动执行器函数, 通过自动执行器函数来让Generator函数每次一停下就接着又往下运行直到done为true函数运行才结束(注意Generator并不是一定要搭配Promise一起用, 他们是分开的两个东西, 只不过都可以解决回调问题)下面模拟该过程// 仍然使用上面的 delayP 函数 来定义一个 Generator 函数function delayP(fn, time = 1500) &#123; return new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; resolve(fn()); &#125;, time) &#125;);&#125;const generator = function* () &#123; const step1 = yield delayP(() =&gt; console.log('step 1')); const step2 = yield delayP(() =&gt; console.log('step 2')); const step3 = yield delayP(() =&gt; console.log('step 3')); console.log('result: ', step1, step2, step3);&#125;// 生成一个遍历器对象const g = generator();// 手动执行遍历g.next().value .then(() =&gt; g.next('res1').value) .then(() =&gt; g.next('res2').value) .then(() =&gt; g.next('res3'))// 自定义一个简单的自动执行器函数function run(generator) &#123; const g = generator(); function next() &#123; const res = g.next(); console.log('res', res); if(res.done) &#123; return; &#125; res.value.then(() =&gt; next()); &#125; next();&#125;// 使用自动执行器函数来自动执行run(generator);asyncES7 里面引入了async让异步操作更为便捷, 目前来看这是最优雅的异步做法. 我们可以把async看做Generator的语法糖, 底层原理是一致的, 只不过在写法上更为简洁.我们使用async来改写一下上面的按序打印三个日志的过程参考: 与Promise血脉相连的async/await// async函数写法const asy = async function () &#123; const step1 = await delayP(() =&gt; &#123; console.log('step 1'); return 'res1'; &#125;); const step2 = await delayP(() =&gt; &#123; console.log('step 2'); return 'res2'; &#125;); const step3 = await delayP(() =&gt; &#123; console.log('step 3'); return 'res3'; &#125;); console.log('res:', step1, step2, step3);&#125;// async函数的执行asy()从上面的比较可以看出, 从形式上来说是关键词不一样.Generator函数使用*来表示一个异步函数, async函数使用async来表示一个异步函数Generator函数使用yield来进行一个异步操作, async函数使用await来进行一个异步操作, 这两者后面也都可以是同步操作, 比如可以同步计算得到的值, 只不过Generator经常搭配使用的co模块约定，yield命令后面只能是Thunk函数或Promise对象Generator返回的是一个iterator对象, 需要使用next()来遍历执行, async函数返回的是一个Promise对象, 可以对返回值直接调用then()方法在async里面的await会把后面的内容转成一个Promise(如果本身不是一个Promise的话), 然后自动获取Promise完成后的结果, 一旦有一个await后面的Promise出现了reject状态, 那么会直接返回这个reject的Promise, 后面的代码都不会执行了. 你可以使用try/catch来包裹可能出现reject的地方来让代码始终向下执行从内部的工作过程来说, Generator函数没有自动执行的功能, 如果需要内部的异步步骤一步步执行, 那么你需要手动一步步调用next()方法来驱动异步的进行(我们也可以去实现一个自动执行器函数比如有名的co模块来帮助我们完成一步步调用next这个过程). 而async函数简化了这个过程, 内置了执行器, 可以自动一步一步的按照顺序执行异步操作.async用起来比generator更加简洁直接, 但是付出的代价就是没有generator灵活, 因为await只是单纯的把 promise resolve后的值原封不动的返回, 而yield则可以自己完全控制返回什么样的值, 这也就意味着使用generator可以在函数的执行过程中向函数内注入各种各样的值, 这带来了更多的可操作性.我这里只是一叶障目, generator 有着更多的含义和用法. 在我能够完整的说个大概之前, 还是请参考一些别人的理解吧.参考文章: [译] Javascript（ES6）Generator 入门// 一个用于理解 generator 和 next()传参的问题function* gen(i) &#123; console.log(i); const j = 5 * (yield (i * 10)); console.log(j); const k = yield (2 * k / 4); console.log(k); return i + j + k;&#125;var g = gen(10);console.log(g.next(20)); // &#123;value: 100, done: false&#125;console.log(g.next(10)); // &#123;value: 25, done: false&#125;console.log(g.next(5)); // &#123;value: 65, done: true&#125;// testconst a = Promise.resolve(90);const b = Promise.reject(78);const c = Promise.reject(56);Promise.all([a, b, c]).then(res =&gt; console.log(res)) .catch(err =&gt; console.log(err));"},{"title":"same-origin-and-CORS","date":"2018-10-16","updated":"2019-02-25","path":"same-origin-and-CORS/","link":"","text":"浏览器同源策略目前的 web 开发还相当的依赖 cookie , 而cookie的使用限制于浏览器的同源策略(same-origin policy), 同时这个策略也是保证我们网站信息安全的基础, 这篇文章主要了解一下浏览器同源策略具体的含义, 以及在实际开发中如何绕过这一限制来达到跨域请求数据的目的.何为同源一个访问地址大致可以分为&lt;协议&gt;&lt;域名&gt;&lt;端口&gt;&lt;路径&gt;四个部分: 例如https://www.example.com:80/home/index.html?page=3, https为协议, www.example.com为域名, 域名内也可分为顶级域名, 一级域名, 二级域名, 三级域名等等, 具体如何拆分的讨论可以参考知乎的一个帖子, 你只要明白意思就可以了, 这里的话我采用其中一种说法来描述一下, com为顶级域名, example为一级域名, www为二级域名, 接下来的80为端口, /home/index.html?page=3为路径, 这样我们就把一个URL的各个部分拆分开了.所谓同源, 就是限制了&lt;协议&gt;&lt;域名&gt;&lt;端口&gt;这三个部分必须要一模一样, 此时就称为同源, 如果这三块有任何一个地方不一样就产生了跨域.跨域带来的限制在跨域情况下有如下几种情况会受到限制:两个域之间无法互相读取Cookie、LocalStorage 和 IndexDB例如a.com向api.com发起请求的时候, 请求中默认是不会携带a.com域下的cookie的, 也就是说api.com默认情况下是无法获取a.com的cookie的两个域之间无法互相获取和操作DOM例如a.com的一个页面内有一个iframe, iframe里面加载的是b.com的一个一个页面, 那么这两个页面之间是无法获取另一方的DOM来进行操作的两个域之间无法使用ajax通信例如a.com向api.com发起一个ajax请求(XMLHttpRequest或者fetch()), 那么返回的数据默认会被浏览器拦截并且丢弃然后控制台提示产生一个跨域的错误, 所以在js中是无法拿到返回数据的cookie的概念这里我们首先看一下cookie的相关概念, cookie是存在客户端浏览器的一小段文本, 不同的浏览器对cookie的大小有不同的限制, 可以通过document.cookie来获取本域名下的cookie信息, cookie中包含如下属性: key=value, Domain, Path, Expires, Max-Age, Secure和HttpOnly, 还有用的比较少的HostOnly等, 可以查看这篇文章, 各个属性之间用英文分号和空格（”; “）连接, 大概说一下各个属性.key=valuecookie最主要的内容, 设置cookie的值, 例如username=krics;, 代表在cookie中存储了一个username, 它的值是krics, 必填项.Domaincookie的域名, 默认是当前域名, 和Path配合指定 cookie 的具体路径. 注意在手动设置时domain是可以设置为页面本身的域名（本域），或页面本身域名的父域，但不能是公共后缀public suffix。举例说明下：如果页面域名为 www.baidu.com, domain可以设置为“www.baidu.com”，也可以设置为“baidu.com”，但不能设置为“.com”或“com”. 设置Domain时的前面带点‘.’和不带点‘.’的区别:带点：任何 subdomain 都可以访问，包括父 domain不带点：只有完全一样的域名才能访问，subdomain 不能（但在 IE 下比较特殊，它支持 subdomain 访问）Pathcookie的可访问路径, 默认为”/“，表示指定域下的所有路径都能访问, 它是在域名的基础下，指定可以访问的路径。例如cookie设置为”domain=.google.com.hk; path=/webhp”，那么只有”.google.com.hk/webhp”及”/webhp”下的任一子目录如”/webhp/aaa”或”/webhp/bbb”会发送cookie信息，而”.google.com.hk”就不会发送，即使它们来自同一个域。Expirescookie的过期日期, 内容格式是GMT时间字符串, 例如Expires=&quot;Tue, 16 Oct 2018 04:01:45 GMT;&quot;代表此cookie将在这个时间过期, 在此之前cookie都是有效的, 可以使用Date类型的toGMTString()方法来获取这个时间戳, 可选属性. 如果没有设置该项那么默认 cookie 的有效期是本次会话期间, 也就是说在关闭浏览器前这个 cookie 一直有效, 但是一关闭浏览器这个 cookie 马上就失效被删除, 这种 cookie 也叫做session cookie. 现在在http/1.1中已经推荐使用Max-Age来代替这个属性, 但是由于老版本的IE(ie6、ie7 和 ie8)只可使用Expires属性, 不兼容Max-Age这个新属性, 所以使用时请考虑到这一点Max-Agecookie的最大有效时间, 在http/1.1中引入的新属性, 单位是秒, 代表从客户端的此刻开始到多少秒后, 这个cookie会失效, 例如Max-Age=3600, 代表在客户端设置这个cookie起的3600秒后这个cookie失效, 可选属性. 默认值是-1, 含义是本次会话期间有效, 关闭浏览器则失效, 设置为0代表删除该 cookie, 设置为正整数代表的有效秒数.注意对于对于Expires和Max-Age都可以使用的浏览器而言, 这两个如果都设置了, 那么Max-Age的优先级高(IE除外, IE只使用Expires), 如果只设置一个, 那就以设置的那个为准(同样IE除外), 如果都没有设置, 那么cookie的有效时间为本次会话期间, 只要浏览器不关闭, 那么这个cookie一直有效, 如果浏览器被关闭, 那么这个cookie就会被删除, 像这样没有设置Expires和Max-Age的cookie, 我们也可以称为session cookie, 因为它是与本次会话相关联的. 可选属性Securecookie的安全标志, 内容很简单, 只需要指定一个Secure字段就可以了, 而不是键值对的形式, 当指定是Secure之后, 这个cookie只会在使用SSL(例如HTTPS)连接时才会被发送到服务器. 默认为空, 那么默认情况下不论是不是安全的连接在可以发送 cookie 的时候都会发送这个cookie. 可选属性. 如果想在客户端即网页中通过 js 去设置secure类型的 cookie，必须保证网页是https协议的。在http协议的网页中是无法设置secure类型cookie的。HttpOnlycookie的安全保证, 内容也很简单, 只需要指定一个HttpOnly字段就可以了, 当指定为HttpOnly后, 就无法通过js去访问或者设置这个cookie的内容, 同时也无法通过js来设置HttpOnly的cookie, 这个字段只有服务器能够操作, 这个cookie会正常的发送给服务器, 只是对客户端的js不可见而已. 可选属性有两种方式产生cookie, 一种是服务器的响应, 而是客户端的js.服务器响应方式如果服务器在响应的数据中添加一个响应头: Set-Cookie: name=krics; Path=/; Domain=.example.com; Max-Age=31536000, 例如下面JAVA的写法,// 生成一个cookieCookie cookie = new Cookie(\"name\", \"krics\");cookie.setPath(\"/\");cookie.setDomain(\".example.com\");//这样设置，能实现不同二级域名的两个网站共用这个cookie, 自定义cookie.setMaxAge(365 * 24 * 60 * 60);// 不设置的话，则cookies不写入硬盘,而是写在内存,只在当前页面有用,以秒为单位response.addCookie(cookie); //添加第一个Cookie// 可以重复上面的代码添加多个cookie这样就会在响应头中添加上面示例给出的额外的头信息.客户端js在客户端通过js方式document.cookie既能访问cookie, 也能设置cookie, 例如document.cookie=&quot;name=krics; Path=/; Domain=.example.com; Max-Age=31536000&quot;, 那么就会添加一个cookie到浏览器中, 这里比较有意思的是并不是多次设置document.cookie其实是追加内容, 不像一般js那样会覆盖内容, 之后有时间可以看一下这里的处理. 这里因为浏览器没有提供其他的api来操作cookie, 所以我们一般会自己封装一个工具类来读写cookie, 这里给出我的一个比较简单的实现Cookie.js解决跨域这里可以参考阮一峰的文章浏览器同源政策及其规避方法.iframe形式的跨域如果两个窗口一级域名相同，只是二级域名不同，那么可以通过设置document.domain属性为同一个值，就可以规避同源政策，拿到DOM。片段标识符（fragment identifier）指的是，URL的#号后面的部分，比如http://example.com/x.html#fragment的#fragment。如果只是改变片段标识符，页面不会重新刷新。但是会触发window的onhashchange事件, 可以通过监听这个事件来传递数据.监听window.name属性。这个属性的最大特点是，无论是否同源，只要在同一个窗口里，前一个网页设置了这个属性，后一个网页可以读取它, 而且这个值得容量很大, 字符串形式.以上三种方式都属于hack, HTML5为了解决这个问题，引入了一个全新的API：跨文档通信 API（Cross-document messaging）,这个API为window对象新增了一个window.postMessage方法，允许跨窗口通信，不论这两个窗口是否同源。具体使用可以参考MDN, 需要注意的是在IE下有一定的兼容性问题.通过window.postMessage，读写其他窗口的 LocalStorage . 也是基于window.postMessage的.AJAX这里才是重点, 一个跨域的AJAX请求要想正常交互, 有如下四种解决方案:JSONP它的基本思想是，网页通过添加一个&lt;script&gt;元素，向服务器请求JSON数据，这种做法不受同源政策限制；服务器收到请求后，将数据放在一个指定名字的回调函数里传回来。这种方式的优点是简单兼容性好, 服务器的改造小, 但是这种方式因为是通过加载js脚本的形式实现的, 所以只支持GET方式.WebSocketWebSocket是一种通信协议，使用ws://（非加密）和wss://（加密）作为协议前缀。该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信。这种方式对服务器的改造最大, 需要更改协议Nginx通过在服务器端布置Nginx, 通过它代理请求, 然后由Nainx将请求转发到真正的数据服务器上, 这种方式需要在服务器端安装Nginx, 然后需要配置Nginx才行CORSCORS是跨源资源分享（Cross-Origin Resource Sharing）的缩写。它是W3C标准，是跨源AJAX请求的根本解决方法。相比JSONP只能发GET请求，CORS允许任何类型的请求。关于CORS, 可以参考阮一峰的文章跨域资源共享 CORS 详解, 简单来说是按照下文配置.CORD服务器端配置Access-Control-Allow-Origin: 代表允许跨域的域名,可选字段, 默认不允许跨域请求, 如果配置为&quot;*&quot;代表接受任何一个域发送的ajax请求, 也可以指定一个特定的域名, 表示只接受这个域发送的跨域请求, 注意- 不能设置多个域, 要么是通配符&quot;*&quot;, 要么是某一个域Access-Control-Allow-Credentials: 代表是否允许跨域请求携带cookie, 可选字段, 默认不允许, 设置为true代表允许, 但是这个字段和上面的Access-Control-Allow-Origin有一点冲突的是, 如果设置为true, 那么Access-Control-Allow-Origin只能配置特定的一个允许跨域的域名, 这个时候不能配置通配符&quot;*&quot;Access-Control-Expose-Headers: 代表允许客户端获取的额外的头字段信息, 可选字段, 默认无法拿到自定义的头部字段, CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。例如可以指定Access-Control-Expose-Headers: FooBar，那么客户端可以通过response.getResponseHeader(&#39;FooBar&#39;)拿到FooBar字段的值。客户端配置withCredentials: 代表跨域请求是否发送对应域的cookie, 可选字段, 默认不会发送(有的浏览器可能例外, 也可以显示的设置为false), 设置为true代表发送, 需要注意的是客户端是需要和服务端配合使用的, 当设置为true时, 虽然cookie发送过去了, 但是服务器要配置Access-Control-Allow-Credentials: true和Access-Control-Allow-Origin: www.example.com才能正确接收到cookie当然还有更详细的内容, 如果碰到更多问题, 可以去看一下上面阮一峰的关于跨域的文章, 也可以参考Faremax的一片文章全解跨域请求处理办法.参考文章聊一聊 cookie全解跨域请求处理办法跨域资源共享 CORS 详解"},{"title":"Content-Type","date":"2018-10-12","updated":"2019-05-16","path":"Content-Type/","link":"","text":"Content-TypeHTTP/1.1协议规定的HTTP请求方法有OPTIONS、GET、HEAD、POST、PUT、DELETE、TRACE、CONNECT这几种, 用的最多的是GET和POST, 这里主要说一下提交请求时的请求头中Content-Type字段http请求结构http请求分为三个部分: 状态行, 请求头和消息主体, 结构如下:&lt;method&gt; &lt;request url&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt;Content-Type类型Content-Type有如下常见的类型:text/plain: 文本类型text/html: html文件类型text/css: css文件类型text/javascript: javascript文件类型application/x-www-form-urlencoded POST讨论multipart/form-data POST讨论application/json POST讨论text/xml POST中讨论由于GET方式的数据实际上是以QueryString的方式放在&lt;request url&gt;中的(非ASCII字符会被转码), 例如’https://www.example.com?key1=value1&amp;key2=value2‘, 所以对GET讨论Content-Type没有意义http协议规定POST提交的数据必须放在消息主体（entity-body）中，但协议并没有规定数据必须使用什么编码方式。实际上，开发者完全可以自己决定消息主体的格式，只要最后发送的HTTP请求满足上面的格式就可以。服务端通常是根据请求头（headers）中的Content-Type字段来获知请求中的消息主体是用何种方式编码，再对主体进行解析。所以有必要了解Content-Type的内容. 目前在POST请求中所使用的Content-Type主要有如下四种类型: application/x-www-urlencoded, multipart/form-data, application/json, text/xml, 下面详细说一下这四种类型.application/x-www-urlencoded这应该是最常见的POST提交数据的方式了。浏览器的原生&lt;form&gt;表单，如果不设置enctype属性，那么默认就会以这种方式提交数据。这种方式会将表单中的数据按照key1=value1&amp;key2=value2的形式连接成字符串, 同时会将出现的非ASCII字符进行编码, 编码方式可以参考encodeURIComponent()函数, 例如下面这个表单提交时的数据结构:POST http://www.example.com HTTP/1.1Content-Type: application/x-www-form-urlencoded;charset=utf-8title=test&amp;sub%5B%5D=1&amp;sub%5B%5D=2&amp;sub%5B%5D=3但是需要注意的是这是在&lt;form&gt;表单中没有type=file形内容的时候的提交方式, 如果表单中有二进制内容需要提交, 比如文件或者图片等, 那么就无法使用application/x-www-urlencoded方式, 需要转而使用下面会谈到的multipart/form-data方式.multipart/form-data当需要提交二进制数据如文件或者图片时就需要使用这种multipart/form-data, 一个常见的提交内容结构如下:POST http://www.example.com HTTP/1.1Content-Type:multipart/form-data; boundary=----WebKitFormBoundaryrGKCBY7qhFd3TrwA------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name=&quot;text&quot;title------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name=&quot;file&quot;; filename=&quot;chrome.png&quot;Content-Type: image/pngPNG ... content of chrome.png ...------WebKitFormBoundaryrGKCBY7qhFd3TrwA--请求头中的boundary代表将使用后面这一长串的字符串来分隔不同的字段, 消息主体里按照字段个数又分为多个结构类似的部分，每部分都是以--boundary开始，紧接着是内容描述信息，然后是回车，最后是字段具体内容（文本或二进制）。如果传输的是文件，还要包含文件名和文件类型信息。消息主体最后以--boundary--标示结束, 关于multipart/form-data的详细定义，请前往rfc1867查看。application/x-www-urlencoded和multipart/form-data都是浏览器原生支持的，而且现阶段标准中原生&lt;form&gt;表单也只支持这两种方式（通过&lt;form&gt;元素的enctype属性指定，默认为 application/x-www-form-urlencoded。其实enctype还支持text/plain，不过用得非常少）。下面提到的Content-Type属于随着技术的发展, 我们自定义出来的新的数据提交方式, 更为便捷.application/json因为json格式数据的读写性非常好, 用的也极为广泛, 所以application/json这个请求头也用的越来越多, 这个请求头就是告诉服务器发送的数据是序列化后的json字符串, 现在在做的Vue项目中用到的Axios所使用的默认就是application/json, 这里有一个问题就是Axios全局设置Content-Type为application/x-www-urlencoded不生效, 需要在请求发出前拦截方法中修改配置才能生效, 不知道是不是bug, 如下:function _interceptorRequest(config) &#123; config.headers['Content-Type'] = 'application/x-www-form-urlencoded; charset=utf-8'; return config&#125;使用application/json方式发送的数据结构类似下面这个:POST http://www.example.com HTTP/1.1 Content-Type: application/json;charset=utf-8&#123;&quot;title&quot;:&quot;test&quot;,&quot;sub&quot;:[1,2,3]&#125;json格式可以提交结构复杂的数据,在抓包工具或者调试中查看起来也很方便, 尤其适合RESEful的接口, 需要注意的是不论我们使用application/x-www-urlencoded还是application/json都要注意和服务器相配合, 因为毕竟我们发送的数据是希望服务器来正确接收和处理的, 如果客户端设置的Content-Type与服务端期望接收的Content-Type不一致就很有可能导致服务器无妨正常处理这个请求.text/xml这是一种使用HTTP作为传输协议，XML作为编码方式的远程调用规范, 典型的XML-RPC请求如下:POST http://www.example.com HTTP/1.1Content-Type: text/xml&lt;?xml version=&quot;1.0&quot;?&gt;&lt;methodCall&gt; &lt;methodName&gt;examples.getStateName&lt;/methodName&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;i4&gt;41&lt;/i4&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodCall&gt;XML-RPC协议简单、功能够用，各种语言的实现都有。它的使用也很广泛，如WordPress的XML-RPCApi，搜索引擎的ping服务等等。JavaScript中，也有现成的库支持以这种方式进行数据交互，能很好的支持已有的 XML-RPC服务。参考文章四种常见的POST提交数据方式HTTP Header之Content-Type"},{"title":"http","date":"2018-10-12","updated":"2019-05-16","path":"http/","link":"","text":"httphttp虽然内容简单, 容易理解, 但是内容十分庞大, 涉及到现在通信的方方面面, 我打算花点时间陆陆续续的把我接触到的http的相关部分整理出来, 这里作为一个入口页, 后续持续补充.Content-Type关于Content-Type"},{"title":"object-defineProperty","subtitle":"Object.defineProperty","date":"2018-10-08","updated":"2019-01-17","path":"object-defineProperty/","link":"","text":"属性描述符在js的对象中通常会有很多个属性, 例如let person = { name: &#39;john&#39;}中的name就是person这个对象的一个属性, 我们可以定义这个属性的一些特性, 也就是来描述这个属性, 比如这个属性是否是可读写的, 是否是可以被枚举的等等, 由此产生出了属性描述符这个概念.属性描述符分为两种: 数据描述符和存取描述符:数据描述符是一个拥有可写或不可写值的属性存取描述符是由一对getter-setter函数功能来描述的属性属性描述符必须是两种形式其中之一, 不能同时是两者. 我们使用Object.defineProperty()这个方法来定义一个属性的属性描述符.数据描述符数据描述符有四个: configurable, enumerable, writable和value, 前三个属性在使用Object.defineProperty()定义时默认都是false,第四个属性value默认为undefined, 而如果使用字面量直接添加属性的话, 那么这个属性的前三个属性默认都是true. 下面具体说一下这个四个属性:configurable是否可以删除目标属性或是否可以再次修改属性的四个特性, 意思是当设置为true时可以随时对configurable, enumerable, writable和value这四个属性进行修改, 但是一旦设置为false, 那么这个四个属性将都不能被更改, 你也无法再次将configurable设置为true, 默认为falseenumerable此属性是否可以被枚举（使用for...in或Object.keys()）。设置为true可以被枚举；设置为false，不能被枚举, 默认为falsewritable属性的值是否可以被重写。设置为true可以被重写；设置为false，不能被重写, 默认为falsevalue属性对应的值,可以使任意类型的值，默认为undefined使用举例:let person = &#123; name: 'john'&#125;// 定义一个已经有的属性 name, 或者新增一个属性 name, 写法一样Object.defineProperty(person, 'name', &#123; configurable: true | false, enumerable: true | false, writable: true | false, value: 任意类型的值&#125;);// 查看属性Object.getOwnPropertyDescriptor(person, 'name');// =&gt; &#123;// configurable: true,// enumerable: true,// writable: true,// value: 'john'// &#125;ES5有三个操作符会忽略掉对象中enumerable设置为false的属性:for...in循环: 只遍历对象自身的和继承的可枚举的属性Object.keys()：返回对象自身的所有可枚举的属性的键名JSON.stringify()：只串行化对象自身的可枚举的属性ES6新增了一个操作Object.assign()，也会忽略对象中enumerable为false的属性，只拷贝对象自身的可枚举的属性。存取描述符存取描述符也有四个: configurable, enumerable, get和set, 前两个属性在使用Object.defineProperty()定义时默认都是false, 后两个属性默认是undefined, 而如果使用字面量直接添加属性的话, 那么这个属性的前两个属性默认都是true, 下面具体说一下这个四个属性:configurable与上面数据描述符中相同enumerable与上面数据描述符中相同get获取对象中属性值的方法, 它的值应该是一个返回这个属性值的方法, 默认为undefinedset设置对象中属性值的方法, 它的值应该是一个接受一个新值作为参数然后执行设置属性值的方法, 默认为undefined使用举例:let person = &#123; name: 'john' &#125;;Object.defineProperty(person, 'name', &#123; configurable: true | false, enumerable: true | false, get: function() &#123; return value; &#125; | undefined, set: function(newVal) &#123; if(newVal !== value) &#123; value = newVal; &#125; &#125; | undefined&#125;);这里的set的用途就很强大了, 比如我们使用的Vue里面的数据绑定就是基于这个set实现的双向数据绑定, 这里埋下一个坑:TODO: 分析Vue的源码中的数据绑定部分属性的遍历for...infor...in循环遍历对象自身的和继承的可枚举属性（不含Symbol属性)Object.keys(obj)Object.keys返回一个数组，包括对象自身的（不含继承的）所有可枚举属性（不含Symbol属性）。Object.getOwnPropertyNames(obj)Object.getOwnPropertyNames返回一个数组，包含对象自身的所有属性（不含Symbol属性，但是包括不可枚举属性）。Object.getOwnPropertySymbols(obj)Object.getOwnPropertySymbols返回一个数组，包含对象自身的所有Symbol属性。Reflect.ownKeys(obj)Reflect.ownKeys返回一个数组，包含对象自身的所有属性，不管是属性名是Symbol或字符串，也不管是否可枚举。"},{"title":"MVC-MVP-MVVM","date":"2018-09-28","updated":"2019-02-25","path":"MVC-MVP-MVVM/","link":"","text":"关于 MV*为了管理有图形界面的应用程序, 先后提出了 MVC, MVP 和 MVVM 等应用架构模式, 我们也许常常听到这几个词, 尤其对我这个前后端都做过的人来说更是时常接触, 但是对于他们之间的区别却不甚了解, 这几天看了不少文章讲这一块, 在看到 Github 上 livoras 写的文章以后才终在心里有所区分, 这里转载一下 livoras 的原文.作者: livoras原文: https://github.com/livoras/blog/issues/11另外可以看一下掘金上的这篇文章, 与前端开发结合起来更好理解: 浅析前端开发中的 MVC/MVP/MVVM 模式以下为转载内容.前言做客户端开发、前端开发对MVC、MVP、MVVM这些名词不了解也应该大致听过，都是为了解决图形界面应用程序复杂性管理问题而产生的应用架构模式。网上很多文章关于这方面的讨论比较杂乱，各种MV模式之间的区别分不清，甚至有些描述都是错误的。本文追根溯源，从最经典的Smalltalk-80 MVC模式开始逐步还原图形界面之下最真实的MV模式。GUI程序所面临的问题图形界面的应用程序提供给用户可视化的操作界面，这个界面提供给数据和信息。用户输入行为（键盘，鼠标等）会执行一些应用逻辑，应用逻辑（application logic）可能会触发一定的业务逻辑（business logic）对应用程序数据的变更，数据的变更自然需要用户界面的同步变更以提供最准确的信息。例如用户对一个电子表格重新排序的操作，应用程序需要响应用户操作，对数据进行排序，然后需要同步到界面上。在开发应用程序的时候，以求更好的管理应用程序的复杂性，基于职责分离（Speration of Duties）的思想都会对应用程序进行分层。在开发图形界面应用程序的时候，会把管理用户界面的层次称为View，应用程序的数据为Model（注意这里的Model指的是Domain Model，这个应用程序对需要解决的问题的数据抽象，不包含应用的状态，可以简单理解为对象）。Model提供数据操作的接口，执行相应的业务逻辑。有了View和Model的分层，那么问题就来了：View如何同步Model的变更，View和Model之间如何粘合在一起。带着这个问题开始探索MV模式，会发现这些模式之间的差异可以归纳为对这个问题处理的方式的不同。而几乎所有的MV模式都是经典的Smalltalk-80 MVC的修改版。Smalltalk-80 MVC历史背景早在上个世纪70年代，美国的施乐公司（Xerox）的工程师研发了Smalltalk编程语言，并且开始用它编写图形界面的应用程序。而在Smalltalk-80这个版本的时候，一位叫Trygve Reenskaug的工程师设计了MVC图形应用程序的架构模式，极大地降低了图形应用程序的管理难度。而在四人帮（GoF）的设计模式当中并没有把MVC当做是设计模式，而仅仅是把它看成解决问题的一些类的集合。Smalltalk-80 MVC和GoF描述的MVC是最经典的MVC模式。MVC的依赖关系MVC出了把应用程序分成View、Model层，还额外的加了一个Controller层，它的职责为进行Model和View之间的协作（路由、输入预处理等）的应用逻辑（application logic）；Model进行处理业务逻辑。Model、View、Controller三个层次的依赖关系如下：Controller和View都依赖Model层，Controller和View可以互相依赖。在一些网上的资料Controller和View之间的依赖关系可能不一样，有些是单向依赖，有些是双向依赖，这个其实关系不大，后面会看到它们的依赖关系都是为了把处理用户行为触发的事件处理权交给Controller。MVC的调用关系用户的对View操作以后，View捕获到这个操作，会把处理的权利交移给Controller（Pass calls）；Controller会对来自View数据进行预处理、决定调用哪个Model的接口；然后由Model执行相关的业务逻辑；当Model变更了以后，会通过观察者模式（Observer Pattern）通知View；View通过观察者模式收到Model变更的消息以后，会向Model请求最新的数据，然后重新更新界面。如下图：看似没有什么特别的地方，但是由几个需要特别关注的关键点：view是把控制权交移给Controller，Controller执行应用程序相关的应用逻辑（对来自View数据进行预处理、决定调用哪个Model的接口等等）。Controller操作Model，Model执行业务逻辑对数据进行处理。但不会直接操作View，可以说它是对View无知的。View和Model的同步消息是通过观察者模式进行，而同步操作是由View自己请求Model的数据然后对视图进行更新。需要特别注意的是MVC模式的精髓在于第三点：Model的更新是通过观察者模式告知View的，具体表现形式可以是Pub/Sub或者是触发Events。而网上很多对于MVC的描述都没有强调这一点。通过观察者模式的好处就是：不同的MVC三角关系可能会有共同的Model，一个MVC三角中的Controller操作了Model以后，两个MVC三角的View都会接受到通知，然后更新自己。保持了依赖同一块Model的不同View显示数据的实时性和准确性。我们每天都在用的观察者模式，在几十年前就已经被大神们整合到MVC的架构当中。这里有一个MVC模式的JavaScript Demo，实现了一个小的TodoList应用程序。经典的Smalltalk-80 MVC不需要任何框架支持就可以实现。目前Web前端框架当中只有一个号称是严格遵循Smalltalk-80 MVC模式的：maria.js。MVC的优缺点优点:把业务逻辑和展示逻辑分离，模块化程度高。且当应用逻辑需要变更的时候，不需要变更业务逻辑和展示逻辑，只需要Controller换成另外一个Controller就行了（Swappable Controller）。观察者模式可以做到多视图同时更新。缺点:Controller测试困难。因为视图同步操作是由View自己执行，而View只能在有UI的环境下运行。在没有UI环境下对Controller进行单元测试的时候，应用逻辑正确性是无法验证的：Model更新的时候，无法对View的更新操作进行断言。View无法组件化。View是强依赖特定的Model的，如果需要把这个View抽出来作为一个另外一个应用程序可复用的组件就困难了。因为不同程序的的Domain Model是不一样的MVC Model 2在Web服务端开发的时候也会接触到MVC模式，而这种MVC模式不能严格称为MVC模式。经典的MVC模式只是解决客户端图形界面应用程序的问题，而对服务端无效。服务端的MVC模式又自己特定的名字：MVC Model 2，或者叫JSP Model 2，或者直接就是Model 2 。Model 2客户端服务端的交互模式如下：服务端接收到来自客户端的请求，服务端通过路由规则把这个请求交由给特定的Controller进行处理，Controller执行相应的应用逻辑，对Model进行操作，Model执行业务逻辑以后；然后用数据去渲染特定的模版，返回给客户端。因为HTTP协议是单工协议并且是无状态的，服务器无法直接给客户端推送数据。除非客户端再次发起请求，否则服务器端的Model的变更就无法告知客户端。所以可以看到经典的Smalltalk-80 MVC中Model通过观察者模式告知View更新这一环被无情地打破，不能称为严格的MVC。Model 2模式最早在1998年应用在JSP应用程序当中，JSP Model 1应用管理的混乱诱发了JSP参考了客户端MVC模式，催生了Model 2。后来这种模式几乎被应用在所有语言的Web开发框架当中。PHP的ThinkPHP，Python的Dijango、Flask，NodeJS的Express，Ruby的RoR，基本都采纳了这种模式。平常所讲的MVC基本是这种服务端的MVC。MVPMVP模式有两种：Passive ViewSupervising Controller而大多数情况下讨论的都是Passive View模式。本文会对PV模式进行较为详细的介绍，而SC模式则简单提及。历史背景MVP模式是MVC模式的改良。在上个世纪90年代，IBM旗下的子公司Taligent在用C/C++开发一个叫CommonPoint的图形界面应用系统的时候提出来的。MVP（Passive View）的依赖关系MVP模式把MVC模式中的Controller换成了Presenter。MVP层次之间的依赖关系如下：MVP打破了View原来对于Model的依赖，其余的依赖关系和MVC模式一致。MVP（Passive View）的调用关系既然View对Model的依赖被打破了，那View如何同步Model的变更？看看MVP的调用关系：和MVC模式一样，用户对View的操作都会从View交移给Presenter。Presenter会执行相应的应用程序逻辑，并且对Model进行相应的操作；而这时候Model执行完业务逻辑以后，也是通过观察者模式把自己变更的消息传递出去，但是是传给Presenter而不是View。Presenter获取到Model变更的消息以后，通过View提供的接口更新界面。关键点：View不再负责同步的逻辑，而是由Presenter负责。Presenter中既有应用程序逻辑也有同步逻辑。View需要提供操作界面的接口给Presenter进行调用。（关键）对比在MVC中，Controller是不能操作View的，View也没有提供相应的接口；而在MVP当中，Presenter可以操作View，View需要提供一组对界面操作的接口给Presenter进行调用；Model仍然通过事件广播自己的变更，但由Presenter监听而不是View。MVP模式，这里也提供一个用JavaScript编写的例子。MVP（Passive View）的优缺点优点：便于测试。Presenter对View是通过接口进行，在对Presenter进行不依赖UI环境的单元测试的时候。可以通过Mock一个View对象，这个对象只需要实现了View的接口即可。然后依赖注入到Presenter中，单元测试的时候就可以完整的测试Presenter应用逻辑的正确性。这里根据上面的例子给出了Presenter的单元测试样例。View可以进行组件化。在MVP当中，View不依赖Model。这样就可以让View从特定的业务场景中脱离出来，可以说View可以做到对业务完全无知。它只需要提供一系列接口提供给上层操作。这样就可以做到高度可复用的View组件。缺点：Presenter中除了应用逻辑以外，还有大量的View-&gt;Model，Model-&gt;View的手动同步逻辑，造成Presenter比较笨重，维护起来会比较困难。MVP（Supervising Controller）上面讲的是MVP的Passive View模式，该模式下View非常Passive，它几乎什么都不知道，Presenter让它干什么它就干什么。而Supervising Controller模式中，Presenter会把一部分简单的同步逻辑交给View自己去做，Presenter只负责比较复杂的、高层次的UI操作，所以可以把它看成一个Supervising Controller。Supervising Controller模式下的依赖和调用关系因为Supervising Controller用得比较少，对它的讨论就到这里为止。MVVMMVVM可以看作是一种特殊的MVP（Passive View）模式，或者说是对MVP模式的一种改良。历史背景MVVM模式最早是微软公司提出，并且了大量使用在.NET的WPF和Sliverlight中。2005年微软工程师John Gossman在自己的博客上首次公布了MVVM模式。ViewModelMVVM代表的是Model-View-ViewModel，这里需要解释一下什么是ViewModel。ViewModel的含义就是 “Model of View”，视图的模型。它的含义包含了领域模型（Domain Model）和视图的状态（State）。 在图形界面应用程序当中，界面所提供的信息可能不仅仅包含应用程序的领域模型。还可能包含一些领域模型不包含的视图状态，例如电子表格程序上需要显示当前排序的状态是顺序的还是逆序的，而这是Domain Model所不包含的，但也是需要显示的信息。可以简单把ViewModel理解为页面上所显示内容的数据抽象，和Domain Model不一样，ViewModel更适合用来描述View。MVVM的依赖MVVM的依赖关系和MVP依赖，只不过是把P换成了VM。MVVM的调用关系MVVM的调用关系和MVP一样。但是，在ViewModel当中会有一个叫Binder，或者是Data-binding engine的东西。以前全部由Presenter负责的View和Model之间数据同步操作交由给Binder处理。你只需要在View的模版语法当中，指令式地声明View上的显示的内容是和Model的哪一块数据绑定的。当ViewModel对进行Model更新的时候，Binder会自动把数据更新到View上去，当用户对View进行操作（例如表单输入），Binder也会自动把数据更新到Model上去。这种方式称为：Two-way data-binding，双向数据绑定。可以简单而不恰当地理解为一个模版引擎，但是会根据数据变更实时渲染。也就是说，MVVM把View和Model的同步逻辑自动化了。以前Presenter负责的View和Model同步不再手动地进行操作，而是交由框架所提供的Binder进行负责。只需要告诉Binder，View显示的数据对应的是Model哪一部分即可。这里有一个JavaScript MVVM的例子，因为MVVM需要Binder引擎。所以例子中使用了一个MVVM的库：Vue.js。MVVM的优缺点优点：提高可维护性。解决了MVP大量的手动View和Model同步的问题，提供双向绑定机制。提高了代码的可维护性。简化测试。因为同步逻辑是交由Binder做的，View跟着Model同时变更，所以只需要保证Model的正确性，View就正确。大大减少了对View同步更新的测试。缺点：过于简单的图形界面不适用，或说牛刀杀鸡。对于大型的图形应用程序，视图状态较多，ViewModel的构建和维护的成本都会比较高。数据绑定的声明是指令式地写在View的模版当中的，这些内容是没办法去打断点debug的。结语可以看到，从MVC-&gt;MVP-&gt;MVVM，就像一个打怪升级的过程。后者解决了前者遗留的问题，把前者的缺点优化成了优点。同样的Demo功能，代码从最开始的一堆文件，优化成了最后只需要20几行代码就完成。MV*模式之间的区分还是蛮清晰的，希望可以给对这些模式理解比较模糊的同学带来一些参考和思路。ReferencesScaling Isomorphic Javascript CodeSmalltalk-80 MVCLearning JavaScript Design PatternsSmalltalk-80 MVC in JavaScriptGUI ArchitecturesThe Model-View-Presenter (MVP) PatternBusiness and application logic?Business logic in MVC"},{"title":"CommonJS-AMD-CMD-ES6","date":"2018-09-25","updated":"2019-02-25","path":"CommonJS-AMD-CMD/","link":"","text":"JavaScript 模块化远古时期, 我们写的 js 都是都是通过 script 标签进行管理, 这使得项目一旦复杂, 页面内便会写上成堆的 script 标签来引入各种外部 js 文件, 而且我们还需要保证 js 的顺序, 因为一个 js 文件内的方法往往依赖另外的 js 来实现, 我们通过确保书写顺序来确保 js 的加载顺序, 这当然是极不方便的, 后来前端工程师们就开始了尝试 js 模块化的探索之旅.什么是模块化在了解这些规范之前，还是先了解一下什么是模块化。模块化是指在解决某一个复杂问题或者一系列的杂糅问题时，依照一种分类的思维把问题进行系统性的分解以之处理。模块化是一种处理复杂系统分解为代码结构更合理，可维护性更高的可管理的模块的方式。可以想象一个巨大的系统代码，被整合优化分割成逻辑性很强的模块时，对于软件是一种何等意义的存在。对于软件行业来说：解耦软件系统的复杂性，使得不管多么大的系统，也可以将管理，开发，维护变得“有理可循”。还有一些对于模块化一些专业的定义为：模块化是软件系统的属性，这个系统被分解为一组高内聚，低耦合的模块。那么在理想状态下我们只需要完成自己部分的核心业务逻辑代码，其他方面的依赖可以通过直接加载被人已经写好模块进行使用即可。首先，既然是模块化设计，那么作为一个模块化系统所必须的能力：定义封装的模块。定义新模块对其他模块的依赖。可对其他模块的引入支持。好了，思想有了，那么总要有点什么来建立一个模块化的规范制度吧，不然各式各样的模块加载方式只会将局搅得更为混乱。那么在JavaScript中出现了一些非传统模块开发方式的规范 CommonJS的模块规范，AMD（Asynchronous Module Definition），CMD（Common Module Definition）等。 –文章CommonJSCommmonsJS是同步加载模块的, 例如如下代码:// foobar.js// 私有变量var test = 123;// 公有方法function foobar () &#123; this.foo = function () &#123; // do someing ... &#125; this.bar = function () &#123; //do someing ... &#125;&#125;// exports对象上的方法和变量是公有的var foobar = new foobar();exports.foobar = foobar;// test.js// require方法默认读取js文件，所以可以省略js后缀var test = require('./boobar').foobar;test.bar();CommonJS规定一个单独的 js 文件就是一个模块, 在 js 文件中引入其他的模块需使用关键字require, 例如require(&#39;./a&#39;), 该方法会根据读取这个文件然后返回这个文件内部的exports对象, 文件内需要导出的东西使用关键字exports, 例如exports.foobar = foobar, 需要注意的是CommonJS 是同步加载模块的, 也就是说会在模块加载完毕之后再去执行接下里的代码, 会阻塞 js 的线程, 对于像 Node.js 这样的服务端, 因为各个模块文件都存在本地硬盘上, 加载起来很快, 所以阻塞的时间很短, 属于可以接受的程度, 但是对于浏览器端, 需要通过网络下载下来各个依赖文件, 这个阻塞的时间就比较长了, 所以 CommonJS一般用在 Node.js 中, 同时也因为 Node.js 发扬光大.那么在浏览器端为了实现异步加载模块, 就产生了 AMD 和 CMD 解决方案.AMDAMD 全称是”Asynchronous Module Definition”, 中文名是”异步模块定义”AMD 定义模块AMD 定义了一个简洁实用的 api, define(id, dependencies?, factory);第一个参数id为字符串类型, 表示模块标志, 为可选参数, 如果不存在则模块标识应该默认定义为在加载器中被请求脚本的标识。如果存在，那么模块标识必须为顶层的或者一个绝对的标识。第二个参数dependencies为数组类型, 表示当前模块所依赖的模块的模块标识.第三个参数factory是一个需要实例化的函数或者一个对象.可以使用这个 api 进行灵活的模块定义:定义无依赖的模块define( &#123; add : function( x, y )&#123; return x + y ; &#125;&#125; );定义有依赖的模块define(['alpha'], function(alpha) &#123; return &#123; verb: function() &#123; return alpha.verb() + 1; &#125; &#125;&#125;);定义数据对象模块define(&#123; users: [], members: []&#125;);具名模块define('alpha', ['require', 'exports', 'beta'], function(require, exports, beta) &#123; exports.verb = function() &#123; return beta.verb(); // or // return require('beta').verb(); &#125;&#125;);包装模块define(function(require, exports, module) &#123; var a = require('a'); exports.action = function() &#123;&#125;&#125;);除了define外，AMD 还保留一个关键字require. require 作为规范保留的全局标识符，可以实现为 module loader，也可以不实现。AMD模式可以用于浏览器环境并且允许非同步加载模块，也可以按需动态加载模块。AMD 使用模块api: require(dependencies, callback);第一个参数dependencies为数组类型, 里面是当前回调函数需要依赖的模块第二个参数callback为回调函数, 当依赖加载完毕之后会执行这个回调函数, 函数的参数就是所加载的模块, 可在函数中使用例如:require(['math'], function(math)) &#123; math.add(2, 3);&#125;);AMD 规范的实现者 RequireJSRequireJS 是一个前端的模块化管理的工具库，遵循AMD规范，它的作者就是AMD规范的创始人 James Burke。所以说RequireJS是对AMD规范的阐述一点也不为过。RequireJS的思想是通过一个函数将所有需要的或者依赖的模块加载进来, 然后返回一个新的函数(或者模块), 我们所有关于新模块的业务代码都在这个函数里面进行, 其内部也可以无限制的使用已经加载进来的模块.&lt;script data-main='scripts/main' src='scripts/require.js'&gt;&lt;/script&gt;那么scripts下的main.js则是指定的主代码脚本文件，所有的依赖模块代码文件都将从该文件开始异步加载进入执行。RequireJS 的定义define和使用require都与之前说的 AMD 规范一致.CMDCMD 规范seajsCMD是SeaJS 在推广过程中对模块定义的规范化产出, 特点有如下两点:对于依赖的模块, AMD 是提前执行, 而 CMD 是延迟执行. (不过RequireJS从2.0开始，也改成可以延迟执行, 根据写法不同，处理方式不同.)AMD 推崇依赖前置, CMD 推崇依赖就近对比:// AMDdefine(['./a', './b'], function() &#123; // 依赖一开始就写好 a.test(); b.test();&#125;);// CMDdefine(function(require, exports, module) &#123; // 依赖就近 var a = require('./a'); a.test(); // 软依赖 if(status) &#123; var b = require('./b'); b.test(); &#125;&#125;)AMD也支持 CMD 的写法, 但依赖前置是官方的推荐做法AMD 的 api 是一个当多个用, CMD 严格的区分推崇职责单一, 例如 AMD 里面的require 分为全局的和局部的, 但是 CMD 里面没有全局的 require, 提供 seajs.use()来实现模块系统的加载启动.UMDUMD 是 CommonJS 和 AMD 的融合.AMD模块以浏览器第一的原则发展，异步加载模块。CommonJS模块以服务器第一原则发展，选择同步加载，它的模块无需包装(unwrapped modules)。这迫使人们又想出另一个更通用的模式UMD （Universal Module Definition）。希望解决跨平台的解决方案。UMD先判断是否支持Node.js的模块（exports）是否存在，存在则使用Node.js模块模式。在判断是否支持AMD（define是否存在），存在则使用AMD方式加载模块。判断过程如下:(function(window, factory) &#123; if(typeof exports = 'object') &#123; module.exports = factory(); &#125; else if(typeof define === 'function' &amp;&amp; define.amd) &#123; define(factory); &#125; else &#123; window.eventUtil = factory(); &#125;&#125;)(this, function()&#123; // module...&#125;)ES6 模块化经历了那么多探索以后, ES6终于在语言层面引入了模块化, 旨在成为服务端和浏览器端通用的解决方案, 模块功能主要由两个命令构成, export和import, export命令用于规定模块的对外接口，import命令用于输入其他模块提供的功能。// 定义模块 module.jslet basicNum = 0;const add = funtion(a, b) &#123; return a + b;&#125;export &#123; basicNum, add&#125;;// 引入模块import &#123; basicNum, add &#125; from './module';function foo() &#123; return add(2, basicNum);&#125;这种引入方式你需要知道模块内部导出的内容的具体名字, 在你引入的时候需要一字不差的对应上名字, 有很多时候我们并不想去模块内部查看它到底是用的什么名字, 这个时候 ES6 贴心的为我们额外提供了一个export default, 为模块指定一个默认输出, 对应的import不需要使用大括号, 这更加接近AMD 的引用写法.// 定义模块 module.jslet basicNum = 0;const add = funtion(a, b) &#123; return a + b;&#125;export default &#123; basicNum, add &#125;;// 引入模块import module from './module';function foo() &#123; return module.add(2, module.basicNum);&#125;需要注意的是ES6的模块不是对象, 它的import会被 JavaScript 引擎静态分析, 在编译的时候就引入模块代码, 而不是在运行的时候加载, 所以也就无法实现条件加载. 但是好处是这使得对代码进行静态分析成为可能.ES6模块与 CommonJS 的差异CommonJS 输出的是一个值得拷贝, ES6输出的是一个值的引用CommonJS 输出的是一个值的拷贝, 也就是说一旦已经输出, 那么模块内部之后再发生变动也不会影响这个已经输出的值.ES6的运行机制和 CommonJS 不一样, 当 js 引擎在进行静态分析的时候如果发现import那么就会生成一个对应模块的只读引用, 只有在运行的时候才根据这个引用到对应的模块去取值。 换句话说，ES6 的import有点像 Unix 系统的“符号连接”，原始值变了，import加载的值也会跟着变。因此，ES6 模块是动态引用，并且不会缓存值，模块里面的变量绑定其所在的模块。CommonJS 是运行时加载, ES6是编译时输出接口运行时加载: CommonJS模块是对象, 即在输入时先加载整个模块, 生成一个对象, 然后再从这个对象上面读取方法, 这种加载称为’运行时加载’编译时加载: ES6模块不是对象, 而是通过export命令显示指定输出的代码, import时采取静态命令的形式, 即在import时指定加载某个值, 而不是加载整个模块, 这种加载称为’编译时加载’.参考文章玉伯的回答模块化七日谈我是豆腐不是渣的文章"},{"title":"AST","date":"2018-09-24","updated":"2019-02-25","path":"AST/","link":"","text":"ASTAST 简介在计算机科学中, 抽象语法树(Abstract Syntax Tree, AST)或者简称语法树(Syntax Tree)是源代码语法解构的一种抽象表现, 它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构. – 维基百科而在 JavaScript 中我们通过 JavaScript Parser 把代码转化为一颗抽象语法树（AST），这颗树定义了代码的结构，通过操纵这颗树，我们可以精准的定位到声明语句、赋值语句、运算语句等等，实现对代码的分析、优化、变更等操作. 然后浏览器会把 js 源码通过解析器转为抽象语法树，再进一步转化为字节码或直接生成机器码. – 简书文章关于 Vue 的语法树解析可以查看这里AST 生成过程总的来说一段源代码在执行之前会经历如下过程:分词 / 词法分析: 将一个语句中的关键词进行提取, 例如let a = 3;, 分词提取之后得到let, a, =, 3, ;解析 / 语法分析: 在对上面已经被拆分提取过的关键词进行分析之后建立一课语法树(AST), 效果可参见下面底层代码生成: 得到语法树之后执行引擎(例如 chrome 的 v8引擎)会对这颗树进行一定的优化分析, 然后生成更底层的代码或者机器指令交由机器执行无图不真相, 我们借助一个在线的可视化工具或者esprima来具体看一下过程, 对于如下代码进行生成 AST 树源码:var a = 42;var b = 5;function addA(d) &#123; return a + d;&#125;var c = addA(2) + b;词法分析结果Keyword(var) Identifier(a) Punctuator(=) Numeric(42) Punctuator(;) Keyword(var) Identifier(b) Punctuator(=)Numeric(5) Punctuator(;) Keyword(function) Identifier(addA) Punctuator(() Identifier(d) Punctuator())Punctuator(&#123;)Keyword(return) Identifier(a) Punctuator(+) Identifier(d)Punctuator(;)Punctuator(&#125;) Keyword(var) Identifier(c) Punctuator(=) Identifier(addA)Punctuator(()Numeric(2) Punctuator()) Punctuator(+) Identifier(b) Punctuator(;)生成 AST 树或者我们可以使用 json 格式来查看&#123; \"type\": \"Program\", \"body\": [ &#123; \"type\": \"VariableDeclaration\", \"declarations\": [ &#123; \"type\": \"VariableDeclarator\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"a\" &#125;, \"init\": &#123; \"type\": \"Literal\", \"value\": 42, \"raw\": \"42\" &#125; &#125; ], \"kind\": \"var\" &#125;, &#123; \"type\": \"VariableDeclaration\", \"declarations\": [ &#123; \"type\": \"VariableDeclarator\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"b\" &#125;, \"init\": &#123; \"type\": \"Literal\", \"value\": 5, \"raw\": \"5\" &#125; &#125; ], \"kind\": \"var\" &#125;, &#123; \"type\": \"FunctionDeclaration\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"addA\" &#125;, \"params\": [ &#123; \"type\": \"Identifier\", \"name\": \"d\" &#125; ], \"body\": &#123; \"type\": \"BlockStatement\", \"body\": [ &#123; \"type\": \"ReturnStatement\", \"argument\": &#123; \"type\": \"BinaryExpression\", \"operator\": \"+\", \"left\": &#123; \"type\": \"Identifier\", \"name\": \"a\" &#125;, \"right\": &#123; \"type\": \"Identifier\", \"name\": \"d\" &#125; &#125; &#125; ] &#125;, \"generator\": false, \"expression\": false, \"async\": false &#125;, &#123; \"type\": \"VariableDeclaration\", \"declarations\": [ &#123; \"type\": \"VariableDeclarator\", \"id\": &#123; \"type\": \"Identifier\", \"name\": \"c\" &#125;, \"init\": &#123; \"type\": \"BinaryExpression\", \"operator\": \"+\", \"left\": &#123; \"type\": \"CallExpression\", \"callee\": &#123; \"type\": \"Identifier\", \"name\": \"addA\" &#125;, \"arguments\": [ &#123; \"type\": \"Literal\", \"value\": 2, \"raw\": \"2\" &#125; ] &#125;, \"right\": &#123; \"type\": \"Identifier\", \"name\": \"b\" &#125; &#125; &#125; ], \"kind\": \"var\" &#125; ], \"sourceType\": \"script\"&#125;AST的作用除了帮助执行引擎去生成底层的代码, AST 在我们常见的代码检查工具或者 webpack 中都可以用来作为代码分析的依据, 通过遍历 AST 树, 找出其中的隐藏问题, 或者提出优化的建议, 又或者是代码高亮或者代码压缩都是在分析这颗树的基础上进行的浏览器渲染过程首先我们看一下浏览器的深层结构:用户界面-包括地址栏, 返回按钮等 UI 组件, 除了主窗口浏览器引擎-用来查询和操作渲染引擎的接口渲染引擎-负责渲染请求的内容. 比如, 如果请求的资源是html, 那么渲染引擎负责解析 html 和 css, 然后把解析结果渲染到页面中js 引擎-用来解析执行 JavaScript 代码网络连接-用于处理网络请求, 如 http 请求. 这一部分是跨平台的UI 后台-用于渲染基础组件, 比如多选框和窗口等, 它暴露了一个不是特定平台的通用接口, 在底层调用了操作系统的用户接口数据存储-这是一个持久层. 浏览器在硬盘中存储各式数据, 比如 cookie , localStorage 等各个组件的关系如下:我们需要注意的是, js 引擎是单线程的, 但是浏览器是多线程的, 比如浏览器会同时开启js 引擎线程, 界面渲染线程, 事件触发线程, http 请求线程HTML5提出Web Worker标准，允许JavaScript脚本创建多个线程，但是子线程完全受主线程控制，且不得操作DOM。所以，这个新标准并没有改变JavaScript单线程的本质。接下来我们着重看一下渲染引擎所做的工作:总的过程是: 解析HTML并构建DOM树 =&gt; 构建render树 =&gt; render树布局 =&gt; render树绘制浏览器引擎开始解析 html, 并把标签转为内容树中的 dom 节点, 同时它也开始解析 css, 外链的 css 以及文件内的 css, 所有这些样式数据以及 html 中的可见性指令都用来构建另外一棵树, – render 树我们以Safari 和 chrome 使用的Webkit 引擎渲染过程如下:firefox使用的Gecko 引擎渲染过程如下:此小节内容参考与 segmentfault 上cucumber翻译的文章:浏览器工作过程详解（译）（一）浏览器工作过程详解（译）（二）"},{"title":"js-object","date":"2018-09-22","updated":"2019-02-25","path":"js-object/","link":"","text":"JavaScript的内存机制及按值传递JavaScript是一门轻级的编程语言, 我之前也用过C++和Java, 相比起来JavaScript是一门年轻简约的编程语言, 但是我很看好这门语言, 我记得之前看过一个大牛说现在的前端开发是黎明前的黑暗, 在数年之内必定会清晰明朗起来. 自己深表赞同, JavaScript现在的确是有很多的缺陷, 相比较起来它的依赖库也不如java那般丰富, 但是它一个最大的优点(个人认为)就是它的轻量级, 你仅仅需要一个浏览器(或者Node环境, 但是Node其实也是基于Chrome的V8引擎), 他就能完成自己所有的工作, 我坚信随着各种标准的制定以及已经走在探索路上的前端开发师们能够很快为JavaScript带来它起飞的春天.上面是我的个人希冀, 说到这篇文章, 主要是记录一下JavaScript的内存机制以及按值传递规则, 因为我在JavaScript的开发过程中会不由自主的把它和我也使用过的C++和Java进行比较, 我认为编程语言是互通的, 但是它们在某些细节上的处理有所不同, 则正是我们需要去注意的.内存机制在JavaScript中有堆和栈两个存储概念, 堆是用来存储Object型数据的 ,栈是用来存储6种基本数据类型(分别是null, undefined, boolean, number, string和ES6中新引入的symbol), 对于我们平时使用的数组Array其实是Object的继承而已, 可以使用typeof运算符查看一个数据的类型, 例如typeof []就会输出object, 另外一个比较特别的就是函数类型, 函数类型的typeof输出的是function, 但是函数其实也是存储在堆中的, 而且可以认为是以字符串的形式存储的.为什么有堆和栈之分与垃圾回收机制有关，为了使程序运行时占用的内存最小。当一个方法执行时，每个方法都会建立自己的内存栈，在这个方法内定义的变量会逐个放入这块栈内存里，随着方法的执行结束，这个方法的内存栈也将自然销毁了。因此，所有在方法中定义的变量都是放在栈内存中的;当我们在程序中创建一个对象时，这个对象将被保存到运行时数据区中，以便反复理由(因为对象的创建成本通常比较大),这个运行时数据区就是堆内存。堆内存中的对象不会随方法的结束而销毁，即使方法结束后，这个对象还可能被另一个引用变量所引用(方法的参数传递时很常见),则这个对象依然不会被销毁,只有当一个对象没有任何引用变量引用它时,系统的垃圾回收机制才会在核实的时候回收它。 –参考在我们知道了JavaScript中的对象是如何存储的之后, 我们就要看一下当我们生成一个变量的时候到底发生了什么.生成变量假如我们生成的是一个存储基本数据类型的变量, 例如let a = 3或者let b = &#39;hello&#39;, 那么有如下两步:在栈中直接开辟出一小块空间把你赋予的数据(3或者hello)存储到这个栈空间中也就是说数据是直接存储在栈中, 但是当我们生成的是一个存储了对象类型的变量, 例如let c = {name: &#39;krics&#39;}, 那么这个时候过程就要复杂一些:在堆中开辟一块空间把你赋予的数据{name: &#39;krics&#39;}存储到这个堆空间中在栈中开辟一小块空间将之前存储了对象数据的堆空间的地址(指针形式)存储到现在刚刚开辟的这个栈空间中所以我们真正的数据其实是存储在堆中的, 我们拿到的c变量里面只是存储了数据的真实地址, 当我们需要访问或者操作数据的时候, JavaScript就会根据这个地址去找到对应的数据, 然后访问或者操作它.值的拷贝我们需要永远记住最关键的一点: JavaScript中只存在按值传递!!!不同于C++中或者Java中经常出现的指针操作, 在JavaScript中不会出现按引用传递, JavaScript永远只操作一个变量最直接的值, 并不会考虑这个值是基本数据类型还是一个指针, 因为如果是指针, 也并不会去按照指针找到具体的数据, 然后拷贝数据什么的, 是指针, 那我就传递这个指针的字面值, 简单粗暴明了.例如:let a = 'hello';let b = a;b = 'yell';console.log(a); // =&gt; 'hello'console.log(b); // =&gt; 'yell'这里发生的故事是:在栈中开辟了一个空间叫a, 然后在a里面存入了一个字符串hello在栈中开辟了一个空间叫b, 然后在b里面存入了一个字符串hello(按值传递, 值是hello, 那么就再存一个hello)修改栈中b的值为yell输出a的值, 没被改变过, 所以输出hello输出b的值, 先是hello, 后来被改成了yell, 那么最后输出的就是yell那么我们举一个对象的例子又如何呢?let c = &#123;name: 'krics'&#125;;let d = c;c.name = 'leo';console.log(d.name); // =&gt; 'leo'd.name = 'troy';console.log(c.name); // =&gt; 'troy'这里发生的故事是:先在栈中开辟一块空间名字叫做c, 然后在堆中开辟一块空间, 存入数据{name: &#39;krics&#39;}, 然后把堆中刚存储的数据的地址存到c中在栈中开辟一块空间名字叫做d, 然后把c中存储的值也就是{name: &#39;krics&#39;}的地址在d中再存储一份将c指向的对象中的name的值改为字符串leo,d和c指向的是同一个对象, 所以第三步中通过c改了name的值以后, 通过d访问这个name时得到的也是改变后的值leo第五和第六步与第三和第四步做法类似这里给出一个很有趣的思考题:var a = &#123;n:1&#125;;var b = a;a.x = a = &#123;n:2&#125;;console.log(a.x); // =&gt; 想想这里 a.x 的值是什么console.log(b.x); // =&gt; 想想这里 b.x 的值是什么这里给个提示, 上面主要涉及到三个细节点, 一是JavaScript中正常运算顺序为从右到左, 二是.点运算符的优先级高于=等号, 三就是我们之前讨论过的对象如何赋值问题, 答案可以参考luoqua的文章最后我仍然要强调一点: JavaScript中只存在按值传递!!!(可以参考&lt;JavaScript高级程序设计&gt;一书中第四章’变量. 作用域和内存问题’)"},{"title":"bash","date":"2018-09-13","updated":"2019-05-16","path":"bash/","link":"","text":"常用的shell命令删除文件rm -f &lt;file&gt;rm -rf &lt;folder&gt;# 参数说明:# -r: 删除目录下所有文件, 包括目录本身# -f: 强制删除, 不确认# 移动文件mv &lt;originFile&gt; &lt;destDir&gt;# 使用 scp 从本地拷贝文件到远程服务器, 参数调换即可反向拷贝# 参数: 添加 -r 代表文件目录拷贝scp &lt;localFile&gt; username@hostname:&lt;remoteDir&gt;# linux查询系统版本lsb_release -a# 查看网络端口占用netstat -antp# 开启 nginx 在 nginx 目录下./sbin/nginx# 关闭 nginx./sbin/nginx -s stopmac# 清除 dns 缓存sudo killall mDNSResponder# Finder是否显示隐藏文件, No 为隐藏, Yes 为显示defaults write com.apple.finder AppleShowAllFiles No &amp;&amp; killall Finder# npm (批量更新包及相关依赖)[https://ask.helplib.com/javascript/post_134443]npm install -g npm-check-updatesnpm-check-updates -unpm install"},{"title":"flex","date":"2018-09-13","updated":"2019-02-25","path":"flex/","link":"","text":"flex布局关于flex布局的笔记"},{"title":"vue","date":"2018-09-13","updated":"2019-05-16","path":"vue/","link":"","text":"Vue 学习笔记最近开始学习 Vue 了, 在这里记录一下学习笔记.最近像没头的苍蝇一样盯着 Vue, 感觉好些地方不甚了解, 博客也搁置了快五天没动过笔了…Vue.extend()和Vue.component()两者都是使用参数来返回一个构建模板的构造方法, 不同的是vue.extend()返回的是一个匿名的构造器, 需要自己接收返回值注册名字, vue.component()可以在生成构造的函数的时候将组件名绑定上去, 所以后者可以看做是前者的语法糖. –参考Vue.set(target, prop, value)给实例添加动态响应的属性, 注意 target 不能是实例本身或者实例的根属性, 也就是说你不能给 data 加上根级的属性, 可以给 data 中的对象加上新属性,例如Vue.set(this.$data, &#39;name&#39;, &#39;krics&#39;)是会报错的, 但是Vue.set(this.$data.info, &#39;name&#39;, &#39;krics&#39;)是正确的.编译在生成单页面的 vue 应用时, 有模板与有 render 函数的区别"},{"title":"Docker","date":"2018-09-10","updated":"2019-05-16","path":"docker/","link":"","text":"docker学习笔记Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台.如无特殊说明, 以下操作环境均为CentOS 7, 内核版本位3.10.0-693.2.2.el7.x86_64(查看内核版本: uname -r)docker常用命令# 安装dockeryum install -y docker# 查看已安装的docker, 或者 docker infodocker version# 启动docker服务service docker start# 查看已下载的镜像 或 docker imagesdocker image ls # 从仓库抓取镜像到本地, Docker 官方提供的镜像都存放在 library 组里, 同时这也是默认的组# 例如 docker image pull library/hello-world 等价于 docker image pull hello-worlddocker image pull [imageName]# 删除已下载的镜像, 如果有使用该镜像创建的容器, 那么必须先删除对应的容器才能删除镜像docker image rm [imageName]# 从镜像创建容器并运行# 给个hello-world的测试例子, 由于本地没有hello-world这个镜像，所以会自动下载一个hello-world的镜像，并在容器内运行。docker run [imageName]# 列出正在运行的容器# dcoker container ls# docker contaienr ls --all 列出所有容器, 包括已停止的docker ps# 停止容器 或强制停止: docker container kill [containID]docker stop [containerId]# 启动已经停止的容器docker start [containerId]# 重启容器docker restart [containerId]# 删除容器docker rm [containerId]# 获取容器的输出信息docker logs [containerId]# 查看当前已经运行的容器(可以看到容器id: CONTAINER_ID)docker ps# 进入容器内部(推荐使用exec)docker exec -it [containerId] /bin/bash# 参数说明# -i 以交互方式运行，是阻塞式的# -t 分配一个伪终端，这个参数通常与-i参数一起使用，然后， 在后面跟上容器里的/bin/bash，这样就把我们带到容器里去了。# -d 以后台方式执行，这样，我们执行完这条命令，还可以干其他事情，写脚本最常用# 查看某个容器的日志docker container logs [containerId]# 在宿主机和容器之间拷贝文件, 容器未启动也可拷贝# docker cp containerId:from/path/to/file to/owner/pathdocker cp from/owner/path containerId:to/path/to/file# 查看各容器占用的系统资源docker stats# 保存对容器的更改, 生成一个新的镜像docker commit [containerId] [newImageName]编写一个 Dockerfile我们可以从一个 Dockerfile 来新建一个镜像来满足自己自定义的需求.我们一般会新建一个.dockerignore文件, 表示在拷贝文件到镜像中的时候要忽略哪些文件, 就像是.gitignore一样(语法也一样), 一般而言, 我们都会忽略诸如.git和node_modules/等文件夹# FROM 表示新建的镜像文件所依赖的基础镜像, 我这里是在8.12.0的版本的node镜像的基础上进行定制的FROM node:8.12.0# LABEL 指令用于向镜像中添加元数据，可以通过docker inspect命令查看, 比如下面指定该镜像维护者信息(旧的 MAINTAINER 字段已经废弃)LABEL maintainer=\"kricsleo.com\"# COPY 表示文件拷贝, 第一个参数是本机源文件路径, 第二个参数是镜像中的目的文件路径, 这里表示将当前文件夹下的内容全部拷贝到镜像中的`/workspace/node`目录中# 与 COPY 类似的命令是 ADD, ADD 的功能更丰富, 除了与 COPY 相同的作用外, 它还可以下载远程的文件拷贝进去, 还可以将压缩的文件自动解压后拷贝到镜像中COPY . /workspace/node# WORKDIR 指定镜像中接下来的工作目录, 命令等都将在这个目录上执行WORKDIR /workspace/node# RUN 表示新建镜像前要执行的命令, 这里执行了`npm install`将会安装项目的所有依赖, 这些依赖安装完成后都会被打包进入镜像文件中# RUN 命令可以有多个, 每一个 RUN 命令都会创建一层镜像, 类似于洋葱结构, 后面的 RUN 失败导致镜像构建失败时, 下次重新构建的话会从上一个成功的# 那一层镜像开始构建, 注意可以按照需求合并 RUN 命令, 可以避免多余的层级RUN npm install# EXPOSE 表示向外提供服务的端口号, 可以指定多个, 用空格分开即可, 一般我们可以在后面创建容器的时候使用`-p`参数来将宿主机和容器中暴露的端口号进行映射EXPOSE 3000# CMD 表示启动容器之后在容器中要运行的命令, 这里相当于告诉容器运行之后运行`/bin/bash`# 我们一般在从镜像启动容器的时候类似于`docker run -it &lt;image&gt; /bin/bash`, 这里最后的`/bin/bash`命令会覆盖我们指定的 CMD 命令# CMD 命令只能存在一个, CMD [command, param1, param2, ...], 后面的参数都会传递给这个命令CMD ['/bin/bash']Dockerfile 编写完成以后我们就可以来使用它构建一个镜像了.# build 表示开始构建镜像# -t 表示构建的镜像名和版本标签, 默认是 latest# -f 指定 Dockerfile 的路径# 最后的 . 表示工作环境为当前目录, 如果 Dockerfile 也在当前目录, 那么可以不用指定 -f 参数docker build -t [imageName:tag] -f [/path/to/Dockerfile] .参考资料:Dockerfile的编写docker中使用mysql# 下载mysql镜像docker pull mysql# 从镜像创建并运行一个容器docker run --name first-mysql -p 3306:3306 -e MYSQL\\_ROOT\\_PASSWORD=root -d mysql# 参数说明:# --name 指定容器独一无二的名字# -p mysql容器的端口映射# -e &lt;key=value&gt; 设置进入后可以使用的环境变量，这样动态指定比较灵活, 'MYSQL\\_ROOT\\_PASSWORD'字段指定的是 root# 用户的密码# -d 表示使用守护进程, 即服务挂在后台在我本机连接阿里云上的ECS中的mysql容器时无法连接, 后来排查使用如下解决方案:编辑ECS的安全组规则把mysql的通信端口3306加入到允许列表中, 如果你是把docker里面的mysql的端口映射到ECS的其它端口, 比如3307, 那么这里你就把这个映射之后的端口3307加入到运行列表即可;编辑ECS的防火墙ECS的防火墙可能会拦截3306端口的通信, 那么你需要打开这个端口, 让防火墙允许端口通信, 我的ECS系统是CentOS7, 在CentOS7中是使用firewall来管理端口通信的, 那么使用如下方法加入3306端口:# 永久加入3306端口firewall-cmd --zone=public --add-port=3306/tcp --permanent# 参数说明:# –zone 作用域# –add-port=80/tcp 添加端口，格式为：端口/通讯协议# –permanent 永久生效，没有此参数重启后失效# 重启防火墙生效firewall-cmd --reload另外附上常用防火墙命令:# 关闭防火墙systemctl stop firewalld#打开防火墙systemctl start firewalld#查看防火墙状态firewall-cmd --state安装 Elasticsearch我安装的版本是6.5.4, 需要指定版本安装, 因为没有默认的’lastest’版本# -it 参数代表分配并且进入该容器的终端, 可以看到命令行详细的启动过程, 也可以进行命令交互# -d 参数代表在后台守护该容器的进程一直运行# --name: 为此次运行的容器起一个好记的名字# 使用 -e 指定多个参数, 因为我服务器是个只有1G内存的小水管, 而 es 在5版本之后的默认最大内存使用是2G, 所以我# 指定了 ES_JAVA_OPTS=\"-Xms200m -Xmx200m\" 参数来限制最大使用 200m 堆内存, 但是不知道怎么回事, 内存还是会一直往上飙,# 会远远超过我指定的内存# 指定 NETWORK_HOST=\"0.0.0.0\", 可以让 es 接受来自任意ip地址的访问# 最后指定了本次启动的容器从 docker.io/elasticsearch:6.5.4 镜像创建docker run -d --name es -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=\"-Xms150m -Xmx150m\" -e NETWORK_HOST=\"0.0.0.0\" docker.io/elasticsearch:6.5.4安装 elasticsearch-head# elasticsearch-head 使用的端口是9100docker run -d -p 9100:9100 docker.io/mobz/elasticsearch-head:5然后访问ip:9100, 在页面上填入 es 的地址ip:9200, 如果无法连接, 那么需要在 es 的配置文件 elasticsearch.yml中添加参数# 如果启用了 HTTP 端口，那么此属性会指定是否允许跨源 REST 请求http.cors.enabled: true# 如果 http.cors.enabled 的值为 true，那么该属性会指定允许 REST 请求来自何处http.cors.allow-origin: \"*\"安装中文分词 ik进入 es 容器中, 使用 es 自带的命令安装插件# 注意安装对应 es 版本的 ik 分词插件, 我的 es 是6.5.4, 所以安装的6.5.4的 ikelasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.5.4/elasticsearch-analysis-ik-6.5.4.zipelasticsearch 的使用参考使用 Elasticsearch 实现博客站内搜索初始化和写入数据都可以了, 但是现在碰到一个问题, 我的博客主站是托管在 github 上的, github 只提供静态资源服务, 那么我这个部署在阿里云上的 es 要如何联动起来使用上搜索功能呢?通过 nginx 分发?目前使用 nginx 分发达到了在备用域名 try.kricsleo.com 上可以调用部署在阿里云上的 es 服务放出我的博客文章的 mapping&#123; index: 'blog', type: 'article', body: &#123; properties: &#123; title: &#123; type: 'text', term_vector: 'with_positions_offsets', analyzer: 'ik_max_word', search_analyzer: 'ik_max_word' &#125;, subtitle: &#123; type: 'text', term_vector: 'with_positions_offsets', analyzer: 'ik_max_word', search_analyzer: 'ik_max_word' &#125;, content: &#123; type: 'text', term_vector: 'with_positions_offsets', analyzer: 'ik_max_word', search_analyzer: 'ik_max_word' &#125;, link: &#123; type: 'text' &#125;, author: &#123; type: 'text', &#125;, categories: &#123; type: 'keyword', &#125;, tags: &#123; type: 'keyword', &#125;, create_date: &#123; type: 'date', index: false &#125;, update_date: &#123; type: 'date', index: false &#125; &#125; &#125;&#125;搜索时使用的生成 DSL 查询语句的方法const generateDSL = (query = '', from = 0, size = 10) =&gt; (&#123; index: 'blog', type: 'article', q: query, from, size, body: &#123; query: &#123; dis_max: &#123; queries: [ &#123; match: &#123; title: &#123; query: keyword, minimum_should_match: '50%', boost: 4, &#125; &#125; &#125;, &#123; match: &#123; subtitle: &#123; query: keyword, minimum_should_match: '50%', boost: 4, &#125; &#125; &#125;, &#123; match: &#123; content: &#123; query: keyword, minimum_should_match: '75%', boost: 4, &#125; &#125; &#125;, &#123; match: &#123; tags: &#123; query: keyword, minimum_should_match: '100%', boost: 2, &#125; &#125; &#125;, &#123; match: &#123; categories: &#123; query: keyword, minimum_should_match: '100%', boost: 2, &#125; &#125; &#125; ], tie_breaker: 0.3 &#125; &#125;, highlight: &#123; pre_tags: ['&lt;b&gt;'], post_tags: ['&lt;/b&gt;'], fields: &#123; title: &#123;&#125;, content: &#123;&#125;, &#125; &#125; &#125;&#125;);参考资料使用 Elasticsearch 实现博客站内搜索Docker 入门教程docker安装elasticSearch以及系列插件Docker安装elasticsearch5（爬坑心得）: 内存不足无法启动 es 解决方法"},{"title":"Practical-Function-In-Javascript","date":"2018-09-07","updated":"2019-02-25","path":"practical-function-in-javascript/","link":"","text":"JavaScript中的常用函数本文主要整理了平时JavaScript中常用的函数, 持续更新.数组Array.concat()作用: 合并数组, 返回新数组, 不影响原数组备注: 字符串中也有此同名函数, 作用可类比Array.filter()作用: 对数组每个元素进行测试, 返回符合条件的元素组成的新数组, 不影响原数组Array.find()作用: 返回数组中满足提供的测试函数的第一个元素的值, 否则返回 undefinedArray.forEach()作用: 对数组的每个元素执行一次提供的函数, 不影响原数组Array.includes()作用: 判断数组是否包含某个值, 是则返回true, 否则返回false备注: 字符串中也有此同名函数String.includes(subSring, fromIndex), 用于判断字符串是否包含另一个字符串Array.indexOf()作用: 返回数组中给定元素的索引值，若给定元素不存在，则返回值是-1备注: 字符串中也有此同名函数, 作用可类比Array.join()作用: 将数组中的所有元素用给定方式连接成一个字符串，默认用，连接, 可用空字符串&#39;&#39;连接, 返回连接后的字符串, 不影响原数组Array.map()作用: 对数组中的每个元素都调用一个提供的函数后返回的结果组成一个新数组, 返回新数组, 不影响原数组Array.reduce(callback[accumulator, currentValue, currentIndex, array], initialValue)作用: 对累加器和数组中的每个元素（从左到右）应用一个函数，将其减少为单个值, 返回最后的计算结果, 此函数功能强大, 建议参考官方文档Array.slice()作用: 将数组的制定部分(包括开始位置, 不包括结束位置)浅拷贝到一个新数组, 返回拷贝的新数组, 不影响原数组备注: 字符串中也有此同名函数, 作用可类比Array.splice()作用: 通过删除现有元素和/或添加新元素来更改一个数组的内容, 返回被删除的元素组成的数组, 如果没有删除, 则返回空数组, 会改变原数组, 此函数功能强大, 建议参考官方文档字符串String.charAt()作用: 返回字符串中指定位置的字符, 不存在则返回空字符串&quot;&quot;String.charCodeAt()作用: 返回字符串中指定位置的字符的UTF-16代码单元值的数, 在0到65535之间, 超出范围返回NaNString.match()作用: 将字符串与正则表达式匹配, 返回匹配后的结果数组,数组的第一项是进行匹配完整的字符串，之后的项是用圆括号捕获的结果。如果没有匹配到，返回null, 不影响原数组如果给的参数不是正则表达式, 那么会隐式的转换成正则表达式, 此函数功能很强大, 请参考官方文档备注: RegExp.text()用来测试字符串是否与正则匹配 速度会更快, 如果匹配则返回true, 否则返回falseString.search()也类似test()方法, 只不过返回的值是第一个匹配的地方的索引值, 如果没有匹配则返回-1RegExp.exec()的行为和String.match()很相似, 在非全局匹配下表示一样, 但是对于全局匹配/g他们的表现就不同, 简单来说就是match()的全局匹配会一次找到全部的匹配项放在数组中返回, 但是exec()的全局匹配是每调用一次exec()就返回在上一次执行的基础上继续搜索的下一个匹配结果, 直到最后找不到的时候就会返回null, 参考这里Sring.replace()作用: 将字符串中的匹配值(字符串或者正则表达式匹配到的值)用另外的值(替换的字符串或者一个方法返回的值)替换, 然后返回新的字符串, 不影响原字符串使用字符串匹配时只会替换第一个匹配的结果关于第二个参数如果使用字符串, 那么$&amp;, $n, ...等能够作为代替匹配的结果字符串使用, 如果使用函数, 那么match, p1, p2, ...能够代替匹配的结果在函数参数中使用, 具体请参见官方文档可使用正则表达式全局匹配实现全局替换, 例如&#39;hello, yello&#39;.replace(/llo/g, &#39;yes&#39;)String.split()作用: 将字符串按照匹配的字符串或者正则表达式进行分割, 返回分割的结果组成的数组, 不影响原字符串关于分割的结果中有时会产生空字符串&#39;&#39;的原因可以参考KevinYue的这篇文章, 评论中的’切黄瓜’的比喻也有助于理解, 另外使用正则表达式时会忽略全局匹配符/gString.substr()作用: 将字符串中从指定位置开始的指定长度(不指定长度则到字符串末尾)的部分拷贝为新字符串返回, 不影响原字符串String.substring()作用: 将字符串中从指定位置开始(包含)到指定位置结束(不包含)(或者默认到结尾)的部分拷贝伟新字符串返回, 不影响原字符串String.trim()作用: 返回字符串开头和结尾的空白字符(包括space, tab, no-break space等以及所有行终止符字符如 LF，CR)都移出的新字符串, 不影响原字符串其他平时的笔记Object.freeze(obj)冻结一个对象, 冻结了之后这个对象的所有属性都不可被修改, 尝试修改不报错但是会不生效, 返回被冻结之后的对象, 并不是传入参数的一个副本, 而是传入的对象本身, 只是进行了属性冻结.Element.scrollIntoView()HTML5原生的滚动API, 使得一个元素滚动到试图中, 兼容到IE8, 主流浏览器均支持.三种调用形式:element.scrollIntoView(); // 等同于element.scrollIntoView(true)element.scrollIntoView(alignToTop); // Boolean型参数(true代表元素顶部尽可能与浏览器顶部对齐, false代表元素底部尽可能与浏览器底部对齐)element.scrollIntoView(scrollIntoViewOptions); // Object型参数scrollIntoViewOptions里面支持三个参数:&#123; behavior: \"auto\" | \"instant\" | \"smooth\", // 默认 auto, 滚动动画, auto 和 instant 都是无动画立即到底目的位置, smooth 为带动画 block: \"start\" | \"center\" | \"end\" | \"nearest\", // 默认 center, 垂直方向对齐方式, start 顶部对齐, center 中间对齐, end 底部对齐, nearest 就近对齐(意思是现在的位置靠近哪种对齐方式就采用哪种对齐方式, 移动最小) inline: \"start\" | \"center\" | \"end\" | \"nearest\", // 默认 nearest, 水平方向对齐方式, 具体参数含义和 block 类似&#125;参考文档1"},{"title":"Mini-Program","date":"2018-09-06","updated":"2019-04-08","path":"Mini-Program/","link":"","text":"微信小程序跳坑记录开发微信小程序还是踩了不少坑的, 官方的文档并不详细, 更新也不及时, 碰到问题还是多 google 吧.摘要小程序的逻辑层和渲染层是分开的, 逻辑层运行在 JSCore 中 并没有一个完整的浏览器对象, 因而缺少相关的 DOM API 和 BOM API.小程序的运行环境 –参考运行环境逻辑层渲染层IOSJavaScriptCoreWKWebView安卓 2X5 J\bSCoreX5 浏览器开发工具NWJSChrome WebView小程序的 Native 和 js 之间的交互是通过 JSBridge 实现小程序的视图线程和服务线程的交互生命周期小程序的文件编译过程:WXml -&gt; js -&gt; Virtual DOM -&gt; DOM TreeWXSS -&gt; js -&gt; CSS数据绑定微信小程序通过状态模式-单向数据流来实现数据绑定.状态模式定义一个对象, 当对象发生改变时, 状态就发生改变, 然后通知与之绑定的视图刷新, 注意: 数据流向是单向的, \b 即视图变化不会引起对象状态变化.如果想要视图改变的时候让对象状态也一并改变, 那么就需要依赖事件来实现, 即视图变化 -&gt; 触发事件 -&gt; 捕获事件 -&gt; 回调处理(在这里可以操作对象)生命周期小程序整个小程序有三个生命阶段:小程序初始化完成时: onLaunch小程序启动，或从后台进入前台显示时: onShow小程序从前台进入后台时: onHide关于小程序的销毁有如下机制: 点击左上角关闭或者’Home’键离开微信, 小程序将在后台运行, 只有在后台超过一定时间或者系统内存占用过高时才会真正销毁小程序 –参考页面栈目前页面栈最大深度是 10 层 –来源一旦达到 10 层, 将无法再使用wx.navigatoTo()或同等方式打开新页面, 必须使用其他方式清除一定的栈空间以后才能再打开新页面路由方式: 五种wx.navigateTo()或者点击&lt;navigator open-type=&quot;navigateTo&quot;/&gt;组件页面栈变化: 仅目标页面(不能是tab页)入栈wx.navigateBack()或者点击&lt;navigator open-type=&quot;navigateBack&quot;&gt;组件或者点击左上角返回按钮页面栈变化: 仅源页面出栈备注: 该方法可在参数(Ojbject)中额外附加一个 Number 型参数delta, 表示返回的页面数, 也就是要退几次页面栈, 如果delta大于当前栈数, 则返回首页wx.redirectTo()或者点击&lt;navigator open-type=&quot;redirectTo&quot;/&gt;组件页面栈变化: 源页面出栈 -&gt; 目标页面(不能是tab页)入栈wx.switchTab()或者点击&lt;navigator open-type=&quot;switchTab&quot;/&gt;组件页面栈变化: 清空页面栈 -&gt; 目标页面(必须是tab页)入栈wx.reLaunch()或者点击组件&lt;navigator open-type=&quot;reLaunch&quot;/&gt;组件页面栈变化: 清空页面栈 -&gt; 目标页面(任意页面)入栈同一页面如果被压栈多次, 那么就会在栈中相应的存在多次, 相当于页面顺序浏览的历史记录页面生命周期从页面栈的变化解释页面的生命周期:页面刚入栈在栈顶: onLoad -&gt; onShow -&gt; onReady页面从栈顶被压栈到第二层: onHide页面从栈的第二层到最底层之间活动: 无事件页面退栈刚到栈顶: onShow页面从栈顶出栈: onUnload (注意: 页面出栈即被销毁, 不会触发onHide, 直接触发onUnload)一个页面要正常显示，必须经历 3 个生命周期：加载 -&gt; 显示 -&gt; 渲染, 对应回调函数顺序:onLoad -&gt; onShow -&gt; onReady.官方给出的示例中onReady放在onShow之前, 但是这并不是真正的顺序, 容易误导开发者组件hidden 属性首先强调一点: 不要使用hidden属性!语法正确的写法是hidden=&quot;true&quot;和hidden=&quot;false&quot;, 遵循Mustache语法, 双大括号不能省略, 因为hidden的值是Boolean型的, 必须使用Mustache计算值才行, 如果省略了双大括号, 比如hidden=&quot;false&quot;(填写其它内容也一样)), 那么就会把&quot;false&quot;作为字符串处理, 此时字符串不为空, 那么结果就是true, 此组件仍然会被隐藏.为什么不要使用该属性hidden属性的表现相当怪异.根据不完全测试, 在view, navigator等组件上表现为会给你的组件添加一个 css 属性display: none;, 如果你是通过id或者class来给组件加上自定义的display属性的话, 那么hidden添加的那个display属性优先级比你的高, 此时组件会被隐藏; 如果你是使用的内联样式style=&quot;display: flex;&quot;来给组件添加display属性, 那么你这里添加的display属性优先级会比较高, 此时hidden属性不生效;在button组件上添加hidden=&quot;true&quot;表现为会给你的组件上添加一个 css 属性display: none !important;, 这里相比之前多了!important关键字, 所以此时的hidden属性的优先级是最高的, 不会被你自定义的给覆盖掉;在text组件上又是一种表示了, 如果你为text组件添加hidden=&quot;true&quot;, 那么只要你给这个组件自定义了display属性, 你的优先级就会比hidden的高, hidden处于不生效的状态, 如果你没有自定义, 那么hidden才会生效;基于上面的种种怪异的表现, 已经不需要去测试更多的组件了, 因为这已经有足够充分的理由不去使用hidden属性了.替代办法我们使用hidden属性无非是想控制组件的显示与否, 那么可以采取如下的替代方案:&lt;view style=\"display: &#123;&#123;isHidden ? 'none' : 'flex'&#125;&#125;;\"&gt;&lt;/view&gt;备注对于不怎么切换显示隐藏的组件可以使用wx:if, 这样的渲染支出是可以接受的, 但是如果一个组件会经常的切换显示隐藏, 那么最好考虑采取display: &quot;none;&quot;的方法, 因为这样不需要重复渲染组件, 只要切换显示隐藏即可, 可以减少 cpu 支出, 提高页面效率. 官方说法scroll-view注意：使用竖向滚动时，需要给scroll-view一个固定高度, 否则无法点击回到顶部以及滚动到指定位置texttext组件内只支持嵌套textcover-view在ios中如果cover-view内的文字使用了rotate旋转, 那么文字将会显示不全, 只能显示一个文字, 官方bug没有修复, 见cover-view使用transform rotate后内容会被裁剪, 目前的做法最简单的是把文字做成图片, 另一种很麻烦的做法是一个cover-view一个文字, 计算每个cover-view的文字, 最后拼成整行的文字.requestGET一般都正常, 但是POST请求真可谓是’一千个读者有一千个哈姆雷特’, 各种失败的情况都有, 可尝试如下方法:首先method是必须设置为POST的;header中设置&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, 也有说小写&quot;content-type&quot;: &quot;application/x-www-form-urlencoded&quot;能成功;data 有说不能直接传json格式, 需要先转格式:function json2Form(json) &#123; var str = []; for(var p in json)&#123; str.push(encodeURIComponent(p) + \"=\" + encodeURIComponent(json[p])); &#125; return str.join(\"&amp;\");&#125;let data = &#123; name: '张三', age: '23'&#125;;const ajaxData = json2Form(data); // 然后将`ajaxData`附在请求的`data`中字段中也有说服务端必须是https的;实在不行服务端就改成GET吧…域名小程序对于服务器的域名有要求, 在开发时如果没有 https 的服务器, 那么 pc 端可以把微信开发工具里的域名校验展示关闭, ios 端打开调试模式运行小程序, 安卓端打不打开调试模式都可以, 之后如果申请到了 https 的服务器, 那么把服务器域名加入到微信管理平台的域名列表中, 然后就可以关闭各种之前调试的东西正常使用了.源码分析对小程序的源码分析应该会是比较大的工作量, 所以我打算另外用一篇文章来记录, 这里先挖下一个坑 微信小程序源码分析"},{"title":"ASCII-Unicode-UTF8","date":"2018-09-05","updated":"2018-09-29","path":"unicode-utf8/","link":"","text":"ASCII, Unicode和UTF8之间的关系本文主要了解一下ASCII码、Unicode码和UTF-8码的来源和相互之间的关系, 顺便也理了一下中文编码GB2312, GBK, GB18030的关系。ASCII码在上世纪60年代，美国制定了ASCII码，主要目的是为了用二进制编码的方式来表达英文字符，用一个8位的字节大小对应了128个字符，其中包括了可打印出来的96个字符和32个不可打印的控制字符, 规则是二进制中第1位固定为0, 后面7位用来编码, 刚好可以表示27 = 128个字符, 例如规定空格SPACE的编码为00100000, 十进制是32, 大写字母A的编码为01000001, 十进制是65, 附上ASCII码表GB2312, GBK, GB18030GB2312 是对 ASCII 的中文扩展, 一个小于127的字符的意义与ASCII码相同, 但是当两个大于127的字符连在一起时就表示汉字, 同时GB2312在127之外的地方把ASCII已经有的数字, 标点和字母又重新加入了一遍, 这些重新加入的字符占用两个字节的空间, 也就是说在GB2312中有两套数字, 字母和标点, 码值小于127的那一套因为是ASCII码, 只占用一个字节, 就叫’半角’符号, 而新加入的一套数字, 字母和标点就叫’全角’符号.因为GB2312只收录了6763个汉字, 很多的汉字也需要加入编码中, 所以微软对GB2312进行了扩展, 规定只要第一个字节大于127, 那么就不管后面一个字节是不是大于127的, 通通都认为这两个字节一起表示了一个汉字, 这样就又增加了近20000个新的汉字（包括繁体字）和符号, 扩充之后就成为GBK标准, 它向下兼容GB2312编码，出现于Windows 95简体中文版中, 但是这个是微软标准, 并不是国家标准.后来又加入了少数民族文字，于是我们再扩展，又加了几千个新的少数民族的字，GBK扩成了GB18030, GB18030成为了国家标准.Unicode码ASCII码虽然满足了美国的需求,但是对于其它语言而言128个字符是远远不够的, 比如法语中字母上方有注音, 这是ASCII码无法表示的, 又比如汉字有10万左右, 这也是超出了ASCII码的范围, 所以后来Unicode码出现了.Unicode码有着很大的容量, 现在的规模可以容纳100多万个符号, 每个符号的编码都不一样, 比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字严。你可以使用在线的工具来转换成Unicode码.Unicode码编码方式Unicode码只是定义了每个字符对应的二进制代码是什么, 但是并没有规定字符对应的二进制应该以什么样的形式存储, Unicode统一规定，每个符号用三个或四个字节表示. 比如汉字严的Unicode码是十六进制数4E25, 转换成二进制就是100111000100101一共是15位, 至少占用2个字节的空间, 而其他的字符可能有更多的二进制位数, 而之前的ASCII码是固定为8位的, 如果采取将前面多余的位数全都置0的话, 那么在存储原来的ASCII码编码的文件时就会浪费大量的空间来存储无用的0信息, 这是不可接受的. 所以如何合理的用Unicode码来兼容原先的ASCII码信息就产生出了多种具体的实现方式.UTF-8实现UnicodeUTF-8是目前使用最多的Unicode编码实现方式, 除此之外也有 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示）实现方式, 不过基本不使用.UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。按照如下两条规则来编码字符:对于单(n = 1)字节的符号，字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。对于多(n &gt; 1)字节的符号，第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。下表总结了编码规则，字母x表示可用编码的位。Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）----------------------+---------------------------------------------0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx在解码的时候现查看二进制的第一位, 如果是0, 那么说明是单字节的字符, 直接将该字节按照Unicode码表转换成对应的字符即可, 如果第一位是1, 那么继续查看有几个连续的1, 有n个, 则说明连续的n个字节代表一个字符.以汉字严为例, \b严的Unicode码是4E25(二进制为100111000100101), 根据上表, 4E25处于0000 0800 - 0000 FFFF范围, 那么严的编码格式就是1110xxxx 10xxxxxx 10xxxxxx, 也就是说严的UTF-8编码方式就需要占用三个字节, 我们把严的二进制按照顺序填到x的位置, 最后得到的结果就是11100100 10111000 10100101, 转成16进制就是E4B8A5, 这就是严的UTF-8编码结果.总得来说, 严的Unicode码为4E25, UTF-8编码为E4B8A5, 这就好比你的身份证是123456, 在学校站队时老师按照一定的排队方式把你编排到了五组三排第二个, 这两者最后的结果是可以相互转换的, 你可借助在线工具验证.JavaScript中的Unicode与UTF-8javascript程序是使用Unicode字符集编写的, 所以我们在JavaScript中经常使用的字符或者字符串实际上内部是采用Unicode编码的, 在有些情况下, 比如我们的服务器要求接受的二进制内容的编码必须是UTF-8, 那么我们在把JavaScript中的字符串发送到服务器之前就需要进行转码, 将Unicode字符串转为UTF-8字符串. 我们在前端有时候会看到的服务器返回的json数据中乱码实际上就是因为服务器发送数据的编码跟我们客户端接受数据的编码方式不一致导致的, 你可以试着将乱码字段拷贝到在线工具中进行转码, 比如选择将Unicode转为UTF-8, 然后你就能看到正确的信息.除了数据交互之外, 浏览器的URI也是我们能够了解这种编码转换的地方, 因为URI中的querystring必须按照UTF8的编码进行传输, 但是JavaScript中是Unicode的, 如果没有中文信息还好, 因为英文字符在这两者之间的码值是保持一致的, JavaScript的字符串hello到了URI中也还是hello, 如果你不手动去转换也是ok的, 但是一旦涉及到中文(包括其它非英文字符), 比如汉字严, 它的Unicode码值和UTF-8码值就差的很远, 如果你不进行手动转换, 直接将JavaScript中的字符严丢到地址栏的URI中, 那么就会导致URI乱码, 你再想从URI中把之前放进去的严取出来就会发现得到的根本不是汉字严, 而是一串乱码.在JavaScript中如何转换Unicode与UTF-8浏览器提供了三对方法来进行编码转换,escape/unescape, encodeURI/decodeURI和encodeURIComponent/decodeURIComponent.第一对escape/unescape是非标准的, 已经被废弃, 这里只说一下它的转码方式, escape在处理大于127的字符时是在字符的Unicode码前面直接加上一个%u, 例如严的Unicode码为4E25, 那么escape(&#39;严&#39;)的结果就是%u4E25, 再次强调, 请不要使用escape/unescape, 它已被废弃;第二对encodeURI/decodeURI是用来给整个URL进行转码的, 它不会转义&amp;, ?, /, =这样的功能字符;第三对encodeURIComponent/decodeURIComponent是用来给URL的部分字段进行转码的, 它会对&amp;, ?, /, =这些特殊字符进行转义, 一般用来处理key-value形式的query字段.encodeURI和encodeURIComponent都是先将非英文字符的Unicode码转为UTF-8码, 然后在每个字节前面都加上一个%, 比如汉字严的Unicode码是4E25, 使用encodeURI编码时会先转成UTF-8码E4 B8 A5, 在用%连接起来就得到最后结果%E4%B8%A5.//编码encodeURIComponent('严'); // =&gt; '%E4%B8%A5'//解码decodeURIComponent('%E4%B8%A5'); // =&gt; '严'//encodeURI和encodeURIComponent对比encodeURI('www.kricsleo.com?name=\"张三\"'); // =&gt; \"www.kricsleo.com?name=%22%E5%BC%A0%E4%B8%89%22\"encodeURIComponent('www.kricsleo.com?name=\"张三\"') // =&gt; \"www.kricsleo.com%3Fname%3D%22%E5%BC%A0%E4%B8%89%22\"我们也可以自己用js来使用Unicode和UTF-8之间的相互转换/** * 将字符串格式化为UTF8编码的字节 */const toUTF8 = function (str, isGetBytes) &#123; var back = []; var byteSize = 0; for (var i = 0; i &lt; str.length; i++) &#123; var code = str.charCodeAt(i); if (0x00 &lt;= code &amp;&amp; code &lt;= 0x7f) &#123; byteSize += 1; back.push(code); &#125; else if (0x80 &lt;= code &amp;&amp; code &lt;= 0x7ff) &#123; byteSize += 2; back.push((192 | (31 &amp; (code &gt;&gt; 6)))); back.push((128 | (63 &amp; code))) &#125; else if ((0x800 &lt;= code &amp;&amp; code &lt;= 0xd7ff) || (0xe000 &lt;= code &amp;&amp; code &lt;= 0xffff)) &#123; byteSize += 3; back.push((224 | (15 &amp; (code &gt;&gt; 12)))); back.push((128 | (63 &amp; (code &gt;&gt; 6)))); back.push((128 | (63 &amp; code))) &#125; &#125; for (i = 0; i &lt; back.length; i++) &#123; back[i] &amp;= 0xff; &#125; if (isGetBytes) &#123; return back &#125; if (byteSize &lt;= 0xff) &#123; return [0, byteSize].concat(back); &#125; else &#123; return [byteSize &gt;&gt; 8, byteSize &amp; 0xff].concat(back); &#125;&#125;toUTF8('严'); // =&gt; [0, 3, 228, 184, 165]/** * 读取UTF8编码的字节，并转为Unicode的字符串 */const fromUTF8 = function (arr) &#123; if (typeof arr === 'string') &#123; return arr; &#125; var UTF = '', _arr = arr; for (var i = 0; i &lt; _arr.length; i++) &#123; var one = _arr[i].toString(2), v = one.match(/^1+?(?=0)/); if (v &amp;&amp; one.length == 8) &#123; var bytesLength = v[0].length; var store = _arr[i].toString(2).slice(7 - bytesLength); for (var st = 1; st &lt; bytesLength; st++) &#123; store += _arr[st + i].toString(2).slice(2) &#125; UTF += String.fromCharCode(parseInt(store, 2)); i += bytesLength - 1 &#125; else &#123; UTF += String.fromCharCode(_arr[i]) &#125; &#125; return UTF&#125;fromUTF8([0, 3, 228, 184, 165]); // =&gt; '严'参考资料:阮一峰的博客: https//www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.htmlsegmentfault上张亚涛的专栏: https://segmentfault.com/a/1190000005794963"},{"title":"Airbnb-JavaScript-Style-Guide","subtitle":"Airbnb 代码规范阅读笔记","date":"2018-09-05","updated":"2019-05-15","path":"Airbnb-JavaScript-Style-Guide/","link":"","text":"Airbnb JavaScript Style Guide 阅读笔记Airbnb的JavaScript代码风格是世界上最流行的JavaScript代码风格之一, 在阅读的时候结合我自己的使用经验记录如下重点, 日后多次阅读应该会持续更新.在线阅读地址: https://github.com/airbnb/javascript(中文翻译版: https://github.com/yuche/javascript)对象使用字面值创建对象// badconst item = new Object();// goodconst item = &#123;&#125;;使用对象方法的简写// badconst atom = &#123; value: 1, addValue: function (value) &#123; return atom.value + value; &#125;,&#125;;// goodconst atom = &#123; value: 1, addValue(value) &#123; return atom.value + value; &#125;,&#125;;数组使用字面值创建数组// badconst items = new Array();// goodconst items = [];使用扩展运算符...复制数组// badconst len = items.length;const itemsCopy = [];let i;for (i = 0; i &lt; len; i++) &#123; itemsCopy[i] = items[i];&#125;// goodconst itemsCopy = [...items];使用Array#from把类数组对象转为数组const foo = document.querySelectorAll('.foo');const nodes = Array.from(foo);解构使用解构存取和使用多属性对象// badfunction getFullName(user) &#123; const firstName = user.firstName; const lastName = user.lastName; return `$&#123;firstName&#125; $&#123;lastName&#125;`;&#125;// goodfunction getFullName(obj) &#123; const &#123; firstName, lastName &#125; = obj; return `$&#123;firstName&#125; $&#123;lastName&#125;`;&#125;// bestfunction getFullName(&#123; firstName, lastName &#125;) &#123; return `$&#123;firstName&#125; $&#123;lastName&#125;`;&#125;对数组使用解构赋值const arr = [1, 2, 3, 4];// badconst first = arr[0];const second = arr[1];// goodconst [first, second] = arr;回传对个对象时, 使用对象解构, 而不是数组解构为什么？增加属性或者改变排序不会改变调用时的位置。// badfunction processInput(input) &#123; // then a miracle occurs return [left, right, top, bottom];&#125;// 调用时需要考虑回调数据的顺序。const [left, __, top] = processInput(input);// goodfunction processInput(input) &#123; // then a miracle occurs return &#123; left, right, top, bottom &#125;;&#125;// 调用时只选择需要的数据const &#123; left, right &#125; = processInput(input);字符串程序化生成字符串时使用模板字符串代替字符串连接模板字符串更简洁, 根据可读性// badfunction sayHi(name) &#123; return 'How are you, ' + name + '?';&#125;// badfunction sayHi(name) &#123; return ['How are you, ', name, '?'].join();&#125;// goodfunction sayHi(name) &#123; return `How are you, $&#123;name&#125;?`;函数使用函数声明代替函数表达式因为函数声明是可命名的, 所以他们在调用栈中更容易\b被识别.此外函数声明会把整个函数提升(hoisted), 而函数表达式只会把函数的引用变量名提升. 这条规则是的箭头函数可以取代函数表达式.// badconst foo = function () &#123;&#125;;// goodfunction foo() &#123;&#125;函数表达式// 立即调用的函数表达式(IIFE)(() =&gt; &#123; console.log('welcome!')&#125;)()不要使用arguments。可以选择rest语法...替代// badfunction concatenateAll() &#123; const args = Array.prototype.slice.call(arguments); return args.join('');&#125;// goodfunction concatenateAll(...args) &#123; return args.join('');&#125;直接给函数的参数指定默认值，不要使用一个变化的函数参数。// really badfunction handleThings(opts) &#123; // 不！我们不应该改变函数参数。 // 更加糟糕: 如果参数 opts 是 false 的话，它就会被设定为一个对象。 // 但这样的写法会造成一些 Bugs。 //（译注：例如当 opts 被赋值为空字符串，opts 仍然会被下一行代码设定为一个空对象。） opts = opts || &#123;&#125;; // ...&#125;// still badfunction handleThings(opts) &#123; if (opts === void 0) &#123; opts = &#123;&#125;; &#125; // ...&#125;// goodfunction handleThings(opts = &#123;&#125;) &#123; // ...&#125;构造器总是使用class, 避免使用prototype因为class语法更易读// badfunction Queen(contents = []) &#123; this._quene = [...contents];&#125;Quene.prototype.pop = function() &#123; const value = this._quene[0]; this._quene.splice(0, 1); return value;&#125;// goodclass Queen &#123; constructor(contents = []) &#123; this._quene = [...contents]; &#125; pop() &#123; const value = this._quene[0]; this._quene.splice(0, 1); return value; &#125;&#125;Iterators and Generators不要使用iterators, 使用高阶函数如map或者reduce来代替for-ofconst numbers = [1, 2, 3, 4, 5];// badlet sum = 0;for (let num of numbers) &#123; sum += num;&#125;sum === 15;// goodlet sum = 0;numbers.forEach((num) =&gt; sum += num);sum === 15// best (use the functional force)const sum = numbers.reduce((total, num) =&gt; total += num, 0)sum === 15比较运算符和等号条件表达式例如 if 语句通过抽象方法ToBoolean强制计算它们的表达式并且总是遵守下面的规则：对象 被计算为 trueUndefined 被计算为 falseNull 被计算为 false布尔值 被计算为 布尔的值数字 如果是 +0、-0、或 NaN 被计算为 false, 否则为 true字符串 如果是空字符串 ‘’ 被计算为 false，否则为 true注释给注释增加 FIXME 或 TODO 的前缀可以帮助其他开发者快速了解这是一个需要复查的问题，或是给需要实现的功能提供一个解决方式。这将有别于常见的注释，因为它们是可操作的。使用 FIXME – need to figure this out 或者 TODO – need to implement。class Calculator &#123; constructor() &#123; // FIXME: shouldn't use a global here total = 0; &#125;&#125;class Calculator &#123; constructor() &#123; // TODO: total should be configurable by an options param this.total = 0; &#125;&#125;空白使用2个空格作为缩进。在文件末尾插入一个空行。逗号增加结尾的逗号: 需要。JavaScript支持这种做法,并且会自动处理结尾多余的逗号, 好处是会让git diff更干净, 新增字段更方便.另外，像 babel 这样的转译器会移除结尾多余的逗号，也就是说你不必担心老旧浏览器的尾逗号问题。// bad - git diff without trailing commaconst hero = &#123; firstName: 'Florence',- lastName: 'Nightingale'+ lastName: 'Nightingale',+ inventorOf: ['coxcomb graph', 'modern nursing']&#125;// good - git diff with trailing commaconst hero = &#123; firstName: 'Florence', lastName: 'Nightingale',+ inventorOf: ['coxcomb chart', 'modern nursing'],&#125;// badconst hero = &#123; firstName: 'Dana', lastName: 'Scully'&#125;;const heroes = [ 'Batman', 'Superman'];// goodconst hero = &#123; firstName: 'Dana', lastName: 'Scully',&#125;;const heroes = [ 'Batman', 'Superman',];类型转换字符串// =&gt; this.reviewScore = 9;// badconst totalScore = this.reviewScore + '';// goodconst totalScore = String(this.reviewScore);如果因为某些原因 parseInt 成为你所做的事的瓶颈而需要使用位操作解决性能问题时，留个注释说清楚原因和你的目的。// good/** * 使用 parseInt 导致我的程序变慢， * 改成使用位操作转换数字快多了。 */const val = inputValue &gt;&gt; 0;命名规则别保存this的引用。使用箭头函数或Function#bind。// badfunction foo() &#123; const self = this; return function() &#123; console.log(self); &#125;;&#125;// badfunction foo() &#123; const that = this; return function() &#123; console.log(that); &#125;;&#125;// goodfunction foo() &#123; return () =&gt; &#123; console.log(this); &#125;;&#125;如果你的文件只输出一个类，那你的文件名必须和类名完全保持一致。// file contentsclass CheckBox &#123; // ...&#125;export default CheckBox;// in some other file// badimport CheckBox from './checkBox';// badimport CheckBox from './check_box';// goodimport CheckBox from './CheckBox';当你导出默认的函数时使用驼峰式命名。你的文件名必须和函数名完全保持一致。function makeStyleGuide() &#123;&#125;export default makeStyleGuide;当你导出单例、函数库、空对象时使用帕斯卡式命名。const AirbnbStyleGuide = &#123; es6: &#123; &#125;&#125;;export default AirbnbStyleGuide;事件当给事件附加数据时（无论是 DOM 事件还是私有事件），传入一个哈希而不是原始值。这样可以让后面的贡献者增加更多数据到事件数据而无需找出并更新事件的每一个处理器。// bad$(this).trigger('listingUpdated', listing.id);...$(this).on('listingUpdated', function(e, listingId) &#123; // do something with listingId&#125;);// good$(this).trigger('listingUpdated', &#123; listingId : listing.id &#125;);...$(this).on('listingUpdated', function(e, data) &#123; // do something with data.listingId&#125;);"},{"title":"Base64-md5","date":"2018-09-04","updated":"2018-09-29","path":"base64-md5/","link":"","text":"Base64编码与md5摘要算法探究及日常应用Base64编码和md5摘要算法我们经常听到,本文主要对着两者算法做一个简单的了解探究Base64Base64是一种基于64个可打印字符来表示二进制数据的表示方法,常用于在通常处理文本数据的场合，表示、传输、存储一些二进制数据，包括MIME的电子邮件及XML的一些复杂数据。Base64来源Base64来源于电子邮件的发展,早期的电子邮件是不支持二进制文件(例如图片)的,并且邮件中也不支持非英语字符,邮件也不能有附件,再后来的发展中工程师对电子邮件的技术规范就行了扩充,也就产生了常说的MIME,全称是全”Multipurpose Internet Mail Extensions”，中译为”多用途互联网邮件扩展”,它包括了多项技术规范.一封传统的电子邮件格式如下:From: &quot;Tommy Lee&quot; &lt;lee@example.com&gt;To: &quot;Jack Zhang&quot; &lt;zhang@example.com&gt;Subject: TestDate: Wed, 17 May 2000 19:08:29 -0400Message-ID: &lt;NDBBIAKOPKHFGPLCODIGIEKBCHAA.lee@example.com&gt;Hello World.它包含两个部分,第一部分是信封,里面包含发件人,收件人,邮件主题,邮件发送时间,邮件的唯一标识Message-ID,第二部分是正文,也就是邮件的内容,第一部分和第二部分之间用一个空行隔开,MIME对传统邮件的扩展体现在在信封里面新增了三行语句MIME-Version: 1.0这行语句标志着该邮件使用了MIME规范,收信端将按照该规范进行解析邮件内容Content-Type: text/plain; charset=”UTF-8”这行语句说明了改邮件的信息类型和编码方式Content-Type表明信息类型，缺省值为” text/plain”它包含了主要类型（primary type）和次要类型（subtype）两个部分，两者之间用”/“分割。主要类型有9种，分别是application、audio、example、image、message、model、multipart、text、video,每种主要类型下面又分为多种次要类型,常用的一些Content-Type类型如下:text/plain：纯文本，文件扩展名.txttext/html：HTML文本，文件扩展名.htm和.htmlimage/jpeg：jpeg格式的图片，文件扩展名.jpgimage/gif：GIF格式的图片，文件扩展名.gifaudio/x-wave：WAVE格式的音频，文件扩展名.wavaudio/mpeg：MP3格式的音频，文件扩展名.mp3video/mpeg：MPEG格式的视频，文件扩展名.mpgapplication/zip：PK-ZIP格式的压缩文件，文件扩展名.zip如果信息的主要类型是”text”，那么还必须指明编码类型”charset”，缺省值是ASCII，其他可能值有”ISO-8859-1”、”UTF-8”、”GB2312”等等。Content-transfer-encoding: Base64这里我们的主角就登场了,这行语句表明邮件编码转换的方式,因为现代邮件里面会有图片或者其它原始邮件不支持的内容,那么在发送的时候就需要对内容进行编码转换,将内容转换成邮件支持的ASCII字符,Content-transfer-encoding的值有5种—-“7bit”、”8bit”、”binary”、”quoted-printable”和”Base64”—-其中”7bit”是缺省值，即不用转化的ASCII字符。真正常用是”quoted-printable”和”Base64”两种.quoted-printable编码关于’quoted-printable’简单介绍一下,它主要用于ACSII文本中夹杂少量非ASCII码字符的情况，不适合于转换纯二进制文件.它规定将每一个8位的字节，转换为3个字符,规则如下:所有可打印的ASCII码字符（十进制值从33到126）都保持原样不变，”=”（十进制值61）除外,其余的字符都要进行编码。编码后第一个字符是”=”号，这是固定不变的;编码后二个字符是二个十六进制数，分别代表了这个字节前四位和后四位的数值。例如ASCII码中的换页键的码值是12,那么先转成8位的二进制是00001100,再转成16进制是0C,然后再在前面加上一个’=’号,最后的编码结果是’=0C’.Base64编码首先选出一个字符集,分别是小写字母a-z、大写字母A-Z、数字0-9、符号”+”、”/“加起来是64个,另外有一个垫字符’=’,然后将其它所有不在这个字符集里面的字符都转换到到这个字符集里面去,转换规则如下:将每三个字节作为一组，一共是24个二进制位;再将这24个二进制位分为四组，每个组有6个二进制位;在每组前面加两个00，扩展成32个二进制位，即四个字节;查询字符表,找到每个字节在表中对应的符号，这就是Base64的编码值;所以分析最终的结果的话,原始的三个字节经过转换以后会变成4个字节,因此Base64编码后的文本，会比原文本大出三分之一左右。Base64编码示例编码译文单词’six’:s i x -&lt;转为对应的ASCII值&gt;&gt;&gt; 115 105 120 -&lt;转为对应的二进制&gt;&gt; 01110011 01101001 01111000 -&lt;二进制分为四组&gt;&gt; 011100 110110 100101 111000 -&lt;每组前面添加两个0&gt;&gt; 00011100 00110110 00100101 00111000 -&lt;每组转为对应的10进制&gt;&gt; 28 54 37 56 -&lt;查询Base64字符表转为对应字符&gt;&gt; c 2 l 4则’six’编码后的结果是’c2l4’,你可以用这个工具来验证你的转码结果是否正确.如果字节数不足三，则处理如下:二个字节的情况：将这二个字节的一共16个二进制位，按照上面的规则，转成三组，最后一组除了前面加两个0以外，后面也要加两个0。这样得到一个三位的Base64编码，再在末尾补上一个”=”号。比如，”Ma”这个字符串是两个字节，可以转化成三组00010011、00010110、00010000以后，对应Base64值分别为T、W、E，再补上一个”=”号，因此”Ma”的Base64编码就是TWE=。一个字节的情况：将这一个字节的8个二进制位，按照上面的规则转成二组，最后一组除了前面加二个0以外，后面再加4个0。这样得到一个二位的Base64编码，再在末尾补上两个”=”号。比如，”M”这个字母是一个字节，可以转化为二组00010011、00010000，对应的Base64值分别为T、Q，再补上二个”=”号，因此”M”的Base64编码就是’TQ==’。再举一个中文的例子，汉字”严”如何转化成Base64编码？这里需要注意，汉字本身可以有多种编码，比如gb2312、utf-8、gbk等等，每一种编码的Base64对应值都不一样。下面的例子以utf-8为例。首先，”严”的utf-8编码为E4B8A5，写成二进制就是三字节的”11100100 10111000 10100101”。将这个24位的二进制字符串，按照第3节中的规则，转换成四组一共32位的二进制值”00111001 00001011 00100010 00100101”，相应的十进制数为57、11、34、37，它们对应的Base64值就为5、L、i、l。所以，汉字”严”（utf-8编码）的Base64值就是5Lil。Base64在js中的使用Base64的js实现如下:/**** Base64 encode / decode** @author haitao.tu* @date 2010-04-26* @email tuhaitao@foxmail.com**/ function Base64() &#123; true// private propertytrue_keyStr = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\"; true// public method for encodingtruethis.encode = function (input) &#123;truetruevar output = \"\";truetruevar chr1, chr2, chr3, enc1, enc2, enc3, enc4;truetruevar i = 0;truetrueinput = _utf8_encode(input);truetruewhile (i &lt; input.length) &#123;truetruetruechr1 = input.charCodeAt(i++);truetruetruechr2 = input.charCodeAt(i++);truetruetruechr3 = input.charCodeAt(i++);truetruetrueenc1 = chr1 &gt;&gt; 2;truetruetrueenc2 = ((chr1 &amp; 3) &lt;&lt; 4) | (chr2 &gt;&gt; 4);truetruetrueenc3 = ((chr2 &amp; 15) &lt;&lt; 2) | (chr3 &gt;&gt; 6);truetruetrueenc4 = chr3 &amp; 63;truetruetrueif (isNaN(chr2)) &#123;truetruetruetrueenc3 = enc4 = 64;truetruetrue&#125; else if (isNaN(chr3)) &#123;truetruetruetrueenc4 = 64;truetruetrue&#125;truetruetrueoutput = output +truetruetrue_keyStr.charAt(enc1) + _keyStr.charAt(enc2) +truetruetrue_keyStr.charAt(enc3) + _keyStr.charAt(enc4);truetrue&#125;truetruereturn output;true&#125; true// public method for decodingtruethis.decode = function (input) &#123;truetruevar output = \"\";truetruevar chr1, chr2, chr3;truetruevar enc1, enc2, enc3, enc4;truetruevar i = 0;truetrueinput = input.replace(/[^A-Za-z0-9\\+\\/\\=]/g, \"\");truetruewhile (i &lt; input.length) &#123;truetruetrueenc1 = _keyStr.indexOf(input.charAt(i++));truetruetrueenc2 = _keyStr.indexOf(input.charAt(i++));truetruetrueenc3 = _keyStr.indexOf(input.charAt(i++));truetruetrueenc4 = _keyStr.indexOf(input.charAt(i++));truetruetruechr1 = (enc1 &lt;&lt; 2) | (enc2 &gt;&gt; 4);truetruetruechr2 = ((enc2 &amp; 15) &lt;&lt; 4) | (enc3 &gt;&gt; 2);truetruetruechr3 = ((enc3 &amp; 3) &lt;&lt; 6) | enc4;truetruetrueoutput = output + String.fromCharCode(chr1);truetruetrueif (enc3 != 64) &#123;truetruetruetrueoutput = output + String.fromCharCode(chr2);truetruetrue&#125;truetruetrueif (enc4 != 64) &#123;truetruetruetrueoutput = output + String.fromCharCode(chr3);truetruetrue&#125;truetrue&#125;truetrueoutput = _utf8_decode(output);truetruereturn output;true&#125; true// private method for UTF-8 encodingtrue_utf8_encode = function (string) &#123;truetruestring = string.replace(/\\r\\n/g,\"\\n\");truetruevar utftext = \"\";truetruefor (var n = 0; n &lt; string.length; n++) &#123;truetruetruevar c = string.charCodeAt(n);truetruetrueif (c &lt; 128) &#123;truetruetruetrueutftext += String.fromCharCode(c);truetruetrue&#125; else if((c &gt; 127) &amp;&amp; (c &lt; 2048)) &#123;truetruetruetrueutftext += String.fromCharCode((c &gt;&gt; 6) | 192);truetruetruetrueutftext += String.fromCharCode((c &amp; 63) | 128);truetruetrue&#125; else &#123;truetruetruetrueutftext += String.fromCharCode((c &gt;&gt; 12) | 224);truetruetruetrueutftext += String.fromCharCode(((c &gt;&gt; 6) &amp; 63) | 128);truetruetruetrueutftext += String.fromCharCode((c &amp; 63) | 128);truetruetrue&#125; truetrue&#125;truetruereturn utftext;true&#125; true// private method for UTF-8 decodingtrue_utf8_decode = function (utftext) &#123;truetruevar string = \"\";truetruevar i = 0;truetruevar c = c1 = c2 = 0;truetruewhile ( i &lt; utftext.length ) &#123;truetruetruec = utftext.charCodeAt(i);truetruetrueif (c &lt; 128) &#123;truetruetruetruestring += String.fromCharCode(c);truetruetruetruei++;truetruetrue&#125; else if((c &gt; 191) &amp;&amp; (c &lt; 224)) &#123;truetruetruetruec2 = utftext.charCodeAt(i+1);truetruetruetruestring += String.fromCharCode(((c &amp; 31) &lt;&lt; 6) | (c2 &amp; 63));truetruetruetruei += 2;truetruetrue&#125; else &#123;truetruetruetruec2 = utftext.charCodeAt(i+1);truetruetruetruec3 = utftext.charCodeAt(i+2);truetruetruetruestring += String.fromCharCode(((c &amp; 15) &lt;&lt; 12) | ((c2 &amp; 63) &lt;&lt; 6) | (c3 &amp; 63));truetruetruetruei += 3;truetruetrue&#125;truetrue&#125;truetruereturn string;true&#125;&#125;md5摘要算法Base64我们说的差不多了,下面说说md5.md5全称’MD5消息摘要算法’（英语：MD5 Message-Digest Algorithm）,其最明显的作用就是对一段文本或者二进制文件进行运算之后得出一个128位的值,我们通常会把计算结果转换成32个16进制的数来表示.对文本进行运算常用于密码的加密,比如对’password2018’这个字符串进行加密之后得到’f4654d5ac34aca487f0e3cb08d769f8a’,由于md5发生碰撞的概率极低,也就是不同的文本加密后得到同样的结果的可能性微乎其微,所以一般可以认为’f4654d5ac34aca487f0e3cb08d769f8a’这样的结果就唯一标识了’password2018’这个字符串.加密容易解密难,如果你想通过’f4654d5ac34aca487f0e3cb08d769f8a’这个结果去逆向运算得到’password2018’这个原始数据几乎是不可能的,付出的成本也相当于是天价,所以我们的网站登录经常会采取用md5加密用户密码的方式来验证和存储用户账户密码.对二进制文件的运算常用于确保文件的完整性,比如在一些正规的网站上下载东西时常常附带会有一个.md5的文件,里面的内容类似于MD5 (tanajiya.tar.gz) = 38b8c2c1093dd0fec383a9d9ac940515这样,这里面记录的一串字符就是你要下载的这个文件的md5的运算结果,因为之前说过了一个东西的md5值是唯一的,一个md5结果也同样标识着唯一的一个东西,类似于每个人都有自己独特的指纹一样,一旦这个文件被人篡改过,那么再次对这个文件计算md5就会得到与之前不一样的md5值,所以我们常常会用这个md5结果来验证确保文件的完整性.md5的js实现如下:/* * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message * Digest Algorithm, as defined in RFC 1321. * Version 2.1 Copyright (C) Paul Johnston 1999 - 2002. * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet * Distributed under the BSD License * See https//pajhome.org.uk/crypt/md5 for more info. *//* * Configurable variables. You may need to tweak these to be compatible with * the server-side, but the defaults work in most cases. */var hexcase = 0; /* hex output format. 0 - lowercase; 1 - uppercase */var b64pad = \"\"; /* base-64 pad character. \"=\" for strict RFC compliance */var chrsz = 8; /* bits per input character. 8 - ASCII; 16 - Unicode *//* * These are the functions you'll usually want to call * They take string arguments and return either hex or base-64 encoded strings */function hex_md5(s)&#123; return binl2hex(core_md5(str2binl(s), s.length * chrsz));&#125;function b64_md5(s)&#123; return binl2b64(core_md5(str2binl(s), s.length * chrsz));&#125;function str_md5(s)&#123; return binl2str(core_md5(str2binl(s), s.length * chrsz));&#125;function hex_hmac_md5(key, data) &#123; return binl2hex(core_hmac_md5(key, data)); &#125;function b64_hmac_md5(key, data) &#123; return binl2b64(core_hmac_md5(key, data)); &#125;function str_hmac_md5(key, data) &#123; return binl2str(core_hmac_md5(key, data)); &#125;/* * Perform a simple self-test to see if the VM is working */function md5_vm_test()&#123; return hex_md5(\"abc\") == \"900150983cd24fb0d6963f7d28e17f72\";&#125;/* * Calculate the MD5 of an array of little-endian words, and a bit length */function core_md5(x, len)&#123; /* append padding */ x[len &gt;&gt; 5] |= 0x80 &lt;&lt; ((len) % 32); x[(((len + 64) &gt;&gt;&gt; 9) &lt;&lt; 4) + 14] = len; var a = 1732584193; var b = -271733879; var c = -1732584194; var d = 271733878; for(var i = 0; i &lt; x.length; i += 16) &#123; var olda = a; var oldb = b; var oldc = c; var oldd = d; a = md5_ff(a, b, c, d, x[i+ 0], 7 , -680876936); d = md5_ff(d, a, b, c, x[i+ 1], 12, -389564586); c = md5_ff(c, d, a, b, x[i+ 2], 17, 606105819); b = md5_ff(b, c, d, a, x[i+ 3], 22, -1044525330); a = md5_ff(a, b, c, d, x[i+ 4], 7 , -176418897); d = md5_ff(d, a, b, c, x[i+ 5], 12, 1200080426); c = md5_ff(c, d, a, b, x[i+ 6], 17, -1473231341); b = md5_ff(b, c, d, a, x[i+ 7], 22, -45705983); a = md5_ff(a, b, c, d, x[i+ 8], 7 , 1770035416); d = md5_ff(d, a, b, c, x[i+ 9], 12, -1958414417); c = md5_ff(c, d, a, b, x[i+10], 17, -42063); b = md5_ff(b, c, d, a, x[i+11], 22, -1990404162); a = md5_ff(a, b, c, d, x[i+12], 7 , 1804603682); d = md5_ff(d, a, b, c, x[i+13], 12, -40341101); c = md5_ff(c, d, a, b, x[i+14], 17, -1502002290); b = md5_ff(b, c, d, a, x[i+15], 22, 1236535329); a = md5_gg(a, b, c, d, x[i+ 1], 5 , -165796510); d = md5_gg(d, a, b, c, x[i+ 6], 9 , -1069501632); c = md5_gg(c, d, a, b, x[i+11], 14, 643717713); b = md5_gg(b, c, d, a, x[i+ 0], 20, -373897302); a = md5_gg(a, b, c, d, x[i+ 5], 5 , -701558691); d = md5_gg(d, a, b, c, x[i+10], 9 , 38016083); c = md5_gg(c, d, a, b, x[i+15], 14, -660478335); b = md5_gg(b, c, d, a, x[i+ 4], 20, -405537848); a = md5_gg(a, b, c, d, x[i+ 9], 5 , 568446438); d = md5_gg(d, a, b, c, x[i+14], 9 , -1019803690); c = md5_gg(c, d, a, b, x[i+ 3], 14, -187363961); b = md5_gg(b, c, d, a, x[i+ 8], 20, 1163531501); a = md5_gg(a, b, c, d, x[i+13], 5 , -1444681467); d = md5_gg(d, a, b, c, x[i+ 2], 9 , -51403784); c = md5_gg(c, d, a, b, x[i+ 7], 14, 1735328473); b = md5_gg(b, c, d, a, x[i+12], 20, -1926607734); a = md5_hh(a, b, c, d, x[i+ 5], 4 , -378558); d = md5_hh(d, a, b, c, x[i+ 8], 11, -2022574463); c = md5_hh(c, d, a, b, x[i+11], 16, 1839030562); b = md5_hh(b, c, d, a, x[i+14], 23, -35309556); a = md5_hh(a, b, c, d, x[i+ 1], 4 , -1530992060); d = md5_hh(d, a, b, c, x[i+ 4], 11, 1272893353); c = md5_hh(c, d, a, b, x[i+ 7], 16, -155497632); b = md5_hh(b, c, d, a, x[i+10], 23, -1094730640); a = md5_hh(a, b, c, d, x[i+13], 4 , 681279174); d = md5_hh(d, a, b, c, x[i+ 0], 11, -358537222); c = md5_hh(c, d, a, b, x[i+ 3], 16, -722521979); b = md5_hh(b, c, d, a, x[i+ 6], 23, 76029189); a = md5_hh(a, b, c, d, x[i+ 9], 4 , -640364487); d = md5_hh(d, a, b, c, x[i+12], 11, -421815835); c = md5_hh(c, d, a, b, x[i+15], 16, 530742520); b = md5_hh(b, c, d, a, x[i+ 2], 23, -995338651); a = md5_ii(a, b, c, d, x[i+ 0], 6 , -198630844); d = md5_ii(d, a, b, c, x[i+ 7], 10, 1126891415); c = md5_ii(c, d, a, b, x[i+14], 15, -1416354905); b = md5_ii(b, c, d, a, x[i+ 5], 21, -57434055); a = md5_ii(a, b, c, d, x[i+12], 6 , 1700485571); d = md5_ii(d, a, b, c, x[i+ 3], 10, -1894986606); c = md5_ii(c, d, a, b, x[i+10], 15, -1051523); b = md5_ii(b, c, d, a, x[i+ 1], 21, -2054922799); a = md5_ii(a, b, c, d, x[i+ 8], 6 , 1873313359); d = md5_ii(d, a, b, c, x[i+15], 10, -30611744); c = md5_ii(c, d, a, b, x[i+ 6], 15, -1560198380); b = md5_ii(b, c, d, a, x[i+13], 21, 1309151649); a = md5_ii(a, b, c, d, x[i+ 4], 6 , -145523070); d = md5_ii(d, a, b, c, x[i+11], 10, -1120210379); c = md5_ii(c, d, a, b, x[i+ 2], 15, 718787259); b = md5_ii(b, c, d, a, x[i+ 9], 21, -343485551); a = safe_add(a, olda); b = safe_add(b, oldb); c = safe_add(c, oldc); d = safe_add(d, oldd); &#125; return Array(a, b, c, d);&#125;/* * These functions implement the four basic operations the algorithm uses. */function md5_cmn(q, a, b, x, s, t)&#123; return safe_add(bit_rol(safe_add(safe_add(a, q), safe_add(x, t)), s),b);&#125;function md5_ff(a, b, c, d, x, s, t)&#123; return md5_cmn((b &amp; c) | ((~b) &amp; d), a, b, x, s, t);&#125;function md5_gg(a, b, c, d, x, s, t)&#123; return md5_cmn((b &amp; d) | (c &amp; (~d)), a, b, x, s, t);&#125;function md5_hh(a, b, c, d, x, s, t)&#123; return md5_cmn(b ^ c ^ d, a, b, x, s, t);&#125;function md5_ii(a, b, c, d, x, s, t)&#123; return md5_cmn(c ^ (b | (~d)), a, b, x, s, t);&#125;/* * Calculate the HMAC-MD5, of a key and some data */function core_hmac_md5(key, data)&#123; var bkey = str2binl(key); if(bkey.length &gt; 16) bkey = core_md5(bkey, key.length * chrsz); var ipad = Array(16), opad = Array(16); for(var i = 0; i &lt; 16; i++) &#123; ipad[i] = bkey[i] ^ 0x36363636; opad[i] = bkey[i] ^ 0x5C5C5C5C; &#125; var hash = core_md5(ipad.concat(str2binl(data)), 512 + data.length * chrsz); return core_md5(opad.concat(hash), 512 + 128);&#125;/* * Add integers, wrapping at 2^32. This uses 16-bit operations internally * to work around bugs in some JS interpreters. */function safe_add(x, y)&#123; var lsw = (x &amp; 0xFFFF) + (y &amp; 0xFFFF); var msw = (x &gt;&gt; 16) + (y &gt;&gt; 16) + (lsw &gt;&gt; 16); return (msw &lt;&lt; 16) | (lsw &amp; 0xFFFF);&#125;/* * Bitwise rotate a 32-bit number to the left. */function bit_rol(num, cnt)&#123; return (num &lt;&lt; cnt) | (num &gt;&gt;&gt; (32 - cnt));&#125;/* * Convert a string to an array of little-endian words * If chrsz is ASCII, characters &gt;255 have their hi-byte silently ignored. */function str2binl(str)&#123; var bin = Array(); var mask = (1 &lt;&lt; chrsz) - 1; for(var i = 0; i &lt; str.length * chrsz; i += chrsz) bin[i&gt;&gt;5] |= (str.charCodeAt(i / chrsz) &amp; mask) &lt;&lt; (i%32); return bin;&#125;/* * Convert an array of little-endian words to a string */function binl2str(bin)&#123; var str = \"\"; var mask = (1 &lt;&lt; chrsz) - 1; for(var i = 0; i &lt; bin.length * 32; i += chrsz) str += String.fromCharCode((bin[i&gt;&gt;5] &gt;&gt;&gt; (i % 32)) &amp; mask); return str;&#125;/* * Convert an array of little-endian words to a hex string. */function binl2hex(binarray)&#123; var hex_tab = hexcase ? \"0123456789ABCDEF\" : \"0123456789abcdef\"; var str = \"\"; for(var i = 0; i &lt; binarray.length * 4; i++) &#123; str += hex_tab.charAt((binarray[i&gt;&gt;2] &gt;&gt; ((i%4)*8+4)) &amp; 0xF) + hex_tab.charAt((binarray[i&gt;&gt;2] &gt;&gt; ((i%4)*8 )) &amp; 0xF); &#125; return str;&#125;/* * Convert an array of little-endian words to a base-64 string */function binl2b64(binarray)&#123; var tab = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\"; var str = \"\"; for(var i = 0; i &lt; binarray.length * 4; i += 3) &#123; var triplet = (((binarray[i &gt;&gt; 2] &gt;&gt; 8 * ( i %4)) &amp; 0xFF) &lt;&lt; 16) | (((binarray[i+1 &gt;&gt; 2] &gt;&gt; 8 * ((i+1)%4)) &amp; 0xFF) &lt;&lt; 8 ) | ((binarray[i+2 &gt;&gt; 2] &gt;&gt; 8 * ((i+2)%4)) &amp; 0xFF); for(var j = 0; j &lt; 4; j++) &#123; if(i * 8 + j * 6 &gt; binarray.length * 32) str += b64pad; else str += tab.charAt((triplet &gt;&gt; 6*(3-j)) &amp; 0x3F); &#125; &#125; return str;&#125;"},{"title":"IIFE","date":"2018-09-02","updated":"2019-02-25","path":"IIFE/","link":"","text":"[增][转][译]JavaScript：立即执行函数表达式（IIFE）原文: https//benalman.com/news/2010/11/immediately-invoked-function-expression/#iife译文: https://segmentfault.com/a/1190000003985390 by Murphywuwu可能你并没有注意到，我是一个对于专业术语有一点坚持细节人。所有，当我听到流行的但是还存在误解的术语“自执行匿名函数”多次时，我最终决定将我的想法写进这篇文章里。除了提供关于这种模式事实上是如何工作的一些全面的信息，更进一步的，实际上我建议我们应该知道我们应该叫它什么。而且，如果你想跳过这里，你可以直接跳到立即调用函数表达式进行阅读，但是我建议你读完整篇文章。它是什么在 JavaScript 里，每个函数，当被调用时，都会创建一个新的执行上下文。因为在函数里定义的变量和函数是唯一在内部被访问的变量，而不是在外部被访问的变量，当调用函数时，函数提供的上下文提供了一个非常简单的方法创建私有变量。function makeCounter() &#123; var i = 0; return function()&#123; console.log(++i); &#125;;&#125;//记住：`counter`和`counter2`都有他们自己的变量 `i`var counter = makeCounter();counter();//1counter();//2var counter2 = makeCounter();counter2();//1counter2();//2i;//ReferenceError: i is not defined(它只存在于makeCounter里)在许多情况下，你可能并不需要makeWhatever这样的函数返回多次累加值，并且可以只调用一次得到一个单一的值，在其他一些情况里，你甚至不需要明确的知道返回值。它的核心现在，无论你定义一个函数像这样function foo(){}或者var foo = function(){}，调用时，你都需要在后面加上一对圆括号，像这样foo()。//向下面这样定义的函数可以通过在函数名后加一对括号进行调用，像这样`foo()`，//因为foo相对于函数表达式`function()&#123;/* code */&#125;`只是一个引用变量var foo = function()&#123;/* code */&#125;//那这可以说明函数表达式可以通过在其后加上一对括号自己调用自己吗？function()&#123; /* code */&#125;(); //SyntaxError: Unexpected token (正如你所看到的，这里捕获了一个错误。当圆括号为了调用函数出现在函数后面时，无论在全局环境或者局部环境里遇到了这样的function关键字，默认的，它会将它当作是一个函数声明，而不是函数表达式，如果你不明确的告诉圆括号它是一个表达式，它会将其当作没有名字的函数声明并且抛出一个错误，因为函数声明需要一个名字。(个人理解: 见扩展’函数声明与函数表达式’)问题1：这里我么可以思考一个问题，我们是不是也可以像这样直接调用函数var foo = function(){console.log(1)}()，答案是可以的。问题2：同样的，我们还可以思考一个问题，像这样的函数声明在后面加上圆括号被直接调用，又会出现什么情况呢？请看下面的解答。函数，圆括号，错误有趣的是，如果你为一个函数指定一个名字并在它后面放一对圆括号，同样的也会抛出错误，但这次是因为另外一个原因。(个人理解: 见扩展’报错原因分析’)当圆括号放在一个函数表达式后面指明了这是一个被调用的函数，而圆括号放在一个声明后面便意味着完全的和前面的函数声明分开了，此时圆括号只是一个简单的代表一个括号(用来控制运算优先的括号)。//然而函数声明语法上是无效的，它仍然是一个声明，紧跟着的圆括号是无效的，因为圆括号里需要包含表达式function foo()&#123; /* code */ &#125;();//SyntaxError: Unexpected token//现在，你把一个表达式放在圆括号里，没有抛出错误...,但是函数也并没有执行，因为：function foo()&#123;/* code */&#125;(1)//它等同于如下，一个函数声明跟着一个完全没有关系的表达式:function foo()&#123;/* code */&#125;(1);立即执行函数表达式（IIFE）幸运的是，修正语法错误很简单。最流行的也最被接受的方法是将函数声明包裹在圆括号里来告诉语法分析器去表达一个函数表达式，因为在Javascript里，圆括号不能包含声明。因为这点，当圆括号为了包裹函数碰上了function关键词，它便知道将它作为一个函数表达式去解析而不是函数声明。注意理解这里的圆括号和上面的圆括号遇到函数时的表现是不一样的，也就是说。当圆括号出现在匿名函数的末尾想要调用函数时，它会默认将函数当成是函数声明。当圆括号包裹函数时，它会默认将函数作为表达式去解析，而不是函数声明。//这两种模式都可以被用来立即调用一个函数表达式，利用函数的执行来创造私有变量(function()&#123;/* code */&#125;());//Crockford recommends this one，括号内的表达式代表函数立即调用表达式(function()&#123;/* code */&#125;)();//But this one works just as well，括号内的表达式代表函数表达式// Because the point of the parens or coercing operators is to disambiguate// between function expressions and function declarations, they can be// omitted when the parser already expects an expression (but please see the// \"important note\" below).var i = function()&#123;return 10;&#125;();true &amp;&amp; function()&#123;/*code*/&#125;();0,function()&#123;&#125;();//如果你并不关心返回值，或者让你的代码尽可能的易读，你可以通过在你的函数前面带上一个一元操作符来存储字节!function()&#123;/* code */&#125;();~function()&#123;/* code */&#125;();-function()&#123;/* code */&#125;();+function()&#123;/* code */&#125;();// Here's another variation, from @kuvos - I'm not sure of the performance// implications, if any, of using the `new` keyword, but it works.// https//twitter.com/kuvos/status/18209252090847232new function()&#123; /* code */ &#125;new function()&#123; /* code */ &#125;() // Only need parens if passing arguments关于括号的重要笔记在一些情况下，当额外的带着歧义的括号围绕在函数表达式周围是没有必要的(因为这时候的括号已经将其作为一个表达式去表达)，但当括号用于调用函数表达式时，这仍然是一个好主意。这样的括号指明函数表达式将会被立即调用，并且变量将会储存函数的结果，而不是函数本身。当这是一个非常长的函数表达式时，这可以节约比人阅读你代码的时间，不用滚到页面底部去看这个函数是否被调用。作为规则，当你书写清楚明晰的代码时，有必要阻止 JavaScript 抛出错误的，同样也有必要阻止其他开发者对你抛出错误WTFError!保存闭包的状态就像当函数通过他们的名字被调用时，参数会被传递，而当函数表达式被立即调用时，参数也会被传递。一个立即调用的函数表达式可以用来锁定值并且有效的保存此时的状态，因为任何定义在一个函数内的函数都可以使用外面函数传递进来的参数和变量(这种关系被叫做闭包)。(个人理解: 见扩展’关于闭包’)// 它的运行原理可能并不像你想的那样，因为`i`的值从来没有被锁定。// 相反的，每个链接，当被点击时（循环已经被很好的执行完毕），因此会弹出所有元素的总数，// 因为这是 `i` 此时的真实值。var elems = document.getElementsByTagName('a');for(var i = 0;i &lt; elems.length; i++ ) &#123; elems[i].addEventListener('click',function(e)&#123; e.preventDefault(); alert('I am link #' + i) &#125;,false);&#125;// 而像下面这样改写，便可以了，因为在IIFE里，`i`值被锁定在了`lockedInIndex`里。// 在循环结束执行时，尽管`i`值的数值是所有元素的总和，但每一次函数表达式被调用时，// IIFE 里的 `lockedInIndex` 值都是`i`传给它的值,所以当链接被点击时，正确的值被弹出。var elems = document.getElementsByTagName('a');for(var i = 0;i &lt; elems.length;i++) &#123; (function(lockedInIndex)&#123; elems[i].addEventListener('click',function(e)&#123; e.preventDefault(); alert('I am link #' + lockedInIndex); &#125;,false) &#125;)(i);&#125;//你同样可以像下面这样使用IIFE，仅仅只用括号包括点击处理函数，并不包含整个`addEventListener`。//无论用哪种方式，这两个例子都可以用IIFE将值锁定，不过我发现前面一个例子更可读var elems = document.getElementsByTagName( 'a' );for ( var i = 0; i &lt; elems.length; i++ ) &#123; elems[ i ].addEventListener( 'click', (function( lockedInIndex )&#123; return function(e)&#123; e.preventDefault(); alert( 'I am link #' + lockedInIndex ); &#125;; &#125;)( i ),false); &#125;记住，在这最后两个例子里，lockedInIndex可以没有任何问题的访问i,但是作为函数的参数使用一个不同的命名标识符可以使概念更加容易的被解释。立即执行函数一个最显著的优势是就算它没有命名或者说是匿名，函数表达式也可以在没有使用标识符的情况下被立即调用，一个闭包也可以在没有当前变量污染的情况下被使用。自执行匿名函数(“Self-executing anonymous function”)有什么问题呢？你看到它已经被提到好几次了，但是它仍然不是那么清楚的被解释，我提议将术语改成”Immediately-Invoked Function Expression”，或者，IIFE，如果你喜欢缩写的话。什么是Immediately-Invoked Function Expression呢？它使一个被立即调用的函数表达式。就像引导你去调用的函数表达式。我想Javascript社区的成员应该可以在他们的文章里或者陈述里接受术语，Immediately-Invoked Function Expression和 IIFE，因为我感觉这样更容易让这个概念被理解，并且术语”self-executing anonymous function”真的也不够精确。//下面是个自执行函数，递归的调用自己本身function foo()&#123;foo();&#125;;//这是一个自执行匿名函数。因为它没有标识符，它必须是使用`arguments.callee`属性来调用它自己var foo = function()&#123;arguments.callee();&#125;;//这也许算是一个自执行匿名函数，但是仅仅当`foo`标识符作为它的引用时，如果你将它换成用`foo`来调用同样可行var foo = function()&#123;foo();&#125;;//有些人像这样叫'self-executing anonymous function'下面的函数,即使它不是自执行的，因为它并没有调用它自己。然后，它只是被立即调用了而已。(function()&#123; /*code*/ &#125;());//为函数表达式增加标识符(也就是说创造一个命名函数)对我们的调试会有很大帮助。一旦命名，函数将不再匿名。(function foo()&#123;/* code */&#125;());//IIFEs同样也可以自执行，尽管，也许他不是最有用的模式(function()&#123;arguments.callee();&#125;())(function foo()&#123;foo();&#125;())// One last thing to note: this will cause an error in BlackBerry 5, because// inside a named function expression, that name is undefined. Awesome, huh?(function foo()&#123; foo(); &#125;());希望上面的例子可以让你更加清楚的知道术语’self-executing’是有一些误导的，因为他并不是执行自己的函数，尽管函数已经被执行。同样的，匿名函数也没用必要特别指出，因为，Immediately Invoked Function Expression，既可以是命名函数也可以匿名函数。最后：模块模式当我调用函数表达式时，如果我不至少一次的提醒我自己关于模块模式，我便很可能会忽略它。如果你并不熟悉JavaScript里的模块模式，它和我下面的例子很像，但是返回值用对象代替了函数。var counter = (function()&#123; var i = 0; return &#123; get: function()&#123; return i; &#125;, set: function(val)&#123; i = val; &#125;, increment: function()&#123; return ++i; &#125; &#125; &#125;()); counter.get();//0 counter.set(3); counter.increment();//4 counter.increment();//5 conuter.i;//undefined (`i` is not a property of the returned object) i;//ReferenceError: i is not defined (it only exists inside the closure)模块模式方法不仅相当的厉害而且简单。非常少的代码，你可以有效的利用与方法和属性相关的命名，在一个对象里，组织全部的模块代码即最小化了全局变量的污染也创造了使用变量。扩展补充以下内容为我个人对原文及译文的扩展分析1. 函数声明与函数表达式关于这两者的定义你可以参看MDN的说明文档:函数表达式和函数声明共同点: 两者都可以用function关键字来创建一个函数，用法也很类似，例如// 函数声明function foo() &#123;console.log(1)&#125;//函数表达式,这样生成的是一个具名函数,叫`bar`var foo = function bar()&#123;console.log(1)&#125;//或者函数表达式也可以这样写,这样生成的是一个匿名函数,`foo`只是这个匿名函数的引用var foo = function ()&#123;console.log(1)&#125;可以看出我们使用函数声明和函数表达式都可以用来创建一个实现某些功能的函数不同点:从上面的例子我们可以看出函数声明只有一种写法,你必须给出函数的名字才行,如foo;而函数表达式则有两种写法,第一种是生成命名函数叫bar,后一种是生成匿名函数,注意函数表达式中的foo并不是函数名,它只是函数的一个引用而已,代表你可以使用foo来间接的调用真正的函数;函数声明存在提升,而函数表达式不存在提升,这意味着如果你是用函数声明的方法创建一个函数,那么你可以在定义这个函数之前就去使用它;但是如果你是用函数表达式的方法来创建一个函数,那么你就必须要在函数被创建了以后才可以去使用这个函数,例如:console.log(foo); // ƒ foo()&#123;console.log(1)&#125;function foo()&#123;console.log(1)&#125;consol.log(foo2); // Uncaught ReferenceError: consol is not definedvar foo2 = function bar()&#123;console.log(1)&#125;你也可以参考这里给出的例子额外的一点是我们经常使用函数表达式的方式来创建匿名函数,进而创建IIFE,这一点就跟本文主要内容联系起来了;还有一个区别是有条件的创建函数,当函数声明出现在非功能模块（比如 if）中时,虽然官方是禁止这样做的,但是实际上浏览器都支持这种做法,但是各个浏览器的处理方式有不同,这一点兼容性问题实在很头疼,所以我们不应该在生成环境代码中使用这种方式，应该使用函数表达式来代替。2. 报错原因function (){console.log(1)}()报错出现在第一个括号，因为声明一个函数需要名字，这里声明没有给出名字，所以直接报错，走不到第二个括号，但是function foo(){console.log(1)}()报错出现在第二括号，因为这里声明函数是正确的，当处理到第二个括号时，发现第二个括号内没有任何东西，这是不允许的,所以报错,理由参见文章中注释处3. 关于闭包在ES6之前只存在两种作用域,一是全局作用域,此作用域当浏览器打开一个页面时就会被创建,你可以通过window对象来访问这个全局作用域中的成员,另外一个就是函数作用域,当js引擎执行一个函数时就会为这个函数创建一个属于该函数的作用域,(在ES6中引入了新的作用域:块级作用域,使用let标识符来生成一个只在块级范围内可访问的变量,关于let的特性你可以参见这里ECMAScript 6 入门).function foo() &#123; let i = 1; return function log() &#123; console.log(++i) &#125;&#125;let logger = foo();logger(); // 2logger(); // 3理解闭包必须先理解js的函数作用域,之前说过了每次执行一个函数时就会为这个函数创建一个属于它自己的函数作用域,一旦这个函数运行完毕,那么它的作用域就会被销毁,其中的保存的信息一般也会被销毁,但是,这是一般的情况,那么什么是不一般的情况呢?这时我们就要利用浏览器销毁变量及作用域的特性来搞事了,浏览器的垃圾回收机制(有两种垃圾回收机制,这里以最常用的标记清除法为例)会定时的检查变量是否被引用,也就是是否有指针指向该数据的存储区域,如果有,那么说明有人可能要使用该数据,则不能销毁该区域,如果没有,说明没人再能够访问这个数据了,那么就可以放心的去销毁该区域来回收内存.而闭包正好利用了这个特性,例如上面的例子中,函数foo每次执行时会返回一个新函数叫做log,log函数内部需要访问它外面的变量i才能正常工作,返回的新函数被赋给了变量logger,那么这里的指向关系是logger -&gt; log -&gt; i,那么在之后的js执行过程中,由于外部的变量logger通过一系列的指向,最终时能够访问的最开始的那个变量i的,那么按照垃圾回收机制,函数foo的作用域将一直不能够被销毁,因为它内部的变量i还有人用着呢!并且我们发现类似i这样的变量能够保存很重要的一些信息,比如函数被调用的次数等等,我们就可以用来计数或者其它你能发挥创造力的用途.关于缺点的话也是很明显的,因为闭包内的变量一直将被保留着,如果我们创建大量这样的变量或者大量的闭包,那么浏览器可用内存就会越来越小造成卡顿,应该考虑情况适当使用."},{"title":"ssh-git","date":"2018-08-30","updated":"2019-05-16","path":"ssh-git/","link":"","text":"github的https和ssh连接方式探究在本机连接github仓库提交代码时有两种可选方法，一种是使用github账号的用户名和密码的认证方式通过https连接，另一种是使用ssh-key的认证方式通过ssh连接，本文主要研究这两种方式的工作过程以及可能会扩展探究一些相关的知识。ssh1995年芬兰赫尔辛基理工大学的塔图·于勒宁编写了secure shell, 简称SSH, 在这之前已经有不安全的shell, 但是SSH的提出保证了在非安全网络中可以加密完整可靠的传输数据, 要注意的是SSH只是一种通信协议, 存在则多种实现, 下面使用的是其中应用最广泛其中之一的开源实现OpenSSH.SSH基于公钥和私钥形式的非对称加密实现身份验证, 其默认的通信端口是22, 在登录验证时有两种方式: 1.密码认证;2.公钥认证.密码认证1.用户使用SSH向远程主机发起连接请求; 2.远程主机收到请求后把自己的公钥发给用户; 3.用户使用公钥对自己的登录密码进行加密, 然后发送给远程主机; 4.远程主机使用自己的密钥对发来的加密信息进行解密, 然后验证解密出来的用户密码是否正确, 如果密码正确则允许用户连接, 登录成功, 然后用户会把远程主机的公钥加入到自己本地的$HOME/.ssh/known_hosts中.仔细分析这个过程我们会发现一个漏洞, 假如我是个黑客, 我出现在了用户和服务器中间的位置, 当在上面第二步的过程时我把我自己的公钥发送给用户, 然后用户就会用我的公钥加密他的密码然后发送给我, 这样我再用我的私钥来解密消息, 就可以获得用户的明文密码了, 这其实就是著名的中间人攻击Main-in-the-middle attack(MITM). 如何应对中间人攻击可以参加下面.密钥认证密钥认证比密码认证安全一些, 因为不涉及用户密码的传输过程. 过程大致如下: 1.用户生成自己的一对公钥和密钥, 然后将公钥存储在远程主机上; 2.用户登录的时候向远程主机发送用私钥签名的包含用户名和公钥等信息; 2.远程主机收到请求后检查自己的$HOME/.ssh/authorized_keys中是否有用户发送的消息中的公钥信息, 如果有则证明该消息的公钥信息合法, 然后就会使用该公钥解密消息.中间人攻击那么SSH如何应对之前提到的中间人攻击呢?在我们第一次连接一个远程主机例如ssh user@host连接时, 我们会收到如下提示信息:The authenticity of host ‘host (12.18.429.21)’ can’t be established.RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.Are you sure you want to continue connecting (yes/no)?这就是在提示我们是第一次连接这个主机, 然后消息里面给出了这个主机的公钥的md5摘要信息98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d, 我们可以通过确认这个摘要值是不是我们想要连接的主机的, 如果是就输入yes回车确认连接, 并且会自动把这个主机加入到我们的本地known hosts（已知主机）名单里面, 以后都不再提示.因为中间人攻击核心就是使用假的公钥来替代真正的远程主机的公钥, 那么可以通过如下两种解决方案来应对:远程主机把自己的公钥拿到CA处做认证，申请一个数字证书有关数字证书和数字签名的区别可以查看这里, 以后只要确认这个证书是正规可信的, 那就可以对应的信任该公钥远程主机把自己公钥的指纹信息公布出来, 让大家自己来查看对比比如放在自己的网站上面供想要连接的人执行对比查阅通过上面两种做法都可以是的用户确认自己当前加密信息所使用的公钥确定是正确的远程主机的公钥, 而不是中间人的公钥关于SSH, 你也可以参考这里或者阮一峰的博客git的两种通信协议实际上git可以使用四种通信协议:本地传输，SSH协议，Git协议和HTTP/S协议, 我们这里只讨论其中的SSH协议和HTTP/S协议.使用中最明显的区别是SSH协议只能操作我们有管理权限的项目, 但是HTTP/S协议允许我们clone没有管理权限的项目(不能修改, 只能clone查看).一般我们使用SSH协议比较多, 因为服务器一般是linux系统的, 它内置了SSH, 使用方便, 而且SSH也更安全.首先在本机下载安装Git，一路点next默认安装即可;配置个人信息使用git提交更改的时候会为本次提交附上提交人的\b一些信息，比如提交人的用户名及邮箱信息，我们可以使用git提供的配置功能来提前配置好这些信息，使用如下：git config --global user.name \"John Doe\"git config --global user.email \"johndoe@example.com\"# 参数说明：# git config: 表示使用git的配置工具# --global: 表示配置全局的信息，你也可以在某个项目下面单独配置这个信息，只需要去掉'--global'即可，# &lt;- 这样不同的项目就会有不同提交人信息# user.name / user.email: 后面跟上你自己的用户名和邮箱信息即可# 之后我们可以使用如下命令来查看我们配置的信息#git config user.name#git config user.email按照下面步骤尝试clone一个github上的项目到本地使用https协议以我的博客所使用hexo的materialFlow主题项目为例(这个项目我没有管理权限)，一行命令git clone https://github.com/stkevintan/hexo-theme-material-flow.git即可clone到本地, 因为这个项目我没有权限, 如果我是用SSH协议方式那么就会报错, 见下面.在修改了代码以后想要提交git push的时候会提示我们输入用户名和密码, 这里就涉及到新版智能HTTP/S协议(Git1.6.6之后引入), 你可参考这里, 在弹出的一个窗口输入用户名和密码, 之后你再提交的时候不会要求输入用户名和密码, 如果你使用的时候不是这样(Git版本太低或者服务器不支持智能HTTP/S协议), 那么可以参考这里配置https协议下的认证, 这样就不用每次提交的时候都要求输入用户名和密码.使用ssh协议此时你就无法直接使用git clone git@github.com:stkevintan/hexo-theme-material-flow.git命令来clone上面那个项目到本地，会产生如下错误提示：fatal: Could not read from remote repository.Please make sure you have the correct access rights and the repository exists.因为ssh的方式是需要进行认证的，你必须是这个项目的所有者或者管理者，才能有权限去使用ssh方式clone该项目，而上面的https方式则允许任何一个人在不需要验证的情况下去clone项目.那么接下来看一下对于一个我们有管理权限的仓库应该如何使用ssh方式去clone到本地ssh方式是基于不对称性加密来通信的，你需要使用不对称性算法来生成一对密钥，然后将私钥放置在你本机上，将公钥放置在github服务器上，之后在进行ssh通信时将会使用这对秘钥来完成认证登陆及加密和解密信息，在window上和mac上我们都可以使用ssh-keygen这个命令行工具来生成我们需要的密钥，这是我们想要使用ssh通信的第一步生成一对密钥打开你的命令行（window下使用cmd.exe，mac下使用terminal.app），然后按照\b如下命令来生成密钥ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"# 参数说明： # ssh-keygen: 表示将要使用ssh-keygen这个工具来生成密钥# -t: 指定要生成的密钥类型，有rsa1(SSH1),dsa(SSH2),ecdsa(SSH2),rsa(SSH2)等类型，较为常用的是rsa类型，此处指定为rsa类型# -b: 指定要生成的密钥长度 (单位:bit)，对于RSA类型的密钥，最小长度768bits,默认长度为2048bits。DSA密钥必须是1024bits，此处指定为4096bits# -C: 制定要生成的密钥的注释，这个可以自己随意填写，就相当于给这个密钥留个名，好分辨，比如此处可以用注册github的邮箱号之后会出现如下提示内容：Generating public/private rsa key pair.Enter file in which to save the key (C:/Users/xxxxx/.ssh/id_rsa):意思是让你输入这个密钥文件的文件名，一般情况保存默认就可以，直接回车确认。(如果你有多个git的账号需要配置，比如你自己在github上有账号需要提交代码，同时自己在公司也有git的账号，有时候需要提交代码到公司的仓库里，那么这时候你就需要额外的配置来保证提交的时候不会冲突，详见下面)然后会出现下一个提示内容：Enter passphrase (empty for no passphrase):意思是要不要对私钥设置口令（passphrase），如果担心私钥的安全，你可以设置一个，这里一般不设置，直接回车确认即可，最后会出现类似如下的提示内容：+—[RSA 4096]—-+| o+o .. .o || oo… o … = ||+ +.+ o.o.o.+ o ||oB =.o..E.o* o ||o = o.o Soo+= || . o .+++ . || o.o || .. || .. |+—-[SHA256]—–+那\b么恭喜你，你已经生成了一对密钥文件，\b他们存储在C:/Users/xxxxx/.ssh/（windows）或者~/.ssh（mac）目录下，默认的文件是id_rsa（私钥文件名）和id_rsa.pub（公钥文件名），你可以去打开查看一下里面的内容。部署密钥之前说过了你需要将私钥保存在本机，公钥放置在服务器上，这样之后才能用这对密钥建立ssh通信，那么在github上我们按照如下做法来部署密钥用文本编辑器打开刚才生成的公钥文件id_rsa.pub，拷贝里面的全部内容；打开浏览器登陆你的github账户，依次打开你头像上的Settings &gt; SSH and GPG keys &gt; New SSH key;填写相关信息，title可以类似之前生成密钥时填写的注释信息那样填写你的邮箱名，然后key里面填上刚才拷贝的公钥内容，点击Add SSH key之后输入一次你的github账户密码进行确认，然后你的公钥就被保存部署到github服务器上了；测试连接，使用如下命令来测试是否能够通过ssh连接到githubssh git@github.com# 参数说明：# ssh: 使用ssh进行连接# git@github.com: ssh连接时需要指定登陆用户名和远程主机名，这里的git就是github的远程服务器的用户名，github.com就是远程服务器的主机名，用'@'符号连接起来当你是第一次连接的时候会提示你如下信息：The authenticity of host ‘github.com (52.74.223.119)’ can’t be established.RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.Are you sure you want to continue connecting (yes/no)?这是因为你是第一次连接该主机，该主机不在你本机的known hosts（已知主机）名单里面，所以询问你是否要继续连接这个陌生的主机，输入yes然后回车确认即可，之后再次连接的时候就不会有这个提示信息了。这里提示信息中的RSA key fingerprint代表的是公钥的md5摘要值, 因为RSA算法生成的公钥长度很长(一般为1024位或者2018位, 可以自己在生成时指定), 这里就用了对公钥进行摘要后的比较短的值来代表公钥.如果你配置步骤没问题的话应该可以看到下面的连接上之后的欢迎信息(xxxxx代表你的github的账户名)：Warning: Permanently added ‘github.com,52.74.223.119’ (RSA) to the list of known hosts.PTY allocation request failed on channel 0Hi xxxxx! You’ve successfully authenticated, but GitHub does not provide shell access.Connection to github.com closed.使用ssh方式clone项目之前说过了ssh方式只能操作我们有管理权限的项目，所以这里我拿自己做的一个微信小程序的虚拟车牌键盘的项目为例git clone git@github.com:kricsleo/vehicleKeyboard.git这个时候我们就能顺利clone该项目到本机了，因为在我们上面这条命令请求数据的过程中，我们本机和github的服务器会使用我们之前生成的那对密钥来进行相互认证，从而使我们不需要手动输入github的账户名和密码信息来完成认证登陆，同时我们以后修改了项目代码在进行提交的时候也可直接进行提交等相关操作，无需再考虑登陆及连接的问题，git的使用可以参考我之前的一篇小总结关于git使用https和ssh方式的区别你也可以查看这里多git账户配置如果你需要生成多对密钥，比如你需要和两个不一样的服务器A和B进行ssh通信，那么这个时候你就可以生成两对密钥，一对用来和A通信，另一对用来和B通信，最常见的情况就是我们自己在github上面会有自己的github账户，自己平时会开发一些自己的项目，然后提交到github上面，在公司里面公司一般会有自己的gitlab服务器，然后给员工开通一个gitlab的账号，有关公司内部的项目就会让员工用gitlab的账户进行开发，然后提交代码到公司的gitlab上面，那么这时候我们可以按照如下的方法来配置一下，保证自己随时提交代码的时候都是能够提交到正确的地方，而不会混乱。再生成一对密钥在上面的操作中你已经生成了一对密钥，名字叫做id_rsa和id_rsa.pub（如果你没有改名的话），这个密钥我们已经拿来和github进行通信了，此时我们要想和公司的gitlab通信就需要再生成一对密钥，为了避免这次生成的密钥覆盖我们之前的那对密钥，可以执行如下命令：ssh-keygen -t rsa -b 4096 -C \"youremail@yourcompany.com” -f ~/.ssh/id_rsa_xx# 参数说明# 这次我们生成密钥的命令只比之前多了一个参数： -f# -f: 表示将这次什么的密钥文件保存为id_rsa_xx，同样放在了之前的那个文件夹，这个文件名你可以自己随意指定，不过最好容易区分一些后面你的操作就和之前生成密钥一样了，生成好密钥之后再看下一步部署新生成的密钥和之前部署github密钥的步骤类似，你登录你公司的gitlab，找到添加ssh-key的地方，然后拷贝新生成的公钥id_rsa_xx.pub文件内容到gitlab里面去并且保存，这样你公司的gitlab服务器上的公钥信息就配置好了新建配置文件因为现在我们本机上有了两对密钥，提交代码到github时需要使用之前生成的那一对，提交代码到公司的gitlab上需要我们现在刚刚生成的这一对，那么我们就要写一个简单的配置文件来告诉git该如何再提交代码时选择正确的密钥，实际上就是编写SSH的用户配置文件config。在目录~/.ssh(mac环境)或者C:/Users/xxxxx/.ssh/下新建文件config，注意没有后缀名的，然后在里面填写上如下内容：#githubHost github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa#yourcompanyHost git.XXXXX.com HostName git.XXXXX.com User git IdentityFile ~/.ssh/id_rsa_XX# 参数说明，此段内容不用拷贝，是为了加以说明# Host: 别名，为了方便记忆和区分，可以任意填写# HostName： 主机名 服务器的主机名，也可以是服务器的ip地址，需要准确填写# User： 用户名，ssh登录服务器时的用户名，一般是git# IdentityFile： 密钥文件的路径，填写上你要用来和这个服务器通信使用的密钥文件的路径# PreferredAuthentications：可选值 'publickey'和'password',强制使用密钥验证或者密码认证，我这里没有要求这个，你也可以按自己需求加上测试连接使用如下命令来分别测试能否连接到对应的服务器# 测试连接公司ssh git@git.XXXXX.com# 测试连接githubssh git@github.com如果能分别看到对应的欢迎信息，那么恭喜你配置正确了。配置个人信息这次我们因为有不同的项目，提交时需要附加上的个人信息也不一样，你提交github时会用你自己的github账户名和邮箱信息，但是提交公司的gitlab时会使用公司给你的账户名和公司个人邮箱，那么我们就需要到具体的项目下面执行如下的命令：git config user.name \"yourname\"git config user.email \"youremail@XXXXX.com\"# 参数说明# 与之前我们执行的那条配置个人信息命令相比，只是少了个'--global'参数，因为我们现在不是在全局配置，而是在个别项目中单独配置到这里为止，你的多git账户依旧配置完毕了，后面就可以和平常一样使用git来提交代码了，ssh会为你选择正确的密钥来和服务器认证和通信。"},{"title":"markdown","date":"2018-08-23","updated":"2019-05-16","path":"markdown/","link":"","text":"markdown语法整理经常使用markdown来做笔记，这里把现在常用的语法先记录一下，万一老年人了记忆不好，也可以查一查标题# h1......###### h6分隔符最少三个---或***目录(部分markdown软件不支持)[TOC]引用&gt; quote(\b每行最后添加两个空格即表示换行) quote &gt; quote(或者采取每行前面都添加引用标志)&gt; quote&gt; quote(多行嵌套引用)&gt;&gt; quote2&gt;&gt;&gt; quote3代码行内代码`code`行内代码多行代码，[支持\b高亮语言](https://blog.csdn.net/qq_32126633/article/details/78838494#language_key)链接[个人博客](https://kricsleo.github.io/ 'krics的个人博客')或者[blog]: https://kricsleo.github.io/ 'krics的个人博客'[个人博客][blog]图片![个人头像](https://kricsleo.github.io/images/avatar.jpg 'krics的个人头像')或者[avatar]: https://kricsleo.github.io/images/avatar.jpg 'krics的个人头像'![个人头像][avatar]图片带链接[![个人头像](https://kricsleo.github.io/images/avatar.jpg 'krics的个人头像')](https://kricsleo.github.io/images/avatar.jpg)序表有序节点1. 节点1 1. 节点1.12. 节点2无序节点- 节点$ - 节点$.^- 节点# - 节点#.&amp;任务- [ ] 未完成- [x] 已完成表格# 附上[在线生成表格工具](https//www.tablesgenerator.com/markdown_tables)| a | b | c ||:-------:|:------------- | ----------:|| 居中 | 左对齐 | 右对齐 |语义性*斜体* or &lt;i&gt;斜体&lt;/i&gt;**加粗** or &lt;b&gt;加粗&lt;/b&gt;***斜体加粗*** or &lt;em&gt;强调&lt;/em&gt;~~删除线~~上标&lt;sup&gt;u&lt;/sup&gt;下标&lt;sub&gt;d&lt;/sub&gt;键盘按键&lt;kbd&gt;Ctrl&lt;/kbd&gt;格式化显示&lt;pre&gt; ...&lt;pre&gt;公式 目前还不常用，之后补齐脚注Markdown[^1]在页面底端注解[^1]: Markdown是一种纯文本标记语言定义型列表Markdown: Markdown是一种纯文本标记语言 (冒号后跟一个'Tab'或者四个空格)邮箱&lt;xxx@163.com&gt;流程图markdown的代码绘制流程图个人感觉比较复杂，个人使用的在线绘制工具ProcessOn"},{"title":"git-workflow","date":"2018-08-22","updated":"2019-05-16","path":"git-workflow/","link":"","text":"git的日常使用流程记录内容参考于阮一峰老师的Git使用规范流程，记录一下git的日常使用流程。1. 新建分支开发新功能时都应该新建一个分支，在分支上开发，当功能开发完成时再合并到主分支，并销毁新建的分支。# git checkout——检出，是我们的常用命令。最为常用的两种情形是创建分支和切换分支# 先切换到主分支，获取最新代码git checkout mastergit pull# 然后新建分支，在这个分支上进行新功能开发git checkout -b myfeature2. 提交分支新功能开发完成以后提交代码# 默认保存所有改动 --allgit add# 查看发生改动的地方git status# 提交改动，也可以跟上 --verbose，然后就可以列出diff比较的结果，并且附上本次提交信息git commit3. 同步代码开发过程中可以经常同步主分支的最新代码，保证一直在最新的基础上进行开发# git fetch 表示取回最新代码git fetch origin# 将有更新的代码与当前分支合并# 所取回的更新，在本地主机上要用\"远程主机名/分支名\"的形式读取。比如origin主机的master，就要用origin/master读取。git merge origin/masterdfdf4. 合并多个commit新功能开发过程中一般会多次commit，但是在功能开发完成以后需要合并到主干时，一般把之前的commit合并成一个或几个关键的commit# git rebase命令的i参数表示互动（interactive），具体如何合并请参见原文git rebase -i origin/master5. 推送到远程仓库多个commit经过合理的处理以后就可以把当前分支推送到远程仓库了# git push命令要加上force参数，因为rebase以后，分支历史改变了，跟远程分支不一定兼容，有可能要强行推送git push --force master myfeature6. 发出Pull Request提交到远程仓库以后，就可以发出 Pull Request 到master分支，然后请求别人进行代码review，确认可以合并到master。常用 git 命令# 本地分支推送到远程# 参数: [origin] 远程主机名, 一般为 origin# [local-branch-name]: 本地创建的分支名# [remote-branch-name]: 把本地分支推送到哪个远程分支(一般和本地保持一致, 如果远程分支名不存在会自动创建)git push [origin] [local-brand-name]:[remote-branch-name]# 删除本地分支# 参数: -d 删除 -D 强制删除git branch -[d|D] [local-branch-name]# 删除远程分支git push [origin] --delete [remote-branch-name]参考文档: https//www.ruanyifeng.com/blog/2014/06/git_remote.html(end)"}]